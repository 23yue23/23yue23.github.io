<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="spark-调优篇, xianchang.yue,github">
    <meta name="description" content="性能调优分配资源：spark-submit \
--class cn.spark.sparktest.core.WordCountCluster \
--num-executors 80 \  配置executor的数量
--driver-">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>spark-调优篇 | 蜗牛笔记</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <script src="/libs/jquery/jquery.min.js"></script>
    
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">蜗牛笔记</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Medias</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/musics">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Musics</span>
        </a>
      </li>
      
      <li>
        <a href="/movies">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Movies</span>
        </a>
      </li>
      
      <li>
        <a href="/books">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Books</span>
        </a>
      </li>
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Galleries</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">蜗牛笔记</div>
        <div class="logo-desc">
            
            Either stand out or kicked out
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Medias
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="/musics " style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>Musics</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/movies " style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>Movies</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/books " style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Books</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/galleries " style="margin-left:75px";>
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Galleries</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/23yue23/23yue23.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/23yue23/23yue23.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/22.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        spark-调优篇
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/spark-调优篇/">
                                <span class="chip bg-color">spark-调优篇</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/spark/" class="post-category">
                                spark
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-04-28
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                
				
                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
            
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h3><h4 id="分配资源："><a href="#分配资源：" class="headerlink" title="分配资源："></a>分配资源：</h4><pre><code>spark-submit \
--class cn.spark.sparktest.core.WordCountCluster \
--num-executors 80 \  配置executor的数量
--driver-memory 6g \  配置driver的内存（影响不大）
--executor-memory 6g \  配置每个executor的内存大小
--executor-cores 3 \  配置每个executor的cpu core数量(RDD cache/shuffle/task执行)
--master yarn-cluster \
--queue root.default \
--conf spark.yarn.executor.memoryOverhead=2048 \  executor堆外内存
--conf spark.core.connection.ack.wait.timeout=300 \ 连接的超时时长
/usr/local/spark/spark.jar \
${1}


spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --executor-cores 3 \
  --executor-memory 10G \
  --driver-memory 4G \
  --conf spark.dynamicAllocation.enabled=true \
  --conf spark.shuffle.service.enabled=true \
  --conf spark.dynamicAllocation.initialExecutors=5 \
  --conf spark.dynamicAllocation.maxExecutors=40 \
  --conf spark.dynamicAllocation.minExecutors=0 \
  --conf spark.dynamicAllocation.executorIdleTimeout=30s \
  --conf spark.dynamicAllocation.schedulerBacklogTimeout=10s \</code></pre><hr>
<h4 id="SparkStreaming-优雅退出"><a href="#SparkStreaming-优雅退出" class="headerlink" title="SparkStreaming 优雅退出"></a>SparkStreaming 优雅退出</h4><pre><code>    public static void main(String[] args) throws Exception{
        Logger.getLogger(&quot;org&quot;).setLevel(Level.ERROR);
//String checkpointPath = PropertiesUtil.getProperty(&quot;streaming.checkpoint.path&quot;);
        JavaStreamingContext javaStreamingContext = JavaStreamingContext.getOrCreate(&quot;hdfs://Master:9000/streaming_checkpoint&quot;, createContext());
        javaStreamingContext.start();

        每隔20秒钟监控是否有停止指令,如果有则优雅退出streaming
        final Properties serverProps = PropertiesUtil.properties;
        Thread thread = new Thread(new MonitorStopThread(javaStreamingContext,serverProps));
        thread.start();
        javaStreamingContext.awaitTermination();
       }
    }</code></pre><hr>
<h4 id="调节并行度："><a href="#调节并行度：" class="headerlink" title="调节并行度："></a>调节并行度：</h4><blockquote>
<ol>
<li>并行度：其实就是指的是，Spark作业中，各个stage的task数量，也就代表了Spark作业的在各个阶段（stage）的并行度。</li>
<li>官方是推荐，task数量，设置成spark application总cpu core数量的2<del>3倍，比如150个cpu core，基本要设置task数量为300</del>500；</li>
<li>SparkConf conf = new SparkConf().set(“spark.default.parallelism”, “500”)</li>
</ol>
</blockquote>
<hr>
<h4 id="InputDStream并行化数据接收"><a href="#InputDStream并行化数据接收" class="headerlink" title="InputDStream并行化数据接收"></a>InputDStream并行化数据接收</h4><blockquote>
<p>创建多个InputDStream来接收同一数据源,把多个topic数据细化为单一的kafkaStream来接收</p>
<blockquote>
<ol>
<li>创建kafkaStream</li>
</ol>
</blockquote>
</blockquote>
<pre><code>  Map&lt;String, String&gt; kafkaParams = new HashMap&lt;String, String&gt;();
   kafkaParams.put(&quot;metadata.broker.list&quot;, &quot;192.168.1.164:9092,192.168.1.165:9092,192.168.1.166:9092&quot;);
   kafkaParams.put(&quot;zookeeper.connect&quot;,&quot;master:2181,data1:2181,data2:2181&quot;);

   构建topic set
   String kafkaTopics = ConfigurationManager.getProperty(Constants.KAFKA_TOPICS);
   String[] kafkaTopicsSplited = kafkaTopics.split(&quot;,&quot;);

   Set&lt;String&gt; topics = new HashSet&lt;String&gt;();
   for(String kafkaTopic : kafkaTopicsSplited) {
       topics.add(kafkaTopic);

   JavaPairInputDStream&lt;String, String&gt; kafkaStream = KafkaUtils.createDirectStream(
       jssc, 
       String.class, 
       String.class, 
       StringDecoder.class, 
       StringDecoder.class, 
       kafkaParams, 
       topics);</code></pre><blockquote>
<blockquote>
<ol start="2">
<li>InputDStream并行化数据接收</li>
</ol>
</blockquote>
</blockquote>
<pre><code> ```
   int numStreams = 5;
   List&lt;JavaPairDStream&lt;String, String&gt;&gt; kafkaStreams = new
   ArrayList&lt;JavaPairDStream&lt;String,String&gt;&gt;(numStreams);
   for (int i = 0; i &lt; numStreams; i++) {
       kafkaStreams.add(KafkaUtils.createStream(...));
       }
   JavaPairDStream&lt;String, String&gt; unifiedStream = streamingContext.union(kafkaStreams.get(0), kafkaStreams.subList(1, kafkaStreams.size()));
  unifiedStream.print();

```</code></pre><hr>
<h4 id="增加block数量，增加每个batch-rdd的partition数量，增加处理并行度"><a href="#增加block数量，增加每个batch-rdd的partition数量，增加处理并行度" class="headerlink" title="增加block数量，增加每个batch rdd的partition数量，增加处理并行度"></a>增加block数量，增加每个batch rdd的partition数量，增加处理并行度</h4><pre><code>第一步：receiver从数据源源源不断地获取到数据，首先是会按照block interval，将指定时间间隔的数据，收集为一个block；默认时间是200ms，官方推荐不要小于50ms；
第二步：根据指定batch interval时间间隔合并为一个batch，创建为一个rdd，
第三步：启动一个job，去处理这个batch rdd中的数据。
第四步：batch rdd 的partition数量是多少呢？一个batch有多少个block，就有多少个partition；就意味着并行度是多少；就意味着每个batch rdd有多少个task会并行计算和处理。
调优：如果希望可以比默认的task数量和并行度再多一些，可以手动调节blockinterval，减少block interval。每个batch可以包含更多的block。因此也就有更多的partition，因此就会有更多的task并行处理每个batch rdd。</code></pre><h4 id="重分区，增加每个batch-rdd的partition数量"><a href="#重分区，增加每个batch-rdd的partition数量" class="headerlink" title="重分区，增加每个batch rdd的partition数量"></a>重分区，增加每个batch rdd的partition数量</h4><p>inputStream.repartition()：重分区，增加每个batch rdd的partition数量<br>对dstream中的rdd进行重分区为指定数量的分区，就可以提高指定dstream的rdd的计算并行度<br>调节并行度</p>
<hr>
<h4 id="重构RDD架构以及RDD持久化："><a href="#重构RDD架构以及RDD持久化：" class="headerlink" title="重构RDD架构以及RDD持久化："></a>重构RDD架构以及RDD持久化：</h4><blockquote>
<ol>
<li>RDD架构重构与优化</li>
<li>公共RDD一定要实现持久化,对于要多次计算和使用的公共RDD，一定要进行持久化。</li>
<li>持久化，是可以进行序列化的<br>sessionid2actionRDD=sessionid2actionRDD.persist(StorageLevel.MEMORY_ONLY());<pre><code>``` 
 MEMORY_ONLY    直接以Java对象的形式存储于JVM的内存中
 MYMORY_AND_DISK    存储于JVM的内存+磁盘
 MEMORY_ONLY_SER    序列化存储于内存中
 MEMORY_AND_DISK_SER    序列化存储于内存+磁盘
 ```</code></pre></li>
<li>为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化</li>
</ol>
</blockquote>
<hr>
<h4 id="实现RDD高可用性：启动WAL预写日志机制"><a href="#实现RDD高可用性：启动WAL预写日志机制" class="headerlink" title="实现RDD高可用性：启动WAL预写日志机制"></a>实现RDD高可用性：启动WAL预写日志机制</h4><blockquote>
<p>spark streaming，从原理上来说，是通过receiver来进行数据接收的；接收到的数据，会被划分成一个一个的block；block会被组合成一个batch；针对一个batch，会创建一个rdd；<br>receiver接收到数据后，就会立即将数据写入一份到容错文件系统（比如hdfs）上的checkpoint目录中的，另一份写入到磁盘文件中去；作为数据的冗余副本。无论你的程序怎么挂掉，或者是数据丢失，那么数据都不肯能会永久性的丢失；因为肯定有副本。</p>
</blockquote>
<pre><code>  SparkConf conf = new SparkConf()       
              .setMaster(&quot;local[2]&quot;)
              .setAppName(&quot;StreamingSpark&quot;);
            .set(&quot;spark.serializer&quot;,&quot;org.apache.spark.serializer.KryoSerializer&quot;);
             .set(&quot;spark.default.parallelism&quot;, &quot;1000&quot;);
              .set(&quot;spark.streaming.blockInterval&quot;, &quot;50&quot;);    
              .set(&quot;spark.streaming.receiver.writeAheadLog.enable&quot;, &quot;true&quot;);   
  JavaStreamingContext jssc = new JavaStreamingContext(conf,Durations.seconds(5)); 
  jssc.checkpoint(&quot;hdfs://192.168.1.164:9000/checkpoint&quot;);</code></pre><hr>
<h4 id="广播大变量（1m-100m）："><a href="#广播大变量（1m-100m）：" class="headerlink" title="广播大变量（1m~100m）："></a>广播大变量（1m~100m）：</h4><blockquote>
<ol>
<li>默认的情况下，task执行的算子中，使用了外部的变量，每个task都会获取一份变量的副本，有什么缺点呢？<pre><code> 网络传输的开销、耗费内存、RDD持久化到内存（内存不够，持续到磁盘）、task创建对象导致gc；</code></pre></li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>广播变量，初始的时候，就在Drvier上有一份副本。</li>
</ol>
</blockquote>
<pre><code>task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；
如果本地没有，那么就从Driver远程拉取变量副本，并保存在本地的BlockManager中；
此后这个executor上的task，都会直接使用本地的BlockManager中的副本。
executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，举例越近越好。
sc.boradcast();</code></pre><hr>
<h4 id="使用Kryo序列化"><a href="#使用Kryo序列化" class="headerlink" title="使用Kryo序列化:"></a>使用Kryo序列化:</h4><blockquote>
<ol>
<li>默认情况下，Spark内部是使用Java的序列化机制，ObjectOutputStream / ObjectInputStream，对象输入输出流机制，来进行序列化。</li>
<li>Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。</li>
<li>Kryo序列化机制，一旦启用以后，会生效的几个地方：<pre><code> ```
 1、算子函数中使用到的外部变量
 2、持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER
 3、shuffle
    .set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)
    .set(&quot;spark.default.parallelism&quot;, &quot;1000&quot;);
       .set(&quot;spark.streaming.blockInterval&quot;, &quot;50&quot;);    
       .set(&quot;spark.streaming.receiver.writeAheadLog.enable&quot;, &quot;true&quot;);   
    .registerKryoClasses(new Class[]{CategorySortKey.class})</code></pre></li>
</ol>
</blockquote>
<pre><code>  &gt; 4. 序列化
       ``` 1、在SparkConf中设置一个属性，spark.serializer，org.apache.spark.serializer.KryoSerializer类；
        2、注册你使用到的，需要通过Kryo序列化的，一些自定义类，SparkConf.registerKryoClasses() </code></pre><hr>
<h4 id="使用fastutil优化数据格式"><a href="#使用fastutil优化数据格式" class="headerlink" title="使用fastutil优化数据格式:"></a>使用fastutil优化数据格式:</h4><blockquote>
<ol>
<li>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；</li>
<li>fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set，好处在于，fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度；</li>
</ol>
</blockquote>
<p>fastutil也提供了64位的array、set和list，以及高性能快速的，以及实用的IO类，来处理二进制和文本类型的文件；fastutil最新版本要求Java 7以及以上版本；</p>
<p>fastutil的每一种集合类型，都实现了对应的Java中的标准接口（比如fastutil的map，实现了Java的Map接口），因此可以直接放入已有系统的任何代码中。</p>
<p>fastutil还提供了一些JDK标准类库中没有的额外功能（比如双向迭代器）。<br>fastutil除了对象和原始类型为元素的集合，fastutil也提供引用类型的支持，但是对引用类型是使用等于号（=）进行比较的，而不是equals()方法。</p>
<blockquote>
<ol start="3">
<li>maven 依赖</li>
</ol>
</blockquote>
<pre><code>  &lt;dependency&gt;
    &lt;groupId&gt;fastutil&lt;/groupId&gt;
    &lt;artifactId&gt;fastutil&lt;/artifactId&gt;
    &lt;version&gt;5.0.9&lt;/version&gt;
  &lt;/dependency&gt;</code></pre><hr>
<h4 id="调节数据本地化等待时长："><a href="#调节数据本地化等待时长：" class="headerlink" title="调节数据本地化等待时长："></a>调节数据本地化等待时长：</h4><blockquote>
<ol>
<li>PROCESS_LOCAL：进程本地化；NODE_LOCAL：节点本地化；NO_PREF：对于task来说，没有好坏之分；RACK_LOCAL：机架本地化；ANY：数据和task可能在集群中的任何地方，而且不在一个机架中，性能最差；</li>
<li>观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。<br>日志里面会显示，starting task。。。，PROCESS LOCAL（不用调节）、NODE LOCAL、ANY（调节一下数据本地化的等待时长），反复调节，每次调节完以后，再来运行，观察日志</li>
<li>怎么调节？</li>
</ol>
</blockquote>
<pre><code>spark.locality.wait，默认是3s；6s，10s
默认情况下，下面3个的等待时长，都是跟上面那个是一样的，都是3s
spark.locality.wait.process
spark.locality.wait.node
spark.locality.wait.rack
new SparkConf()
  .set(&quot;spark.locality.wait&quot;, &quot;10&quot;)</code></pre><hr>
<h4 id="定时清除不需要的数据"><a href="#定时清除不需要的数据" class="headerlink" title="定时清除不需要的数据"></a>定时清除不需要的数据</h4><blockquote>
<ol>
<li>通过配置spark.cleaner.ttl为一个合理的值，但是这个值不能过小，因为如果后面计算需要用的数据被清除会带来不必要的麻烦。</li>
<li>另外通过配置spark.streaming.unpersist为true(默认就是true)来更智能地去持久化（unpersist）RDD。这个配置使系统找出那些不需要经常保有的RDD，然后去持久化它们。这可以减少Spark RDD的内存使用，也可能改善垃圾回收的行为。</li>
</ol>
</blockquote>
<hr>
<h4 id="去除压缩-内存充足的情况下"><a href="#去除压缩-内存充足的情况下" class="headerlink" title="去除压缩 (内存充足的情况下)"></a>去除压缩 (内存充足的情况下)</h4><p>在内存充足的情况下，可以设置spark.rdd.compress 设置为false.</p>
<hr>
<h3 id="Yarn-优化"><a href="#Yarn-优化" class="headerlink" title="Yarn 优化"></a>Yarn 优化</h3><h4 id="Executors和cpu核心数设置和Spark-On-Yarn-动态资源分配"><a href="#Executors和cpu核心数设置和Spark-On-Yarn-动态资源分配" class="headerlink" title="Executors和cpu核心数设置和Spark On Yarn 动态资源分配"></a>Executors和cpu核心数设置和Spark On Yarn 动态资源分配</h4><blockquote>
<p>首先需要对YARN的NodeManager进行配置，使其支持Spark的Shuffle Service。</p>
</blockquote>
<pre><code>  #修改
  &lt;property&gt;
  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
  &lt;value&gt;mapreduce_shuffle,spark_shuffle&lt;/value&gt;
  &lt;/property&gt;
  #增加
  &lt;property&gt;
  &lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;
  &lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
  &lt;name&gt;spark.shuffle.service.port&lt;/name&gt;
  &lt;value&gt;7337&lt;/value&gt;
  &lt;/property&gt;</code></pre><blockquote>
<p>将spark中对应jar包拷贝到hadoop的目录下：</p>
</blockquote>
<pre><code>  首先找到spark版本的spark-&lt;version&gt;-yarn-shuffle.jar
  shuffle包，并将该包放到集群所有NodeManager的classpath下，
  比如放到HADOOP_HOME/share/hadoop/yarn/lib</code></pre><hr>
<h3 id="JVM-调优"><a href="#JVM-调优" class="headerlink" title="JVM 调优"></a>JVM 调优</h3><h4 id="原理概述以及降低cache操作的内存占比"><a href="#原理概述以及降低cache操作的内存占比" class="headerlink" title="原理概述以及降低cache操作的内存占比:"></a>原理概述以及降低cache操作的内存占比:</h4><blockquote>
<ol>
<li>full gc / minor gc，无论是快，还是慢，都会导致jvm的工作线程停止工作，stop the world。简而言之，就是说，gc的时候，spark停止工作了。等着垃圾回收结束。</li>
<li>spark中，堆内存又被划分成了两块儿，存储内存和执行内存；<pre><code> 一句话，让task执行算子函数时，有更多的内存可以使用。</code></pre></li>
</ol>
</blockquote>
<hr>
<h4 id="GC优化策略-暂时不确定"><a href="#GC优化策略-暂时不确定" class="headerlink" title="GC优化策略(暂时不确定)"></a>GC优化策略(暂时不确定)</h4><p>建议用并行Mark-Sweep垃圾回收机制，虽然它消耗更多的资源，但是我们还是建议开启。<br>在spark-submit中使用<br>–driver-java-options “-XX:+UseConcMarkSweepGC”<br>–conf “spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC”</p>
<h4 id="调节executor堆外内存与连接等待时长-在spark-sbmit中修改-："><a href="#调节executor堆外内存与连接等待时长-在spark-sbmit中修改-：" class="headerlink" title="调节executor堆外内存与连接等待时长(在spark-sbmit中修改)："></a>调节executor堆外内存与连接等待时长(在spark-sbmit中修改)：</h4><blockquote>
<ol>
<li>有时候，如果你的spark作业处理的数据量特别特别大，几亿数据量；然后spark作业一运行，时不时的报错，shuffle file cannot find，executor、task lost，out of memory（内存溢出）；–conf spark.yarn.executor.memoryOverhead=2048</li>
<li>有时候，无法建立网络连接；会卡住；ok，spark默认的网络连接的超时时长，是60s；如果卡住60s都无法建立连接的话，那么就宣告失败了:一串file id。uuid（dsfsfd-2342vs–sdf–sdfsd）。not found。file lost。<br> –conf spark.core.connection.ack.wait.timeout=300</li>
</ol>
</blockquote>
<hr>
<h3 id="Shuffle调优"><a href="#Shuffle调优" class="headerlink" title="Shuffle调优"></a>Shuffle调优</h3><h4 id="原理概述："><a href="#原理概述：" class="headerlink" title="原理概述："></a>原理概述：</h4><blockquote>
<ol>
<li>在spark中，主要是以下几个算子：groupByKey、reduceByKey、countByKey、join，等等。</li>
<li>shuffle，一定是分为两个stage来完成的。因为这其实是个逆向的过程，不是stage决定shuffle，是shuffle决定stage。</li>
<li>shuffle前半部分的task在写入数据到磁盘文件之前，都会先写入一个一个的内存缓冲，内存缓冲满溢之后，再spill溢写到磁盘文件中。</li>
</ol>
</blockquote>
<hr>
<h4 id="合并map端输出文件："><a href="#合并map端输出文件：" class="headerlink" title="合并map端输出文件："></a>合并map端输出文件：</h4><blockquote>
<ol>
<li>开启shuffle map端输出文件合并的机制；默认情况下，是不开启的，就是会发生如上所述的大量map端输出文件的操作，严重影响性能。</li>
<li>new SparkConf().set(“spark.shuffle.consolidateFiles”, “true”)<br>new SparkConf().set(“spark.shuffle.consolidateFiles”, “true”)</li>
</ol>
</blockquote>
<hr>
<h4 id="合并map端输出文件：-1"><a href="#合并map端输出文件：-1" class="headerlink" title="合并map端输出文件："></a>合并map端输出文件：</h4><blockquote>
<ol>
<li>map端内存缓冲：spark.shuffle.file.buffer，默认32k  <pre><code> reduce端内存占比：spark.shuffle.memoryFraction，0.2</code></pre></li>
<li>调节的时候的原则。spark.shuffle.file.buffer，每次扩大一倍，然后看看效果，64，128；<br>spark.shuffle.memoryFraction，每次提高0.1，看看效果。<br>不能调节的太大，太大了以后过犹不及，因为内存资源是有限的，你这里调节的太大了，其他环节的内存使用就会有问题了。</li>
</ol>
</blockquote>
<pre><code>new SparkConf().set(&quot;spark.shuffle.file.buffer&quot;, &quot;64&quot;)
new SparkConf().set(&quot;spark.shuffle.memoryFraction&quot;, &quot;0.3&quot;)</code></pre><hr>
<h4 id="HashShuffleManager与SortShuffleManager"><a href="#HashShuffleManager与SortShuffleManager" class="headerlink" title="HashShuffleManager与SortShuffleManager"></a>HashShuffleManager与SortShuffleManager</h4><blockquote>
<ol>
<li>spark.shuffle.manager：hash、sort、tungsten-sort（自己实现内存管理），spark 1.2.x版本以后，默认的shuffle manager，是SortShuffleManager。<br>   spark.shuffle.sort.bypassMergeThreshold：200（默认值为200）</li>
<li>SortShuffleManager会避免像HashShuffleManager那样，默认就去创建多份磁盘文件。一个task，只会写入一个磁盘文件，不同reduce task的数据，用offset来划分界定。</li>
</ol>
</blockquote>
<pre><code>new SparkConf().set(&quot;spark.shuffle.manager&quot;, &quot;sort&quot;)
new SparkConf().set(&quot;spark.shuffle.sort.bypassMergeThreshold&quot;, &quot;550&quot;)</code></pre><hr>
<h3 id="算子调优"><a href="#算子调优" class="headerlink" title="算子调优"></a>算子调优</h3><h4 id="MapPartitions提升Map类操作性能"><a href="#MapPartitions提升Map类操作性能" class="headerlink" title="MapPartitions提升Map类操作性能:"></a>MapPartitions提升Map类操作性能:</h4><blockquote>
<ol>
<li>如果是普通的map，比如一个partition中有1万条数据；function要执行和计算1万次。但是，使用MapPartitions操作之后，一个task仅仅会执行一次function，function一次接收所有的partition数据。只要执行一次就可以了，性能比较高。</li>
<li>但是，可能就OOM，内存溢出。   </li>
</ol>
</blockquote>
<hr>
<h4 id="filter过后使用coalesce减少分区数量："><a href="#filter过后使用coalesce减少分区数量：" class="headerlink" title="filter过后使用coalesce减少分区数量："></a>filter过后使用coalesce减少分区数量：</h4><blockquote>
<ol>
<li>就会导致有些task运行的速度很快；有些task运行的速度很慢。这就是数据倾斜。</li>
<li>coalesce算子：主要就是用于在filter操作之后，针对每个partition的数据量各不相同的情况，来压缩partition的数量。减少partition的数量，而且让每个partition的数据量都尽量均匀紧凑。</li>
</ol>
</blockquote>
<hr>
<h4 id="foreachPartition优化写数据库性能："><a href="#foreachPartition优化写数据库性能：" class="headerlink" title="foreachPartition优化写数据库性能："></a>foreachPartition优化写数据库性能：</h4><pre><code>&gt; 1. 用了foreachPartition算子之后，好处在哪里？
    1、对于我们写的function函数，就调用一次，一次传入一个partition所有数据；
    2、主要创建或者获取一个数据库连接就可以；
    3、只要向数据库发送一次SQL语句和多组参数即可；
&gt; 2. 很有可能会发生OOM，内存溢出的问题。
    一个partition大概是1千条左右用foreach，跟用foreachPartition，性能的提升达到了2~3分钟。</code></pre><hr>
<h4 id="repartition解决Spark-SQL低并行度的性能问题："><a href="#repartition解决Spark-SQL低并行度的性能问题：" class="headerlink" title="repartition解决Spark SQL低并行度的性能问题："></a>repartition解决Spark SQL低并行度的性能问题：</h4><pre><code>repartition算子，你用Spark SQL这一步的并行度和task数量，肯定是没有办法去改变了。但是呢，可以将你用Spark SQL查询出来的RDD，使用repartition算子，去重新进行分区，此时可以分区成多个partition，比如从20个partition，分区成100个。</code></pre><hr>
<h4 id="reduceByKey本地聚合介绍："><a href="#reduceByKey本地聚合介绍：" class="headerlink" title="reduceByKey本地聚合介绍："></a>reduceByKey本地聚合介绍：</h4><pre><code>reduceByKey，相较于普通的shuffle操作（比如groupByKey），它的一个特点，就是说，会进行map端的本地聚合</code></pre><h3 id="代码-调优"><a href="#代码-调优" class="headerlink" title="代码 调优"></a>代码 调优</h3><h4 id="进行HA机制处理-针对Driver高可用性"><a href="#进行HA机制处理-针对Driver高可用性" class="headerlink" title="进行HA机制处理-针对Driver高可用性"></a>进行HA机制处理-针对Driver高可用性</h4><blockquote>
<p>在创建和启动StreamingContext的时候，将元数据写入容错的文件系统（比如hdfs）。保证在driver挂掉之后，spark集群可以自己将driver重新启动起来；而且driver在启动的时候，不会重新创建一个streaming context，而是从容错文件系统（比如hdfs）中读取之前的元数据信息，包括job的执行进度，继续接着之前的进度，继续执行。使用这种机制，就必须使用cluster模式提交，确保driver运行在某个worker上面；</p>
</blockquote>
<pre><code>  JavaStreamingContextFactory contextFactory = new JavaStreamingContextFactory() {
      @Override
     public JavaStreamingContext create() {
           JavaStreamingContext jssc = new JavaStreamingContext(...);
          JavaDStream&lt;String&gt; lines = jssc.socketTextStream(...);
          jssc.checkpoint(checkpointDirectory);
          return jssc;
        }
      };
 JavaStreamingContext context = JavaStreamingContext.getOrCreate(checkpointDirectory, contextFactory);
 context.start();
 context.awaitTermination();</code></pre><pre><code>JavaStreamingContext.getOrCreate 基于Function0&lt; JavaStreamingContext &gt; 进行Driver高可用
 Function0&lt;JavaStreamingContext&gt; createContextFunc = new Function0&lt;JavaStreamingContext&gt;(){
     @Override
     public JavaStreamingContext call() throws Exception
     {
         conf = new SparkConf()
                 .setMaster(&quot;local[4]&quot;)
                 .setAppName(&quot;java/RealTimeStreaming&quot;)
                 .set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)
                 .set(&quot;spark.default.parallelism&quot;, &quot;10&quot;)
                 .set(&quot;spark.streaming.blockInterval&quot;, &quot;50&quot;)
                 .set(&quot;spark.streaming.receiver.writeAheadLog.enable&quot;, &quot;true&quot;);
         Map&lt;String, Object&gt; kafkaParams = new HashMap&lt;&gt;();
         kafkaParams.put(&quot;bootstrap.servers&quot;, &quot;Master:9092,Worker1:9092,Worker2:9092&quot;);
         kafkaParams.put(&quot;key.deserializer&quot;, StringDeserializer.class);
         kafkaParams.put(&quot;value.deserializer&quot;, StringDeserializer.class);
         kafkaParams.put(&quot;group.id&quot;, &quot;TestGroup&quot;);
         kafkaParams.put(&quot;auto.offset.reset&quot;, &quot;latest&quot;);
         kafkaParams.put(&quot;enable.auto.commit&quot;,true);

         JavaStreamingContext jssc = new JavaStreamingContext(
                 conf, Durations.seconds(30));
         jssc.checkpoint(&quot;hdfs://Master:9000/checkpoint&quot;);

         // 构建topic set
         String kafkaTopics = ConfigurationManager.getProperty(Constants.KAFKA_TOPICS);
         String[] kafkaTopicsSplited = kafkaTopics.split(&quot;,&quot;);
         Set&lt;String&gt; topics = new HashSet&lt;String&gt;();
         for(String kafkaTopic : kafkaTopicsSplited) {
             topics.add(kafkaTopic);
         }

         JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; adRealTimeLogDStream = KafkaUtils.createDirectStream(jssc,
                 LocationStrategies.PreferConsistent(),
                 ConsumerStrategies.Subscribe(topics, kafkaParams));

         hostMap = adRealTimeLogDStream.mapToPair(record -&gt; new Tuple2&lt;String, String&gt;(record.key(), record.value()));

         logPeakDstream  = hostMap.mapToPair(new PairFunction&lt;Tuple2&lt;String, String&gt;, String, Long&gt;() {
             @Override
             public Tuple2&lt;String,Long&gt; call(Tuple2&lt;String, String&gt; tuple) throws Exception {
                 String log = tuple._2;
                 String[] logSplited = log.split(&quot;\\|&quot;);
                 String eventTime= logSplited[1];
                 String todayDate = DATE_FORMAT.format(new Date()).trim();
                 String cutTime= eventTime.substring(13,eventTime.length()-7);

                 String ip = logSplited[0].trim();
                 String host = logSplited[14].trim();
                 return new Tuple2&lt;String, Long&gt;(host+&quot;-&quot;+ip, 1L);
             }
         });

         hostReduce = logPeakDstream.reduceByKeyAndWindow(new Function2&lt;Long, Long, Long&gt;() {
             @Override
             public Long call(Long v1, Long v2) throws Exception {
                 return v1 + v2;
             }
         }, Durations.minutes(10),Durations.seconds(30));

         JavaPairDStream&lt;String, Long&gt; topNPairRdd = hostReduce.transformToPair(new Function&lt;JavaPairRDD&lt;String, Long&gt;, JavaPairRDD&lt;String, Long&gt;&gt;() {
             @Override
             public JavaPairRDD&lt;String, Long&gt; call(JavaPairRDD&lt;String, Long&gt; rdd) throws Exception {
                 JavaPairRDD&lt;Long, String&gt; sortRDD = (JavaPairRDD&lt;Long, String&gt;) rdd.mapToPair(record -&gt; new Tuple2&lt;Long, String&gt;(record._2, record._1));
                 JavaPairRDD&lt;String, Long&gt; sortedRdd = (JavaPairRDD&lt;String, Long&gt;) sortRDD.sortByKey(false).mapToPair(record -&gt; new Tuple2&lt;String, Long&gt;(record._2, record._1));

                 List&lt;Tuple2&lt;String, Long&gt;&gt; topNs = sortedRdd.take(5);//取前5个输出
                 System.out.println(&quot;                                                 &quot;);
                 System.out.println(&quot;*****************峰值访问窗统计*******************&quot;);
                 for (Tuple2&lt;String, Long&gt; topN : topNs) {
                     System.out.println(topN);
                 }
                 System.out.println(&quot;**********************END***********************&quot;);
                 System.out.println(&quot;                                                 &quot;);
                 return sortedRdd;
             }
         });

         topNPairRdd.foreachRDD(new VoidFunction&lt;JavaPairRDD&lt;String, Long&gt;&gt;() {
             @Override
             public void call(JavaPairRDD&lt;String, Long&gt; rdd) throws Exception {

             }
         });

         logDetailDstream = hostMap.map(new Function&lt;Tuple2&lt;String,String&gt;, String&gt;() {
             @Override
             public String call(Tuple2&lt;String, String&gt; tuple) throws Exception {
                 String log = tuple._2;
                 String[] logSplited = log.split(&quot;\\|&quot;);
                 String eventTime= logSplited[1];
                 String todayDate = DATE_FORMAT.format(new Date()).trim();
                 String cutTime= eventTime.substring(13,eventTime.length()-7);
                 String[] urlDetails = logSplited[7].split(&quot;/&quot;);
                 String ip = logSplited[0].trim();

                 String url =&quot;&quot;;
                 if(urlDetails.length==4){
                     url = urlDetails[3];
                 }else if(urlDetails.length==5){
                     url = urlDetails[3] + &quot;/&quot; + urlDetails[4];
                 }else if(urlDetails.length&gt;=6){
                     url = urlDetails[3] + &quot;/&quot; + urlDetails[4]+ &quot;/&quot; + urlDetails[5];
                 }
                 String host = logSplited[14].trim();
                 String dataTime =todayDate +&quot; &quot;+ cutTime;
                 String bytesSent = logSplited[5].trim();
                 return  dataTime+&quot; &quot;+host+&quot; &quot;+ip+&quot; &quot;+url+&quot; &quot;+bytesSent;
             }
         });
         //logDetailDstream.print();
         return jssc;
     }
 };
 return createContextFunc;</code></pre><pre><code>
 提交方式
  spark-submit
          --deploy-mode cluster
          --supervise
</code></pre><hr>
<h4 id="SparkStreaming-与kafka整合调优"><a href="#SparkStreaming-与kafka整合调优" class="headerlink" title="SparkStreaming 与kafka整合调优"></a>SparkStreaming 与kafka整合调优</h4><blockquote>
<p>LocationStrategies 位置策略：</p>
</blockquote>
<pre><code>The new Kafka consumer API will pre-fetch messages into buffers. Therefore it is important for performance 
reasons that the Spark integration keep cached consumers on executors (rather than recreating them for each 
batch), and prefer to schedule partitions on the host locations that have the appropriate consumers.</code></pre><blockquote>
<p>新的Kafka消费者API可以预获取消息缓存到缓冲区，因此Spark整合Kafka让消费者在executor上进行缓存对性能是非常有助的，可以调度消费者所在主机位置的分区。</p>
</blockquote>
<pre><code>In most cases, you should use LocationStrategies.PreferConsistent as shown above. This will distribute partitions 
evenly across available executors. If your executors are on the same hosts as your Kafka brokers, use PreferBrokers,
which will prefer to schedule partitions on the Kafka leader for that partition. Finally, if you have a significant 
skew in load among partitions, use PreferFixed. This allows you to specify an explicit mapping of partitions to 
hosts (any unspecified partitions will use a consistent location).</code></pre><blockquote>
<p>通常，你可以使用 LocationStrategies.PreferConsistent，这个策略会将分区分布到所有可获得的executor上。如果你的executor和kafkabroker在同一主机上的话，可以使用PreferBrokers，这样kafka leader会为此分区进行调度。最后，如果你加载数据有倾斜的话可以使用PreferFixed，这将允许你制定一个分区和主机的映射（没有指定的分区将使用PreferConsistent 策略）</p>
</blockquote>
<pre><code>The cache for consumers has a default maximum size of 64. If you expect to be handling more than 
(64 * number of executors) Kafka partitions, you can change this setting
via spark.streaming.kafka.consumer.cache.maxCapacity</code></pre><blockquote>
<p>消费者默认缓存大小是64，如果你期望处理较大的Kafka分区的话，你可以使用</p>
</blockquote>
<pre><code>spark.streaming.kafka.consumer.cache.maxCapacity设置大小。
The cache is keyed by topicpartition and group.id, so use a separate group.id for each call to createDirectStream.</code></pre><blockquote>
<p>缓存是使用key为topic partition 和组id的，因此对于每一次调用 createDirectStream 可以使用不同的 group . id</p>
</blockquote>
<pre><code>public  static SparkConf  conf = new SparkConf()
                .setMaster(&quot;local[4]&quot;)
                .setAppName(&quot;java/RealTimeStreaming&quot;)
                .set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)
                .set(&quot;spark.default.parallelism&quot;, &quot;10&quot;)
                .set(&quot;spark.streaming.blockInterval&quot;, &quot;50&quot;)
                .set(&quot;spark.streaming.receiver.writeAheadLog.enable&quot;, &quot;true&quot;);
Map&lt;String, Object&gt; kafkaParams = new HashMap&lt;&gt;();
kafkaParams.put(&quot;bootstrap.servers&quot;, &quot;Master:9092,Worker1:9092,Worker2:9092&quot;);
kafkaParams.put(&quot;key.deserializer&quot;, StringDeserializer.class);
kafkaParams.put(&quot;value.deserializer&quot;, StringDeserializer.class);
kafkaParams.put(&quot;group.id&quot;, &quot;TestGroup&quot;);
kafkaParams.put(&quot;auto.offset.reset&quot;, &quot;latest&quot;);
kafkaParams.put(&quot;enable.auto.commit&quot;,true);

JavaStreamingContext jssc = new JavaStreamingContext(
        conf, Durations.seconds(30));
jssc.checkpoint(&quot;hdfs://Master:9000/checkpoint&quot;);</code></pre><blockquote>
<p>构建topic set</p>
</blockquote>
<pre><code>String kafkaTopics = ConfigurationManager.getProperty(Constants.KAFKA_TOPICS);
String[] kafkaTopicsSplited = kafkaTopics.split(&quot;,&quot;);
Set&lt;String&gt; topics = new HashSet&lt;String&gt;();
for(String kafkaTopic : kafkaTopicsSplited) {
    topics.add(kafkaTopic);
        }

JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; adRealTimeLogDStream = KafkaUtils.createDirectStream(jssc,
        LocationStrategies.PreferConsistent(),
        ConsumerStrategies.Subscribe(topics, kafkaParams));</code></pre>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://23yue23.github.io" rel="external nofollow noreferrer">岳贤昌</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://23yue23.github.io/2019/04/28/spark-调优篇/">https://23yue23.github.io/2019/04/28/spark-调优篇/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://23yue23.github.io" target="_blank">岳贤昌</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/spark-调优篇/">
                                    <span class="chip bg-color">spark-调优篇</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2019/04/29/经典文章/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/16.jpg" class="responsive-img" alt="技术文章">
                        
                        <span class="card-title">技术文章</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            技术文章

MySQL索引原理及慢查询优化
美团点评基于 Flink 的实时数仓建设实践
从零开始入门推荐算法工程师
计算广告与流处理技术综述


学习规划文章1.面试过阿里等互联网大公司，我知道了这些套路

                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2019-04-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/技术文章/" class="post-category">
                                    技术文章
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/技术文章/">
                        <span class="chip bg-color">技术文章</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/04/28/grafana-资料篇/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="grafana-资料篇">
                        
                        <span class="card-title">grafana-资料篇</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            本文罗列了一些 grafana 学习资料。
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2019-04-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/grafana/" class="post-category">
                                    grafana
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/grafana-资料篇/">
                        <span class="chip bg-color">grafana-资料篇</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>

    
<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('3'),
            headingSelector: 'h2, h3, h4, h5, h6'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4, h5, h6').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">年份</span>
            <a href="https://23yue23.github.io" target="_blank">岳贤昌</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">51.9k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    window.setTimeout("siteTime()", 1000);
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2019";
                    var startMonth = "6";
                    var startDate = "28";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/23yue23/23yue23.github.io" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:yxc_job@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=978265975" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 978265975" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"superSample":2,"width":100,"height":100,"position":"right"},"mobile":{"show":false},"react":{"opacityDefault":0.6,"opacityOnHover":0.3},"log":false});</script></body>

</html>
