<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蜗牛笔记</title>
  
  <subtitle>永不设限，尽在自律。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://BradyYue.github.io/"/>
  <updated>2020-03-04T02:11:16.665Z</updated>
  <id>https://BradyYue.github.io/</id>
  
  <author>
    <name>岳贤昌</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>博客文章总目录</title>
    <link href="https://BradyYue.github.io/2020/01/07/%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0%E6%80%BB%E7%9B%AE%E5%BD%95/"/>
    <id>https://BradyYue.github.io/2020/01/07/博客文章总目录/</id>
    <published>2020-01-07T07:17:38.000Z</published>
    <updated>2020-03-04T02:11:16.665Z</updated>
    
    <content type="html"><![CDATA[<h4 id="A"><a href="#A" class="headerlink" title="A"></a>A</h4><h6 id="azkaban"><a href="#azkaban" class="headerlink" title="azkaban"></a>azkaban</h6><h6 id="airflow"><a href="#airflow" class="headerlink" title="airflow"></a>airflow</h6><h6 id="atlas"><a href="#atlas" class="headerlink" title="atlas"></a>atlas</h6><h6 id="avro"><a href="#avro" class="headerlink" title="avro"></a>avro</h6><h4 id="B"><a href="#B" class="headerlink" title="B"></a>B</h4><h6 id="brew"><a href="#brew" class="headerlink" title="brew"></a>brew</h6><h4 id="C"><a href="#C" class="headerlink" title="C"></a>C</h4><h6 id="cassandra"><a href="#cassandra" class="headerlink" title="cassandra"></a>cassandra</h6><h6 id="clickhouse"><a href="#clickhouse" class="headerlink" title="clickhouse"></a>clickhouse</h6><h4 id="D"><a href="#D" class="headerlink" title="D"></a>D</h4><h6 id="druid"><a href="#druid" class="headerlink" title="druid"></a>druid</h6><h6 id="dubbo"><a href="#dubbo" class="headerlink" title="dubbo"></a>dubbo</h6><h4 id="E"><a href="#E" class="headerlink" title="E"></a>E</h4><h6 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h6><h4 id="F"><a href="#F" class="headerlink" title="F"></a>F</h4><h6 id="flink"><a href="#flink" class="headerlink" title="flink"></a>flink</h6><blockquote><p>flink优化(1)-配置参数优化<br>flink优化(2)-优化<br>flink优化(3)-<br>flink优化(4)-相关文章</p></blockquote><blockquote><p>flink应用-<br>flink案例-<br>flink</p></blockquote><h6 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h6><h4 id="G"><a href="#G" class="headerlink" title="G"></a>G</h4><h6 id="grafana"><a href="#grafana" class="headerlink" title="grafana"></a>grafana</h6><h6 id="go"><a href="#go" class="headerlink" title="go"></a>go</h6><h6 id="git"><a href="#git" class="headerlink" title="git"></a>git</h6><h4 id="H"><a href="#H" class="headerlink" title="H"></a>H</h4><h6 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h6><h6 id="haproxy"><a href="#haproxy" class="headerlink" title="haproxy"></a>haproxy</h6><h6 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h6><h6 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h6><h6 id="httpd"><a href="#httpd" class="headerlink" title="httpd"></a>httpd</h6><h4 id="I"><a href="#I" class="headerlink" title="I"></a>I</h4><h6 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h6><h6 id="ignite"><a href="#ignite" class="headerlink" title="ignite"></a>ignite</h6><h6 id="impala"><a href="#impala" class="headerlink" title="impala"></a>impala</h6><h4 id="J"><a href="#J" class="headerlink" title="J"></a>J</h4><h6 id="java"><a href="#java" class="headerlink" title="java"></a>java</h6><h4 id="K"><a href="#K" class="headerlink" title="K"></a>K</h4><h6 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h6><h6 id="kubernets"><a href="#kubernets" class="headerlink" title="kubernets"></a>kubernets</h6><h6 id="kudu"><a href="#kudu" class="headerlink" title="kudu"></a>kudu</h6><h6 id="kylin"><a href="#kylin" class="headerlink" title="kylin"></a>kylin</h6><h4 id="L"><a href="#L" class="headerlink" title="L"></a>L</h4><h6 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h6><h6 id="livy"><a href="#livy" class="headerlink" title="livy"></a>livy</h6><h4 id="M"><a href="#M" class="headerlink" title="M"></a>M</h4><h6 id="maven"><a href="#maven" class="headerlink" title="maven"></a>maven</h6><h4 id="N"><a href="#N" class="headerlink" title="N"></a>N</h4><h6 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h6><h6 id="netty"><a href="#netty" class="headerlink" title="netty"></a>netty</h6><h4 id="O"><a href="#O" class="headerlink" title="O"></a>O</h4><h6 id="orc"><a href="#orc" class="headerlink" title="orc"></a>orc</h6><h4 id="P"><a href="#P" class="headerlink" title="P"></a>P</h4><h6 id="parquet"><a href="#parquet" class="headerlink" title="parquet"></a>parquet</h6><h6 id="python"><a href="#python" class="headerlink" title="python"></a>python</h6><h6 id="pulsar"><a href="#pulsar" class="headerlink" title="pulsar"></a>pulsar</h6><h4 id="Q"><a href="#Q" class="headerlink" title="Q"></a>Q</h4><h4 id="R"><a href="#R" class="headerlink" title="R"></a>R</h4><h6 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h6><h6 id="rpc"><a href="#rpc" class="headerlink" title="rpc"></a>rpc</h6><h4 id="S"><a href="#S" class="headerlink" title="S"></a>S</h4><h6 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h6><h6 id="spring-全家桶"><a href="#spring-全家桶" class="headerlink" title="spring 全家桶"></a>spring 全家桶</h6><h6 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h6><h6 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h6><h4 id="T"><a href="#T" class="headerlink" title="T"></a>T</h4><h6 id="tomcat"><a href="#tomcat" class="headerlink" title="tomcat"></a>tomcat</h6><h4 id="V"><a href="#V" class="headerlink" title="V"></a>V</h4><h6 id="vim"><a href="#vim" class="headerlink" title="vim"></a>vim</h6><h4 id="Y"><a href="#Y" class="headerlink" title="Y"></a>Y</h4><h6 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h6><h4 id="Z"><a href="#Z" class="headerlink" title="Z"></a>Z</h4><h6 id="zabbix"><a href="#zabbix" class="headerlink" title="zabbix"></a>zabbix</h6><h6 id="zeppelin"><a href="#zeppelin" class="headerlink" title="zeppelin"></a>zeppelin</h6><h6 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h6><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><h6 id="心灵港湾"><a href="#心灵港湾" class="headerlink" title="心灵港湾"></a>心灵港湾</h6><h6 id="书籍阅读"><a href="#书籍阅读" class="headerlink" title="书籍阅读"></a>书籍阅读</h6><h6 id="生活感悟"><a href="#生活感悟" class="headerlink" title="生活感悟"></a>生活感悟</h6>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;A&quot;&gt;&lt;a href=&quot;#A&quot; class=&quot;headerlink&quot; title=&quot;A&quot;&gt;&lt;/a&gt;A&lt;/h4&gt;&lt;h6 id=&quot;azkaban&quot;&gt;&lt;a href=&quot;#azkaban&quot; class=&quot;headerlink&quot; title=&quot;azkaban&quot;&gt;&lt;/a&gt;az
      
    
    </summary>
    
      <category term="目录" scheme="https://BradyYue.github.io/categories/%E7%9B%AE%E5%BD%95/"/>
    
    
      <category term="目录" scheme="https://BradyYue.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>go-学习篇</title>
    <link href="https://BradyYue.github.io/2019/12/31/go-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/31/go-学习篇/</id>
    <published>2019-12-31T02:58:23.000Z</published>
    <updated>2019-12-31T03:01:17.398Z</updated>
    
    <content type="html"><![CDATA[<p>基础：<br>声明放后面，函数多产出，</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;基础：&lt;br&gt;声明放后面，函数多产出，&lt;/p&gt;

      
    
    </summary>
    
      <category term="go" scheme="https://BradyYue.github.io/categories/go/"/>
    
    
      <category term="go 学习篇" scheme="https://BradyYue.github.io/tags/go-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>zabbix-报警脚本篇</title>
    <link href="https://BradyYue.github.io/2019/12/27/zabbix-%E6%8A%A5%E8%AD%A6%E8%84%9A%E6%9C%AC%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/27/zabbix-报警脚本篇/</id>
    <published>2019-12-27T08:11:43.000Z</published>
    <updated>2019-12-27T08:14:47.843Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>邮件报警</p></blockquote><pre class=" language-sh"><code class="language-sh">#!/bin/bash#export.UTF-8FILE=/tmp/mailtmp.txtecho "$3" >$FILEdos2unix -k $FILE/bin/mail -s "$2" $1 < $FILE</code></pre><blockquote><p>微信报警</p></blockquote><pre><code>#!/bin/bash## Filename:    sendWeiXin.sh# Revision:    1.0# Description: zabbix微信报警脚本CropID=&#39;wxxxxxxxxxxxxxxxxx&#39;Secret=&#39;XXXXXXXXXXXXXXXXXXXXXX-XXXXX-XXXXXXXXXXXXXXXXX-XXXXXXXXXXXXXXXXX&#39;GURL=&quot;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$CropID&amp;corpsecret=$Secret&quot; Gtoken=$(/usr/bin/curl -s -G $GURL | awk -F\&quot; &#39;{print $4}&#39;)PURL=&quot;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$Gtoken&quot;function body() {        local int AppID=6                       # 企业号中的应用id        local UserID=$1                         # 部门成员id，zabbix中定义的微信接收者        local PartyID=                         # 部门id，定义了范围，组内成员都可接收到消息        local Msg=$(echo &quot;$@&quot; | cut -d&quot; &quot; -f3-) # 过滤出zabbix中传递的第三个参数        printf &#39;{\n&#39;        printf &#39;\t&quot;touser&quot;: &quot;&#39;&quot;$UserID&quot;&#39;&quot;,\n&#39;        printf &#39;\t&quot;toparty&quot;: &quot;&#39;&quot;$PartyID&quot;&#39;&quot;,\n&#39;        printf &#39;\t&quot;msgtype&quot;: &quot;text&quot;,\n&#39;        printf &#39;\t&quot;agentid&quot;: &#39;&quot;$AppID&quot;&#39;,\n&#39;        printf &#39;\t&quot;text&quot;: {\n&#39;        printf &#39;\t\t&quot;content&quot;: &quot;&#39;&quot;$Msg&quot;&#39;&quot;\n&#39;        printf &#39;\t},\n&#39;        printf &#39;\t&quot;safe&quot;:&quot;0&quot;\n&#39;        printf &#39;}\n&#39;}/usr/bin/curl --data-ascii &quot;$(body $1 $2 $3)&quot; $PURL#body $1 $2 $3</code></pre><blockquote><p>短信报警</p></blockquote><pre><code>#!/bin/bash## Filename:    sendSMS.sh# Description: zabbix短信告警脚本# 脚本的日志文件LOGFILE=&quot;/tmp/SMS.log&quot;&gt;&quot;$LOGFILE&quot;exec 1&gt;&quot;$LOGFILE&quot;exec 2&gt;&amp;1# Uid 网站用户名# Key 接口秘钥Uid=&quot;itttl-user&quot;Key=&quot;itttl-passwd&quot;MOBILE_NUMBER=$1    # 手机号码MESSAGE_FUCK=$3        # 短信内容MESSAGE_UTF8=`iconv -t GB2312 -f UTF-8 &lt;&lt; EOF$MESSAGE_FUCKEOF`XXD=&quot;/usr/bin/xxd&quot;CURL=&quot;/usr/bin/curl&quot;TIMEOUT=5# 短信内容要经过URL编码处理，除了下面这种方法，也可以用curl的--data-urlencode选项实现。MESSAGE_ENCODE=$(echo &quot;$MESSAGE_UTF8&quot; | ${XXD} -ps | sed &#39;s/\(..\)/%\1/g&#39; | tr -d &#39;\n&#39;)# SMS APIURL=&quot;http://123.45.67.89:9876/QxtSms/QxtFirewall?OperID=${Uid}&amp;OperPass=${Key}&amp;SendTime=&amp;ValidTime=&amp;AppendID=0000&amp;DesMobile=${MOBILE_NUMBER}&amp;Content=${MESSAGE_ENCODE}&amp;ContentType=8&quot;# Send itset -x${CURL} -s --connect-timeout ${TIMEOUT} &quot;${URL}&quot;</code></pre><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;邮件报警&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot; language-sh&quot;&gt;&lt;code class=&quot;language-sh&quot;&gt;#!/bin/bash
#export.UTF-8
FILE=/tmp/mailtmp.txt
e
      
    
    </summary>
    
      <category term="zabbix" scheme="https://BradyYue.github.io/categories/zabbix/"/>
    
    
      <category term="zabbix 报警脚本篇" scheme="https://BradyYue.github.io/tags/zabbix-%E6%8A%A5%E8%AD%A6%E8%84%9A%E6%9C%AC%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>扫雷系列-Java进程CPU过高故障排查</title>
    <link href="https://BradyYue.github.io/2019/12/27/%E6%89%AB%E9%9B%B7%E7%B3%BB%E5%88%97-Java%E8%BF%9B%E7%A8%8BCPU%E8%BF%87%E9%AB%98%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"/>
    <id>https://BradyYue.github.io/2019/12/27/扫雷系列-Java进程CPU过高故障排查/</id>
    <published>2019-12-27T08:04:41.000Z</published>
    <updated>2019-12-27T08:09:16.890Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载地址：<a href="http://blog.itttl.com/blog/java/java_tuning.html" target="_blank" rel="noopener">http://blog.itttl.com/blog/java/java_tuning.html</a></p></blockquote><blockquote><p>问题描述：</p></blockquote><p>排查java服务CPU负载异常过高。</p><blockquote><p>解决过程：</p></blockquote><p>1.根据top命令，发现PID为9914的Java进程占用CPU高达150%，出现故障。</p><p>2.找到该进程后，如何定位具体线程或代码呢，首先显示线程列表,并按照CPU占用高的线程排序：</p><pre><code>[root@test01 logs]# ps -mp 9914 -o THREAD,tid,time | sort -rn显示结果如下：USER     %CPU PRI SCNT WCHAN  USER SYSTEM   TID     TIMEroot     28.6  19    - futex_    -      - 10032 00:16:56root     28.6  19    - -         -      -  9985 00:16:59root     28.5  19    - futex_    -      -  9981 00:16:56root     28.5  19    - -         -      - 10108 00:16:55找到了耗时最高的线程10032，占用CPU时间有16分钟了！将需要的线程ID转换为16进制格式：[root@test01 logs]# printf &quot;%x\n&quot; 100322730最后打印线程的堆栈信息：[root@test01 logs]# jstack 2633 |grep 2730 -A 30将输出的信息发给开发部进行确认，这样就能找出有问题的代码。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载地址：&lt;a href=&quot;http://blog.itttl.com/blog/java/java_tuning.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://blog.itttl.com/blog/ja
      
    
    </summary>
    
      <category term="扫雷系列" scheme="https://BradyYue.github.io/categories/%E6%89%AB%E9%9B%B7%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="扫雷系列 Java进程CPU过高故障排查" scheme="https://BradyYue.github.io/tags/%E6%89%AB%E9%9B%B7%E7%B3%BB%E5%88%97-Java%E8%BF%9B%E7%A8%8BCPU%E8%BF%87%E9%AB%98%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>zeppelin-部署篇</title>
    <link href="https://BradyYue.github.io/2019/12/24/zeppelin-%E9%83%A8%E7%BD%B2%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/24/zeppelin-部署篇/</id>
    <published>2019-12-24T05:47:35.000Z</published>
    <updated>2019-12-24T05:47:35.402Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="zeppelin-部署篇" scheme="https://BradyYue.github.io/categories/zeppelin-%E9%83%A8%E7%BD%B2%E7%AF%87/"/>
    
    
      <category term="zeppelin-部署篇" scheme="https://BradyYue.github.io/tags/zeppelin-%E9%83%A8%E7%BD%B2%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>azkaban-部署篇</title>
    <link href="https://BradyYue.github.io/2019/12/24/azkaban-%E9%83%A8%E7%BD%B2%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/24/azkaban-部署篇/</id>
    <published>2019-12-24T05:47:23.000Z</published>
    <updated>2019-12-24T06:10:39.657Z</updated>
    
    <content type="html"><![CDATA[<h4 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h4><blockquote><p>macOS | java 8 |gradle | azkaban</p></blockquote><h4 id="构建source-的命令"><a href="#构建source-的命令" class="headerlink" title="构建source 的命令"></a>构建source 的命令</h4><pre><code># Build Azkaban./gradlew build# Clean the build./gradlew clean# Build and install distributions./gradlew installDist# Run tests./gradlew test# Build without running tests./gradlew build -x test</code></pre><h4 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h4><pre><code>#下载azkaban git clone https://github.com/azkaban/azkaban.git#选择版本git checkout 3.81.4#source 进行build./gradlew clean build#或者构建成tar 的形式，上传服务器进行部署，只需部署exec 和web ./gradlew clean distTar</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;部署环境&quot;&gt;&lt;a href=&quot;#部署环境&quot; class=&quot;headerlink&quot; title=&quot;部署环境&quot;&gt;&lt;/a&gt;部署环境&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;macOS | java 8 |gradle | azkaban&lt;/p&gt;
&lt;/blockquote
      
    
    </summary>
    
      <category term="azkaban" scheme="https://BradyYue.github.io/categories/azkaban/"/>
    
    
      <category term="azkaban-部署篇" scheme="https://BradyYue.github.io/tags/azkaban-%E9%83%A8%E7%BD%B2%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>k8s-aliyun操作</title>
    <link href="https://BradyYue.github.io/2019/12/19/k8s-aliyun%E6%93%8D%E4%BD%9C/"/>
    <id>https://BradyYue.github.io/2019/12/19/k8s-aliyun操作/</id>
    <published>2019-12-19T11:47:39.000Z</published>
    <updated>2019-12-19T11:49:14.347Z</updated>
    
    <content type="html"><![CDATA[<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><blockquote><p>获取令牌 （需在master 节点）</p></blockquote><pre><code>kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#39;{print $1}&#39;)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;常用命令&quot;&gt;&lt;a href=&quot;#常用命令&quot; class=&quot;headerlink&quot; title=&quot;常用命令&quot;&gt;&lt;/a&gt;常用命令&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;获取令牌 （需在master 节点）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;k
      
    
    </summary>
    
      <category term="k8s-aliyun操作" scheme="https://BradyYue.github.io/categories/k8s-aliyun%E6%93%8D%E4%BD%9C/"/>
    
    
      <category term="k8s-aliyun操作" scheme="https://BradyYue.github.io/tags/k8s-aliyun%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>java-ThreadLocalRandom篇</title>
    <link href="https://BradyYue.github.io/2019/12/19/java-ThreadLocalRandom%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/19/java-ThreadLocalRandom篇/</id>
    <published>2019-12-19T08:47:06.000Z</published>
    <updated>2019-12-19T09:11:57.621Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-为什么用？"><a href="#1-为什么用？" class="headerlink" title="1.为什么用？"></a>1.为什么用？</h4><p>因为在Java 7 才引入了 java.util.concurrent.ThreadLocalRandom 类，主要是用于在多线程环境中生成随机数。是 ThreadLocal 类和 Random 类的组合，与当前线程隔离，通过简单地避免对 Random 对象的任何并发访问，在多线程环境中实现了更好的性能。</p><h4 id="2-怎么用？"><a href="#2-怎么用？" class="headerlink" title="2.怎么用？"></a>2.怎么用？</h4><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//当前边界时 int 的边界</span><span class="token keyword">int</span> boundedRandomValue <span class="token operator">=</span> ThreadLocalRandom<span class="token punctuation">.</span><span class="token function">current</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//当前边界时【0，100） 之间，包含0 不包含100</span><span class="token keyword">int</span> boundedRandomValue <span class="token operator">=</span> ThreadLocalRandom<span class="token punctuation">.</span><span class="token function">current</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="3-使用场景"><a href="#3-使用场景" class="headerlink" title="3.使用场景"></a>3.使用场景</h4><pre><code>//可用于大数据倾斜时，用于打散数据。//key + &quot;@&quot; + ThreadLocalRandom.current().nextInt()</code></pre><p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/ed298b30.png" alt="图来自美团技术团队的博客：https://tech.meituan.com/2016/05/12/spark-tuning-pro.html"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-为什么用？&quot;&gt;&lt;a href=&quot;#1-为什么用？&quot; class=&quot;headerlink&quot; title=&quot;1.为什么用？&quot;&gt;&lt;/a&gt;1.为什么用？&lt;/h4&gt;&lt;p&gt;因为在Java 7 才引入了 java.util.concurrent.ThreadLocalRan
      
    
    </summary>
    
      <category term="java" scheme="https://BradyYue.github.io/categories/java/"/>
    
    
      <category term="java ThreadLocalRandom" scheme="https://BradyYue.github.io/tags/java-ThreadLocalRandom/"/>
    
  </entry>
  
  <entry>
    <title>azkaban-问题篇</title>
    <link href="https://BradyYue.github.io/2019/12/19/azkaban-%E9%97%AE%E9%A2%98%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/19/azkaban-问题篇/</id>
    <published>2019-12-19T02:26:22.000Z</published>
    <updated>2019-12-19T02:44:07.508Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-azkaban-exec-遇到的问题"><a href="#1-azkaban-exec-遇到的问题" class="headerlink" title="1.azkaban exec 遇到的问题"></a>1.azkaban exec 遇到的问题</h4><h5 id="1-1-Job-failed-Cannot-request-memory-Xms-0-kb-Xmx-0-kb-from-system-for-job"><a href="#1-1-Job-failed-Cannot-request-memory-Xms-0-kb-Xmx-0-kb-from-system-for-job" class="headerlink" title="1.1 Job failed, Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job"></a>1.1 Job failed, Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job</h5><pre><code>异常：    ERROR - Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job job_run_distinct_impression cause: null分析：当前遇到的问题，是在提交作业的时候进行了内存的检查，认为空闲资源不足，抛除的异常。解决：在 azkaban/exec-server/plugins/jobtypes/commonprivate.properties文件中添加memCheck.enable=false参考： https://github.com/azkaban/azkaban/issues/481      https://my.oschina.net/u/2988360/blog/1537561</code></pre><h4 id="2-azkaban-web-遇到的问题"><a href="#2-azkaban-web-遇到的问题" class="headerlink" title="2.azkaban web 遇到的问题"></a>2.azkaban web 遇到的问题</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-azkaban-exec-遇到的问题&quot;&gt;&lt;a href=&quot;#1-azkaban-exec-遇到的问题&quot; class=&quot;headerlink&quot; title=&quot;1.azkaban exec 遇到的问题&quot;&gt;&lt;/a&gt;1.azkaban exec 遇到的问题&lt;/h4&gt;&lt;
      
    
    </summary>
    
      <category term="azkaban" scheme="https://BradyYue.github.io/categories/azkaban/"/>
    
    
      <category term="azkaban" scheme="https://BradyYue.github.io/tags/azkaban/"/>
    
  </entry>
  
  <entry>
    <title>flink-优化篇</title>
    <link href="https://BradyYue.github.io/2019/12/17/flink-%E4%BC%98%E5%8C%96%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/17/flink-优化篇/</id>
    <published>2019-12-17T02:33:22.000Z</published>
    <updated>2020-01-07T03:21:37.275Z</updated>
    
    <content type="html"><![CDATA[<h4 id="flink-基础配置层面"><a href="#flink-基础配置层面" class="headerlink" title="flink 基础配置层面"></a>flink 基础配置层面</h4><h5 id="1-flink-conf-yaml-配置优化"><a href="#1-flink-conf-yaml-配置优化" class="headerlink" title="1.flink-conf.yaml 配置优化"></a>1.flink-conf.yaml 配置优化</h5><blockquote><p>1.优化GC</p></blockquote><pre><code>Flink是依赖内存计算，计算过程中内存不够对Flink的执行效率影响很大。可以通过监控GC（Garbage Collection），评估内存使用及剩余情况来判断内存是否变成性能瓶颈，并根据情况优化。监控节点进程的YARN的Container GC日志，如果频繁出现Full GC，需要优化GC。解决方法：GC的配置：在客户端的“conf/flink-conf.yaml”配置文件中，在“env.java.opts”配置项中添加参数：“-Xloggc:&lt;LOG_DIR&gt;/gc.log -XX:+PrintGCDetails -XX:-OmitStackTraceInFastThrow -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=20 -XX:GCLogFileSize=20M”。 此处默认已经添加GC日志。调整老年代和新生代的比值。在客户端的“conf/flink-conf.yaml”配置文件中，在“env.java.opts”配置项中添加参数：“-XX:NewRatio”。如“ -XX:NewRatio=2”，则表示老年代与新生代的比值为2:1，新生代占整个堆空间的1/3，老年代占2/3。</code></pre><blockquote><p>2.配置进程参数</p></blockquote><pre><code>操作场景Flink on YARN模式下，有JobManager和TaskManager两种进程。在任务调度和运行的过程中，JobManager和TaskManager承担了很大的责任。因而JobManager和TaskManager的参数配置对Flink应用的执行有着很大的影响意义。用户可通过如下操作对Flink集群性能做优化。操作步骤1.配置JobManager内存。    JobManager负责任务的调度，以及TaskManager、RM之间的消息通信。当任务数变多，任务平行度增大时，JobManager内存都需要相应增大。您可以根据实际任务数量的多少，为JobManager设置一个合适的内存。1.1在使用yarn-session命令时，添加“-jm MEM”参数设置内存。1.2在使用yarn-cluster命令时，添加“-yjm MEM”参数设置内存。2.配置TaskManager个数。每个TaskManager每个核同时能跑一个task，所以增加了TaskManager的个数相当于增大了任务的并发度。在资源充足的情况下，可以相应增加TaskManager的个数，以提高运行效率。2.1在使用yarn-session命令时，添加“-n NUM”参数设置TaskManager个数。2.2在使用yarn-cluster命令时，添加“-yn NUM”参数设置TaskManager个数。3.配置TaskManager Slot数。每个TaskManager多个核同时能跑多个task，相当于增大了任务的并发度。但是由于所有核共用TaskManager的内存，所以要在内存和核数之间做好平衡。3.1在使用yarn-session命令时，添加“-s NUM”参数设置SLOT数。3.2在使用yarn-cluster命令时，添加“-ys NUM”参数设置SLOT数。4.配置TaskManager内存。TaskManager的内存主要用于任务执行、通信等。当一个任务很大的时候，可能需要较多资源，因而内存也可以做相应的增加。4.1将在使用yarn-sesion命令时，添加“-tm MEM”参数设置内存。4.2将在使用yarn-cluster命令时，添加“-ytm MEM”参数设置内存。</code></pre><blockquote><ol start="3"><li>设计分区方法</li></ol></blockquote><pre><code>操作场景合理的设计分区依据，可以优化task的切分。在程序编写过程中要尽量分区均匀，这样可以实现每个task数据不倾斜，防止由于某个task的执行时间过长导致整个任务执行缓慢。操作步骤以下是几种分区方法。随机分区：将元素随机地进行分区。dataStream.shuffle();Rebalancing (Round-robin partitioning)：基于round-robin对元素进行分区，使得每个分区负责均衡。对于存在数据倾斜的性能优化是很有用的。dataStream.rebalance();Rescaling：以round-robin的形式将元素分区到下游操作的子集中。如果你想要将数据从一个源的每个并行实例中散发到一些mappers的子集中，用来分散负载，但是又不想要完全的rebalance 介入（引入`rebalance()`），这会非常有用。dataStream.rescale();广播：广播每个元素到所有分区。dataStream.broadcast();自定义分区：使用一个用户自定义的Partitioner对每一个元素选择目标task，由于用户对自己的数据更加熟悉，可以按照某个特征进行分区，从而优化任务执行。简单示例如下所示：// fromElements构造简单的Tuple2流DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dataStream = env.fromElements(Tuple2.of(&quot;hello&quot;,1), Tuple2.of(&quot;test&quot;,2), Tuple2.of(&quot;world&quot;,100));// 定义用于分区的key值，返回即属于哪个partition的，该值加1就是对应的子任务的id号Partitioner&lt;Tuple2&lt;String, Integer&gt;&gt; strPartitioner = new Partitioner&lt;Tuple2&lt;String, Integer&gt;&gt;() {    @Override    public int partition(Tuple2&lt;String, Integer&gt; key, int numPartitions) {        return (key.f0.length() + key.f1) % numPartitions;    }};// 使用Tuple2进行分区的key值dataStream.partitionCustom(strPartitioner, new KeySelector&lt;Tuple2&lt;String, Integer&gt;, Tuple2&lt;String, Integer&gt;&gt;() {    @Override    public Tuple2&lt;String, Integer&gt; getKey(Tuple2&lt;String, Integer&gt; value) throws Exception {        return value;    }}).print();</code></pre><blockquote><ol start="4"><li>配置netty网络通信</li></ol></blockquote><pre><code>操作场景Flink通信主要依赖netty网络，所以在Flink应用执行过程中，netty的设置尤为重要，网络通信的好坏直接决定着数据交换的速度以及任务执行的效率。操作步骤以下配置均可在客户端的“conf/flink-conf.yaml”配置文件中进行修改适配，默认已经是相对较优解，请谨慎修改，防止性能下降。“taskmanager.network.netty.num-arenas”： 默认是“taskmanager.numberOfTaskSlots”，表示netty的域的数量。“taskmanager.network.netty.server.numThreads”和“taskmanager.network.netty.client.numThreads”：默认是“taskmanager.numberOfTaskSlots”，表示netty的客户端和服务端的线程数目设置。“taskmanager.network.netty.client.connectTimeoutSec”：默认是120s，表示taskmanager的客户端连接超时的时间。“taskmanager.network.netty.sendReceiveBufferSize”：默认是系统缓冲区大小(cat /proc/sys/net/ipv4/tcp_[rw]mem) ，一般为4MB，表示netty的发送和接收的缓冲区大小。“taskmanager.network.netty.transport”：默认为“nio”方式，表示netty的传输方式，有“nio”和“epoll”两种方式。</code></pre><blockquote><p>5.优化设置总结</p></blockquote><pre><code>1.数据倾斜当数据发生倾斜（某一部分数据量特别大），虽然没有GC（Gabage Collection，垃圾回收），但是task执行时间严重不一致。1.1需要重新设计key，以更小粒度的key使得task大小合理化。1.2修改并行度。1.3调用rebalance操作，使数据分区均匀。2.缓冲区超时设置由于task在执行过程中存在数据通过网络进行交换，数据在不同服务器之间传递的缓冲区超时时间可以通过setBufferTimeout进行设置。当设置“setBufferTimeout(-1)”，会等待缓冲区满之后才会刷新，使其达到最大吞吐量；当设置“setBufferTimeout(0)”时，可以最小化延迟，数据一旦接收到就会刷新；当设置“setBufferTimeout”大于0时，缓冲区会在该时间之后超时，然后进行缓冲区的刷新。示例可以参考如下：env.setBufferTimeout(timeoutMillis);env.generateSequence(1,10).map(new MyMapper()).setBufferTimeout(timeoutMillis);</code></pre><h5 id="2-程序内部接收外部传参（配置常变的参数）"><a href="#2-程序内部接收外部传参（配置常变的参数）" class="headerlink" title="2.程序内部接收外部传参（配置常变的参数）"></a>2.程序内部接收外部传参（配置常变的参数）</h5><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//解析参数</span><span class="token keyword">val</span> parameters <span class="token operator">=</span> ParameterTool<span class="token punctuation">.</span>fromArgs<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//将参数设置到job 的全局参数中</span>env<span class="token punctuation">.</span>getConfig<span class="token punctuation">.</span>setGlobalJobParameters<span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//register the parameters globally</span><span class="token comment" spellcheck="true">// 获取方式： 外部的参数名</span><span class="token keyword">val</span> parallelisms <span class="token operator">=</span> parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"parallelisms"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt###在继承富函数后 open中初始化查询<span class="token keyword">val</span> params<span class="token operator">:</span> ParameterTool <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getExecutionConfig<span class="token punctuation">.</span>getGlobalJobParameters<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>ParameterTool<span class="token punctuation">]</span><span class="token keyword">val</span> restore <span class="token operator">=</span> params<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"restoreFlag"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim</code></pre><hr><h5 id="3-加载内部配置文件-（配置固定不变的参数）"><a href="#3-加载内部配置文件-（配置固定不变的参数）" class="headerlink" title="3.加载内部配置文件 （配置固定不变的参数）"></a>3.加载内部配置文件 （配置固定不变的参数）</h5><pre class=" language-scala"><code class="language-scala"> <span class="token keyword">def</span> loadConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token punctuation">{</span>     <span class="token keyword">val</span> p <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">val</span> in <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getClassLoader<span class="token punctuation">.</span>getResourceAsStream<span class="token punctuation">(</span><span class="token string">"config.properties"</span><span class="token punctuation">)</span>     p<span class="token punctuation">.</span>load<span class="token punctuation">(</span>in<span class="token punctuation">)</span>     in<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>     p   <span class="token punctuation">}</span></code></pre><hr><h5 id="4-程序中的并行执行设置"><a href="#4-程序中的并行执行设置" class="headerlink" title="4.程序中的并行执行设置"></a>4.程序中的并行执行设置</h5><blockquote><p>并行度的概念</p></blockquote><pre><code> 并行度数和slot 数有关，而slot 数是有taskManager 的核数决定的，</code></pre><blockquote><p>并行设置的方式</p></blockquote><pre><code> 1.可以内部程序接收外部传参数的形式。 2.可以内部程序env.setParallelism(16)的形式设置全局的并行度。 3.可以设置算子级别的并行度 4.命令行中进行全局设置： ./bin/flink run -p 5 ../wordCount-java*.jar</code></pre><blockquote><p>并行度设置优化点：</p></blockquote><pre><code>1. 在设置kafka source的时候，可以设置与partition 数一致的并行度。    这样会启动与分区数对等的flinkKafkaConsumer 实例。每个FlinkKafkaConsumer实例消费的topic和partition则是根据探测到的所有指定topic分区对于并行数量取余数拿到的。    公式：(startIndex+parttion.getPartition())%numParallerSubtasks == currentTaskId2.当然kafka source也可以根据topic的数量进行设置，当数据量少时，可以设置并行度小于partition数。  注意：不要设置并发数大于 partitions 总数，因为这种情况下某些并发因为分配不到 partition 导致没有数据处理。3.#        </code></pre><blockquote><p>并行度设置注意事项：</p></blockquote><pre><code>Apache Flink的并行度设置并不是说越大越好、数据处理的效率就越高。而是需要设置合理的并行度。那么何谓合理呢？Apache Flink的 并行度取决于每个TaskManager上的slot数量而决定的。Flink的JobManager把任务分成子任务提交给slot进行执行。相同的slot共享相同的JVM资源，同时对Flink提供维护的心跳等信息。slot是指TaskManagere的并发执行能力，通常来说TaskManager有多少核CPU也就会有多少个slot。这样来看，我们设置的并行度其实是与TaskManager所有Slot数量有关的</code></pre><hr><h5 id="5-name-和uid-设置的作用"><a href="#5-name-和uid-设置的作用" class="headerlink" title="5.name 和uid 设置的作用"></a>5.name 和uid 设置的作用</h5><hr><h4 id="flink-的容错层面"><a href="#flink-的容错层面" class="headerlink" title="flink 的容错层面"></a>flink 的容错层面</h4><h5 id="1-内部失败重试策略"><a href="#1-内部失败重试策略" class="headerlink" title="1.内部失败重试策略"></a>1.内部失败重试策略</h5><blockquote><p>故障恢复可设置指标：</p></blockquote><blockquote><ul><li>RestartStrategies.fixedDelayRestart  </li><li>RestartStrategies.failureRateRestart</li><li>RestartStrategies.noRestart</li></ul></blockquote><blockquote><ol><li>如果发生故障，系统将尝试重新启动作业3次，并在连续的重新启动尝试之间等待10秒。</li></ol></blockquote><pre class=" language-scala"><code class="language-scala">env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span>RestartStrategies<span class="token punctuation">.</span>fixedDelayRestart<span class="token punctuation">(</span>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">// number of restart attempts</span>  Time<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// delay</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><blockquote><ol start="2"><li>超过设定的指标，则该作业最终将失败（程序常用）</li></ol></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 设置内部 如果10分钟内连续失败3次，或者每次失败间隔时间超过15s 将认为不可恢复，则作业失败。其他情况作业默认启用内部恢复策略，直到作业恢复。</span>env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span>RestartStrategies<span class="token punctuation">.</span>failureRateRestart<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>   org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>time<span class="token punctuation">.</span>Time<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>MINUTES<span class="token punctuation">)</span><span class="token punctuation">,</span>   org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>time<span class="token punctuation">.</span>Time<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><blockquote><ol start="3"><li>不设置重试策略，作业有异常时直接失败。</li></ol></blockquote><pre class=" language-scala"><code class="language-scala"> env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span>RestartStrategies<span class="token punctuation">.</span>noRestart<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><hr><h4 id="flink-状态数据层面"><a href="#flink-状态数据层面" class="headerlink" title="flink 状态数据层面"></a>flink 状态数据层面</h4><h5 id="1-checkpoint-优化设置"><a href="#1-checkpoint-优化设置" class="headerlink" title="1.checkpoint 优化设置"></a>1.checkpoint 优化设置</h5><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//设置checkpoint 快照时间为5分钟</span>env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">300000l</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//设置的是事件的处理时间</span><span class="token punctuation">.</span>setStreamTimeCharacteristic<span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>ProcessingTime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">/***设置checkpoint 取消时清理和保留机制：* 1.DELETE_ON_CANCELLATION 工作取消时删除checkpoint 做的检查点。* 2.RETAIN_ON_CANCELLATION 工作取消时保留checkpoint 做的检查点*/</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>enableExternalizedCheckpoints<span class="token punctuation">(</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 设置两个检查点之间的最小间隔，</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMinPauseBetweenCheckpoints<span class="token punctuation">(</span><span class="token number">1000L</span> <span class="token operator">*</span> <span class="token number">60L</span> <span class="token operator">*</span> <span class="token number">5L</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//设置checkpoint的超时时间</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">1000L</span> <span class="token operator">*</span> <span class="token number">60L</span> <span class="token operator">*</span> <span class="token number">30L</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//设置checkpoint 的最大并发数       </span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMaxConcurrentCheckpoints<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//当前path 最好是hdfs 的路径，s3 的路径有时会出现一致性的问题。</span><span class="token keyword">val</span> backend <span class="token operator">=</span> <span class="token keyword">new</span> RocksDBStateBackend<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">/*** 设置rsDB的保存策略* 由于flink 不依赖磁盘上的RocksDB数据进行恢复，因此无需将数据同步到稳定的存储中。* 1.DEFAULT ：所有设置都是默认选项，但不强制写入磁盘* 2.SPINNING_DISK_OPTIMIZED：使用常规硬盘提高性能。* 3.SPINNING_DISK_OPTIMIZED_HIGH_MEM：此配置将会应用大量的内存用于块的缓存和压缩，如果遇到DB内存不足，建议切换为第二种SPINNING_DISK_OPTIMIZED。* 4.FLASH_SSD_OPTIMIZED：使用SSD 提高性能**/</span>backend<span class="token punctuation">.</span>setPredefinedOptions<span class="token punctuation">(</span>PredefinedOptions<span class="token punctuation">.</span>FLASH_SSD_OPTIMIZED<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//设置checkpoint的模式：CheckpointingMode.EXACTLY_ONCE or CheckpointingMode.AT_LEAST_ONCE</span><span class="token comment" spellcheck="true">//默认是使用的 EXACTLY_ONCE</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//将ck保存进行set</span>env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span>backend<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>StateBackend<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><hr><h5 id="2-自动清理程序状态（flink-1-8-And-Processing-Time）"><a href="#2-自动清理程序状态（flink-1-8-And-Processing-Time）" class="headerlink" title="2.自动清理程序状态（flink 1.8+ And Processing Time）"></a>2.自动清理程序状态（flink 1.8+ And Processing Time）</h5><blockquote><p>基本介绍</p></blockquote><pre><code>1.在Flink的DataStream API中，应用程序状态是由状态描述符（state descriptor）来定义的。状态生存时间是通过将StateTtlConfiguration对象传递给状态描述符来配置的。 2.flink 提供多个选项配置状态的生存时间行为* 什么时候重置生存时间？ 默认情况下，当状态被修改时，生存时间就会被更新。我们也可以在读操作访问状态时更新相关项的生存时间，但这样要花费额外的写操作来更新时间戳。*已经过期的数据是否可以访问？ 状态生存时间机制使用的是惰性策略来清除过期状态。这可能导致应用程序会尝试读取过期但尚未删除的状态。用户可以配置对这样的读取请求是否返回过期状态。无论哪种情况，过期状态都会在之后立即被删除。虽然返回已经过期的状态有利于数据可用性，但不返回过期状态更符合相关数据保护法规的要求。*哪种时间语义被用于定义生存时间？ 在Apache Flink 1.8.0中，用户只能根据处理时间（Processing Time）定义状态生存时间。未来的Flink版本中计划支持事件时间（Event Time）。在实现上，状态生存时间特性会额外存储上一次相关状态访问的时间戳。虽然这种方法增加了一些存储开销，但它允许Flink在访问状态、创建检查点、恢复或存储清理过程时可以检查过期状态。3.堆内存状态后端的增量清理适用于堆内存状态后端（FsStateBackend和MemoryStateBackend）。其基本思路是在存储后端的所有状态条目上维护一个全局的惰性迭代器。某些事件（例如状态访问）会触发增量清理，而每次触发增量清理时，迭代器都会向前遍历删除已遍历的过期数据。》注意：首先是增量清理所花费的时间会增加记录处理的延迟。其次，如果没有状态被访问（state accessed）或者没有记录被处理（record processed），过期的状态也将不会被删除。4.RocksDB状态后端利用后台压缩来清理过期状态该策略基于Flink定制的RocksDB压缩过滤器（compaction filter）。RocksDB会定期运行异步的压缩流程以合并数据并减少相关存储的数据量，该定制的压缩过滤器使用生存时间检查状态条目的过期时间戳，并丢弃所有过期值。》注意：启用Flink的生存时间压缩过滤机制后，会放缓RocksDB的压缩速度。4.也可以使用定时器进行状态的清理</code></pre><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//当前是以RocksDB状态后端利用后台压缩来清理过期状态 为例的代码</span>    <span class="token keyword">val</span> ttlConfig <span class="token operator">=</span> StateTtlConfig      <span class="token punctuation">.</span>newBuilder<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>minutes<span class="token punctuation">(</span>parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"ttl-minutes"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">//更新当前时间戳之前，压缩过滤器要处理的状态条目数 默认值1000L</span>      <span class="token punctuation">.</span>cleanupInRocksdbCompactFilter<span class="token punctuation">(</span>parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"query-time-after-num-entries"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setTimeCharacteristic<span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>ProcessingTime<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setUpdateType<span class="token punctuation">(</span>StateTtlConfig<span class="token punctuation">.</span>UpdateType<span class="token punctuation">.</span>OnCreateAndWrite<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setStateVisibility<span class="token punctuation">(</span>StateTtlConfig<span class="token punctuation">.</span>StateVisibility<span class="token punctuation">.</span>NeverReturnExpired<span class="token punctuation">)</span>      <span class="token punctuation">.</span>build    <span class="token keyword">val</span> stateDescriptor <span class="token operator">=</span> <span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span>ArrayBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"state"</span><span class="token punctuation">,</span> createTypeInformation<span class="token punctuation">[</span>ArrayBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//开启状态生存时间</span>    stateDescriptor<span class="token punctuation">.</span>enableTimeToLive<span class="token punctuation">(</span>ttlConfig<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//开启状态client 可查询</span>    stateDescriptor<span class="token punctuation">.</span>setQueryable<span class="token punctuation">(</span><span class="token string">"state"</span><span class="token punctuation">)</span>    state <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getState<span class="token punctuation">(</span>stateDescriptor<span class="token punctuation">)</span></code></pre><h5 id="3-状态数据的使用"><a href="#3-状态数据的使用" class="headerlink" title="3.状态数据的使用"></a>3.状态数据的使用</h5><h4 id="flink-监控层面"><a href="#flink-监控层面" class="headerlink" title="flink 监控层面"></a>flink 监控层面</h4><h5 id><a href="#" class="headerlink" title></a></h5><h4 id="flink-延迟数据的处理"><a href="#flink-延迟数据的处理" class="headerlink" title="flink 延迟数据的处理"></a>flink 延迟数据的处理</h4><p>Watermark机制假设在某个时间点上，不会有比这个时间点更晚的上报数据，常被作为一个时间窗口的结束时间，</p><blockquote><p>生成WaterMaker</p></blockquote><pre><code>流数据中的事件时间戳与Watermark高度相关，事件时间戳的抽取和Watermark的生成也基本是同时进行的，抽取的过程会遇到下面两种情况：1.数据流中已经包含了事件时间戳和Watermark。2.使用抽取算子生成事件时间戳和Watermark，这也是实际应用中更为常见的场景。因为后续的计算都依赖时间，抽取算子最好在数据接入后马上使用。具体而言，抽取算子包含两个函数：第一个函数从数据流的事件中抽取时间戳，并将时间戳赋值到事件的元数据上，第二个函数生成Watermark。</code></pre><h4 id="flink-streamAPI层面"><a href="#flink-streamAPI层面" class="headerlink" title="flink streamAPI层面"></a>flink streamAPI层面</h4><h5 id="1-source-和-sink-常用"><a href="#1-source-和-sink-常用" class="headerlink" title="1.source 和 sink 常用"></a>1.source 和 sink 常用</h5><blockquote><p>source         </p><blockquote><ol><li>flink kafka connector</li></ol><ul><li>基本设置：</li></ul></blockquote></blockquote><pre><code>1.因为 kafka 中数据都是以二进制 byte 形式存储的。读到 Flink 系统中之后，需要将二进制数据转化为具体的 java、scala 对象。具体需要实现一个 schema 类，定义如何序列化和反序列数据，flink 也提供了常用的序列化反序列化的schema类，例如SimpleStringSchema（按字符串方式进行序列化、反序列化），JsonDeserializationSchema 使用 jackson 反序列化 json 格式消息，并返回 ObjectNode，可以使用 .get(“property”) 方法来访问相应字段。2.消费起始位置设置 2.1 setStartFromLatest: 设置最新位置开始读。 2.2 setStartFromEarliest: 设置最早位置开始读. 2.3 setStartFromGroupOffsets: 也是默认的策略，从 group offset 位置读取数据，group offset 指的是 kafka broker 端记录的某个 group 的最后一次的消费位置。但是 kafka broker 端没有该 group 信息，会根据 kafka 的参数&quot;auto.offset.reset&quot;的设置来决定从哪个位置开始消费.注意事项：作业故障从savepoint自动恢复时，以及手动做savepoint时，消费位置从保存状态中恢复，与上面的起始位置设置无关。因为Flink Kafka Consumer 不依赖于提交的 offset 来实现容错保证。提交的 offset 只是一种方法，用于公开 consumer 的进度以便进行监控。3.setCommitOffsetsOnCheckpoints(true)时 会将偏移量提交到checkpoint快照的状态数据中。4.other 配置： 4.1 flink.poll-timeout:配置轮询的超时时间。如果没有可用数据，则等待轮询所需的时间 默认是100毫秒 4.2 flink.partition-discovery.interval-millis 设置参数为非负值，表示开启动态发现的开关，以及设置的时间间隔，下面会以场景的形式进行讲解,也就是下面要说的topic 和 partition 的动态发现。5.topic 和 partition 动态发现    场景一：有一个 Flink 作业需要将五份数据聚合到一起，五份数据对应五个 kafka topic，随着业务增长，新增一类数据，同时新增了一个 kafka topic，如何在不重启作业的情况下作业自动感知新的 topic。    场景二：作业从一个固定的 kafka topic 读数据，开始该 topic 有 10 个 partition，但随着业务的增长数据量变大，需要对 kafka partition 个数进行扩容，由 10 个扩容到 20。该情况下如何在不重启作业情况下动态感知新扩容的 partition？    针对上面两种场景，需要在构建 FlinkKafkaConsumer 时的 properties 中设置 flink.partition-discovery.interval-millis(默认为false) 参数为非负值，表示开启动态发现的开关，而设置的值为发现时间间隔。    原理：FlinkKafkaConsumer 内部会启动一个单独的线程定期去 kafka 获取最新的 meta 信息。    针对场景一：需在构建 FlinkKafkaConsumer 时，topic 的描述可以传一个正则表达式描述的 pattern。每次获取最新 kafka meta 时获取正则匹配的最新 topic 列表。    代码：    val topicStr = &quot;topic1&quot;    val topicPattern: Pattern = java.util.regex.Pattern.compile(&quot;topic[0-9]&quot;)    val consumer = new FlinkKafkaConsumer011[String](topicPattern, new SimpleStringSchema(), props)        针对场景二：设置前面的动态发现参数，在定期获取 kafka 最新 meta 信息时会匹配新的 partition。为了保证数据的正确性，新发现的 partition 从最早的位置开始读取    代码：在properties  设置 flink.partition-discovery.interval-millis:发现时间间隔（毫秒）6.commit offset 方式 提交 offset 的方式分为两种： checkpoint 关闭：        依赖kafka 客户端的auto commit定期提交。        需要设置 enable.auto.commit,auto.commit.interval.ms 参数到配置文件。 checkpoint 开启：构建source 时 setCommitOffsetsOnCheckpoints(true)          offset 自己在checkpoint state 中进行管理和维护。提交kafka offset 和ck时间一致，仅仅为了外部监控消费情况。         通过setCommitOffsetsOnCheckpoints 设置,ck成功后是否提交offset 到kafka 。7.Timestamp Extraction/Watermark 生成  我们知道当 Flink 作业内使用 EventTime 属性时，需要指定从消息中提取时戳和生成水位的函数。  FlinkKakfaConsumer 构造的 source 后直接调用 assignTimestampsAndWatermarks 函数设置水位生成器的好处是此时是每个 partition 一个 watermark assigner，  如下图。source 生成的时戳为多个 partition 时戳对齐后的最小时戳。此时在一个 source 读取多个 partition，并且 partition 之间数据时戳有一定差距的情况下，因为在 source 端 watermark 在 partition 级别有对齐，不会导致数据读取较慢 partition 数据丢失</code></pre><p><img src="https://pic3.zhimg.com/v2-c6614444177e3c59dc86123748db0b4a_r.jpg" alt="flink-kafka-consumer waterMaker"></p><pre><code>8.Producer 分区   8.1 FlinkKafkaProducer 往 kafka 中写数据时，如果不单独设置 partition 策略，会默认使用 FlinkFixedPartitioner，该 partitioner 分区的方式是 task 所在的并发 id 对 topic 总 partition 数取余：parallelInstanceId % partitions.length那么如果sink 的task 为4 partition 为2 则 4/2= 2 则2个并行度往2个partion 里写。那么如果sink 的task 为4 partition 为1 则 4/1= 4 则4个并行度往1个partion 里写。那么如果sink 的task 为2 partition 为4 则 2/4    则2个并行度往2个partion 里写，剩余两个partion 将没有数据。   8.2 构建 FlinkKafkaProducer 时，partition 设置为 null，此时会使用 kafka producer 默认分区方式，非 key 写入的情况下，使用 round-robin 的方式进行分区，每个 task 都会轮循的写下游的所有 partition。该方式下游的 partition 数据会比较均衡，但是缺点是 partition 个数过多的情况下需要维持过多的网络连接，即每个 task 都会维持跟所有 partition 所在 broker 的连接。9.连接kafka容错  Flink kafka 09、010 版本下通过 setLogFailuresOnly 为 false，setFlushOnCheckpoint 为 true，能达到 at-least-once 语义。  setLogFailuresOnly，默认为 false，是控制写 kafka 失败时，是否只打印失败的 log 不抛异常让作业停止。  setFlushOnCheckpoint，默认为 true，是控制是否在 checkpoint 时 fluse 数据到 kafka，保证数据已经写到 kafka。否则数据有可能还缓存在 kafka 客户端的 buffer 中，并没有真正写出到 kafka，此时作业挂掉数据即丢失，不能做到至少一次的语义。  Flink kafka 011 版本下，通过两阶段提交的 sink 结合 kafka 事务的功能，可以保证端到端精准一次 </code></pre><p><a href="https://www.ververica.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka" target="_blank" rel="noopener">flink到kafka精准一次</a></p><hr><blockquote><blockquote><ul><li>构建flink kafka source代码：</li></ul></blockquote></blockquote><pre class=" language-scala"><code class="language-scala"> <span class="token comment" spellcheck="true">//设置kafka</span><span class="token keyword">val</span> props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span>config<span class="token punctuation">.</span>getProperty<span class="token punctuation">(</span>BOOTSTRAP_SERVERS<span class="token punctuation">)</span><span class="token punctuation">)</span>props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"groupid"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">)</span>props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//获取kafka的数据源（如有特殊配制可以根据以上基本设置进行配置）</span><span class="token keyword">val</span> source <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaConsumer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>getProperty<span class="token punctuation">(</span>TOPIC<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setCommitOffsetsOnCheckpoints<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>name<span class="token punctuation">(</span><span class="token string">"topic-source"</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>uid<span class="token punctuation">(</span><span class="token string">"topic-source"</span><span class="token punctuation">)</span></code></pre><hr><blockquote><ol start="2"><li>flink mysql Async I/O 访问</li></ol></blockquote><blockquote><ol start="3"><li>flink redis Async I/O 访问</li></ol></blockquote><hr><blockquote><p>sink</p></blockquote><blockquote><blockquote><ol><li>flink sink kafka</li></ol></blockquote></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">val</span> stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">val</span> myProducer <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>        <span class="token string">"localhost:9092"</span><span class="token punctuation">,</span>         <span class="token comment" spellcheck="true">// broker 列表</span>        <span class="token string">"my-topic"</span><span class="token punctuation">,</span>               <span class="token comment" spellcheck="true">// 目标 topic</span>        <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">// 序列化 schema</span><span class="token comment" spellcheck="true">// 0.10+ 版本的 Kafka 允许在将记录写入 Kafka 时附加记录的事件时间戳；</span><span class="token comment" spellcheck="true">// 此方法不适用于早期版本的 Kafka</span>myProducer<span class="token punctuation">.</span>setWriteTimestampToKafka<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>stream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span>myProducer<span class="token punctuation">)</span></code></pre><hr><blockquote><blockquote><ol start="2"><li>flink sink cassandra</li></ol></blockquote></blockquote><blockquote><blockquote><ol start="3"><li>flink sink redis</li></ol></blockquote></blockquote><blockquote><blockquote><ol start="4"><li>flink sink hdfs</li></ol></blockquote></blockquote><blockquote><blockquote><ol start="5"><li>flink sink es</li></ol></blockquote></blockquote><hr><blockquote><p>side outPut的使用</p></blockquote><pre><code>除了DataStream操作产生的主流之外，您还可以产生任意数量的附加副输出结果流。结果流中的数据类型不必与主流中的数据类型匹配，并且不同侧输出的类型也可以不同。</code></pre><hr><h5 id="2-ProcessFunction-的使用"><a href="#2-ProcessFunction-的使用" class="headerlink" title="2.ProcessFunction 的使用"></a>2.ProcessFunction 的使用</h5><h5 id="3-异步加载外部数据"><a href="#3-异步加载外部数据" class="headerlink" title="3.异步加载外部数据"></a>3.异步加载外部数据</h5><h5 id="4-缓存配置文件数据"><a href="#4-缓存配置文件数据" class="headerlink" title="4.缓存配置文件数据"></a>4.缓存配置文件数据</h5><pre class=" language-scala"><code class="language-scala">env<span class="token punctuation">.</span>registerCachedFile<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'myFileCache'</span><span class="token punctuation">)</span>在富函数的open方法中进行获取 <span class="token keyword">val</span> myFile <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getDistributedCache<span class="token punctuation">.</span>getFile<span class="token punctuation">(</span><span class="token string">'MyTestFile'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//flink支持将变量广播到worker上，以供程序运算使用。</span></code></pre><h4 id="flink-应对数据解析"><a href="#flink-应对数据解析" class="headerlink" title="flink 应对数据解析"></a>flink 应对数据解析</h4><blockquote><p>判断数据是否为空</p></blockquote><pre><code> StringUtils.isNotBlank(data)</code></pre><blockquote><p>如果有就获取，没有就为默认值</p></blockquote><pre class=" language-scala"><code class="language-scala"> person<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>name<span class="token punctuation">)</span></code></pre><blockquote><p>时间解析 以秒为单位</p></blockquote><pre class=" language-scala"><code class="language-scala"> <span class="token comment" spellcheck="true">//解析格式以秒为单位的数字事件时间字段，如果解析异常，则用当前系统时间代替，返回秒</span> <span class="token keyword">def</span> parseTimestamp<span class="token punctuation">(</span>timestamp<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token punctuation">{</span>    timestamp<span class="token punctuation">.</span>toLong  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> e<span class="token operator">:</span> Exception <span class="token keyword">=></span>      logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>s<span class="token string">"Parsing event time exception: ${e.getMessage}"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>      System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>  <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">//解析格式为yyyy-MM-dd HH:mm:ss的事件时间字段，如果解析异常，则用当前系统事件代替，返回毫秒</span> <span class="token keyword">def</span> parseDateTime<span class="token punctuation">(</span>dateTime<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token punctuation">{</span>    DateTimeFormat<span class="token punctuation">.</span>forPattern<span class="token punctuation">(</span><span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>withZone<span class="token punctuation">(</span>DateTimeZone<span class="token punctuation">.</span>forID<span class="token punctuation">(</span><span class="token string">"+08:00"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parseDateTime<span class="token punctuation">(</span>dateTime<span class="token punctuation">)</span><span class="token punctuation">.</span>getMillis  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> e<span class="token operator">:</span> Exception <span class="token keyword">=></span>      logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>s<span class="token string">"Parsing event time exception: ${e.getMessage}"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>      System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span></code></pre><blockquote><p>加载配置文件</p></blockquote><pre class=" language-scala"><code class="language-scala"> <span class="token keyword">def</span> loadConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> p <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> in <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getClassLoader<span class="token punctuation">.</span>getResourceAsStream<span class="token punctuation">(</span><span class="token string">"config.properties"</span><span class="token punctuation">)</span>    p<span class="token punctuation">.</span>load<span class="token punctuation">(</span>in<span class="token punctuation">)</span>    in<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    p  <span class="token punctuation">}</span></code></pre><blockquote><p>切分日志 split</p></blockquote><pre class=" language-scala"><code class="language-scala">  <span class="token comment" spellcheck="true">//按照制表符切割日志</span>  <span class="token keyword">val</span> splitter <span class="token operator">=</span> Pattern<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span>  <span class="token keyword">def</span> split<span class="token punctuation">(</span>log<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    splitter<span class="token punctuation">.</span>split<span class="token punctuation">(</span>log<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span></code></pre><blockquote><p>josn 的解析（alibaba.fastjson）</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">val</span> tmp <span class="token operator">=</span> <span class="token keyword">try</span><span class="token punctuation">{</span>  <span class="token comment" spellcheck="true">//将json 转化为对象，并获取name 字段的字符串值</span>  JSON<span class="token punctuation">.</span>parseObject<span class="token punctuation">(</span>template<span class="token punctuation">)</span><span class="token punctuation">.</span>getString<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">{</span><span class="token keyword">case</span> e<span class="token operator">:</span>Exception <span class="token keyword">=></span>     logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>s<span class="token string">"Parsing json from template field occur exception: ${e.getMessage}"</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span>    <span class="token string">""</span><span class="token punctuation">}</span></code></pre><blockquote><p>正则表达式对设备id 的匹配</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">val</span> deviceIdReg <span class="token operator">=</span> <span class="token string">"^[0-9a-fA-F]{8}(-[0-9a-fA-F]{4}){3}-[0-9a-fA-F]{12}$"</span><span class="token punctuation">.</span>r<span class="token keyword">def</span> filterDeviceId<span class="token punctuation">(</span>deviceId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    deviceIdReg<span class="token punctuation">.</span>findFirstMatchIn<span class="token punctuation">(</span>deviceId<span class="token punctuation">)</span><span class="token punctuation">.</span>isDefined <span class="token operator">&amp;&amp;</span> deviceId <span class="token operator">!=</span> <span class="token string">"00000000-0000-0000-0000-000000000000"</span>  <span class="token punctuation">}</span></code></pre><blockquote><p>组合字符</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">private</span> <span class="token keyword">val</span> joiner <span class="token operator">=</span> Joiner<span class="token punctuation">.</span>on<span class="token punctuation">(</span><span class="token string">"^"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>useForNull<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token keyword">def</span> join<span class="token punctuation">(</span>str1<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> str2<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> str<span class="token operator">:</span> <span class="token builtin">String</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    joiner<span class="token punctuation">.</span>join<span class="token punctuation">(</span>str1<span class="token punctuation">,</span> str2<span class="token punctuation">,</span> str<span class="token operator">:</span> _<span class="token operator">*</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// result = A^B^C^D</span> <span class="token keyword">val</span> result <span class="token operator">=</span> join<span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">)</span></code></pre><blockquote><p>构建测试类测试数据解析是否正常</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">import</span> org<span class="token punctuation">.</span>scalatest<span class="token punctuation">.</span>FunSuite<span class="token keyword">import</span> scala<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Source<span class="token keyword">class</span> ScalaTest <span class="token keyword">extends</span> FunSuite <span class="token punctuation">{</span>    test<span class="token punctuation">(</span><span class="token string">"test-parser-data"</span><span class="token punctuation">)</span><span class="token punctuation">{</span>          <span class="token keyword">val</span> dataFilter <span class="token operator">=</span> <span class="token keyword">new</span> DataFilter          <span class="token keyword">val</span> file<span class="token operator">=</span>Source<span class="token punctuation">.</span>fromFile<span class="token punctuation">(</span><span class="token string">"local_file_path"</span><span class="token punctuation">)</span>          <span class="token keyword">val</span> lines <span class="token operator">=</span> file<span class="token punctuation">.</span>getLines        <span class="token keyword">var</span> counter<span class="token punctuation">,</span>total <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>line <span class="token keyword">&lt;-</span> lines<span class="token punctuation">)</span><span class="token punctuation">{</span>            total <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>dataFilter<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                counter <span class="token operator">+=</span> <span class="token number">1</span>                <span class="token keyword">val</span> data <span class="token operator">=</span> 解析完的数据。                printBean<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            <span class="token punctuation">}</span>         <span class="token punctuation">}</span>         println<span class="token punctuation">(</span><span class="token string">"-"</span><span class="token operator">*</span><span class="token number">10</span><span class="token operator">+</span><span class="token string">"counter="</span><span class="token operator">+</span>counter <span class="token operator">+</span><span class="token string">",total="</span><span class="token operator">+</span> total<span class="token punctuation">)</span>         file<span class="token punctuation">.</span>close     <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><blockquote><p>加载定时加载外部数据</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//设置当前的线程数</span>  <span class="token keyword">var</span> countDown<span class="token operator">:</span> CountDownLatch <span class="token operator">=</span> <span class="token keyword">new</span> CountDownLatch<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token annotation punctuation">@volatile</span> <span class="token keyword">var</span> resultData<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> _  <span class="token keyword">def</span> getUccrAndKvAndDefalut<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>countDown<span class="token punctuation">.</span>getCount <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      countDown<span class="token punctuation">.</span>await<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    resultData  <span class="token punctuation">}</span>  <span class="token comment" spellcheck="true">//创建调度器</span>  <span class="token keyword">var</span> executor<span class="token operator">:</span> ScheduledExecutorService <span class="token operator">=</span> Executors<span class="token punctuation">.</span>newSingleThreadScheduledExecutor<span class="token punctuation">(</span>    <span class="token keyword">new</span> ThreadFactoryBuilder<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>setDaemon<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>setNameFormat<span class="token punctuation">(</span><span class="token string">"loaderData-%d"</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>build<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">// 开始调度 一开始就执行，每三分钟调度一次</span>  executor<span class="token punctuation">.</span>scheduleAtFixedRate<span class="token punctuation">(</span><span class="token keyword">new</span> Runnable <span class="token punctuation">{</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> run<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>      loadData<span class="token punctuation">(</span><span class="token punctuation">)</span>      logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Sync resultData from filesystem complete"</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>MINUTES<span class="token punctuation">)</span> <span class="token keyword">def</span> loadData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    resultData <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">"1"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"A"</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> <span class="token punctuation">(</span>countDown<span class="token punctuation">.</span>getCount <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      countDown<span class="token punctuation">.</span>countDown<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span> <span class="token punctuation">}</span></code></pre><h4 id="flink-排查问题层面"><a href="#flink-排查问题层面" class="headerlink" title="flink 排查问题层面"></a>flink 排查问题层面</h4><h5 id="1-查看-flinkUI-的监控"><a href="#1-查看-flinkUI-的监控" class="headerlink" title="1.查看 flinkUI 的监控"></a>1.查看 flinkUI 的监控</h5><pre><code>1.查看当前作业运行的状态2.如果有checkpoint 快照，首先查看快照是否按照约定的时间触发。3.查看作业是否有背压。-&gt;根据拓扑结构定位错误位置，查看哪里数据产生堆积。4.在EXception 处查看是否有异常信息。5.如果on yarn 上，可以查看container 和 jobmanager的log 来定位错误。</code></pre><hr><h5 id="2-查看kafka-监控，看是否offset-没有提交数据消费延迟"><a href="#2-查看kafka-监控，看是否offset-没有提交数据消费延迟" class="headerlink" title="2.查看kafka 监控，看是否offset 没有提交数据消费延迟"></a>2.查看kafka 监控，看是否offset 没有提交数据消费延迟</h5><blockquote><p>promethus 抓取kafka 的信息，并通过grafana 展现出来。</p></blockquote><hr><h5 id="3-如果发现subTask-有问题，怎么排查"><a href="#3-如果发现subTask-有问题，怎么排查" class="headerlink" title="3.如果发现subTask 有问题，怎么排查"></a>3.如果发现subTask 有问题，怎么排查</h5><p>基本思路是根据restApi来定位:<br><a href="https://juejin.im/post/5d973af2518825096a1874f4" target="_blank" rel="noopener">Flink定位SubTask在哪台机器哪个进程执行</a></p><h5 id="4-keyby-的数据倾斜了怎么办"><a href="#4-keyby-的数据倾斜了怎么办" class="headerlink" title="4.keyby 的数据倾斜了怎么办"></a>4.keyby 的数据倾斜了怎么办</h5><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//1. 将值进行hash</span><span class="token comment" spellcheck="true">//将keyData 进行hash</span>    <span class="token keyword">val</span> hashCode<span class="token operator">:</span> HashCode <span class="token operator">=</span> Hashing<span class="token punctuation">.</span>murmur3_32<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>hashString<span class="token punctuation">(</span>keyData<span class="token punctuation">,</span> Charset<span class="token punctuation">.</span>forName<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>hashCode<span class="token punctuation">.</span>hashCode<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> Integer<span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">,</span> hashCode<span class="token punctuation">.</span>toString<span class="token punctuation">)</span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;flink-基础配置层面&quot;&gt;&lt;a href=&quot;#flink-基础配置层面&quot; class=&quot;headerlink&quot; title=&quot;flink 基础配置层面&quot;&gt;&lt;/a&gt;flink 基础配置层面&lt;/h4&gt;&lt;h5 id=&quot;1-flink-conf-yaml-配置优化&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="flink" scheme="https://BradyYue.github.io/categories/flink/"/>
    
    
      <category term="flink-优化篇" scheme="https://BradyYue.github.io/tags/flink-%E4%BC%98%E5%8C%96%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>博客编写思路</title>
    <link href="https://BradyYue.github.io/2019/12/17/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E6%80%9D%E8%B7%AF/"/>
    <id>https://BradyYue.github.io/2019/12/17/博客编写思路/</id>
    <published>2019-12-17T01:13:40.000Z</published>
    <updated>2020-01-07T09:01:14.977Z</updated>
    
    <content type="html"><![CDATA[<h4 id="博客类型分类"><a href="#博客类型分类" class="headerlink" title="博客类型分类"></a>博客类型分类</h4><h5 id="常用篇"><a href="#常用篇" class="headerlink" title="常用篇"></a>常用篇</h5><blockquote><p>主要介绍本知识点和框架常用到的命令和技巧，以及需要注意的事项。</p></blockquote><h5 id="学习篇"><a href="#学习篇" class="headerlink" title="学习篇"></a>学习篇</h5><blockquote><p>主要介绍本知识点和框架的3W， who 是什么，where 应用场景， what 怎么用比较好。</p></blockquote><h5 id="问题篇"><a href="#问题篇" class="headerlink" title="问题篇"></a>问题篇</h5><blockquote><p>在使用本知识点或框架中遇到的问题。</p></blockquote><h5 id="资料篇"><a href="#资料篇" class="headerlink" title="资料篇"></a>资料篇</h5><blockquote><p>扩展本知识点或架构的其他比较好的学习资料。</p></blockquote><h5 id="优化篇"><a href="#优化篇" class="headerlink" title="优化篇"></a>优化篇</h5><blockquote><p>主要编写的是当前组件或架构可优化点。</p></blockquote><h5 id="实战篇"><a href="#实战篇" class="headerlink" title="实战篇"></a>实战篇</h5><blockquote><p>主要演示在知识点实际搭建过程中的操作。</p></blockquote><h5 id="other"><a href="#other" class="headerlink" title="other"></a>other</h5><blockquote><p>主要是小的知识点分类，比如java-JVM篇，java-cache篇，java-多线程篇</p></blockquote><h4 id="博客思想"><a href="#博客思想" class="headerlink" title="博客思想"></a>博客思想</h4><blockquote><p>本站博客，是以练促学，以学促用的理念来进行编写，当然为了取其精华去其糟粕，博客中也会引用总结其他大牛比较好的内容，用来学习。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;博客类型分类&quot;&gt;&lt;a href=&quot;#博客类型分类&quot; class=&quot;headerlink&quot; title=&quot;博客类型分类&quot;&gt;&lt;/a&gt;博客类型分类&lt;/h4&gt;&lt;h5 id=&quot;常用篇&quot;&gt;&lt;a href=&quot;#常用篇&quot; class=&quot;headerlink&quot; title=&quot;常用篇
      
    
    </summary>
    
      <category term="博客编写思路" scheme="https://BradyYue.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E6%80%9D%E8%B7%AF/"/>
    
    
      <category term="博客编写思路" scheme="https://BradyYue.github.io/tags/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E6%80%9D%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>java-cache篇</title>
    <link href="https://BradyYue.github.io/2019/12/17/java-cache%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/17/java-cache篇/</id>
    <published>2019-12-16T23:54:44.000Z</published>
    <updated>2019-12-18T06:48:07.391Z</updated>
    
    <content type="html"><![CDATA[<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p> 首先要有意识的进行缓存的使用。在某值多次使用的时候，可以考虑把当前值获取到并放到缓存中去，使得数据在内存中获取，而非外部存储，能极大提高数据获取的速度。但要注意缓存数据的容量大小。</p><h4 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h4><blockquote><p>构建缓存</p></blockquote><pre><code> var cache: Cache[String, String] = CacheBuilder.newBuilder()    .expireAfterAccess(30, TimeUnit.MINUTES)   //过期时间    .maximumSize(30000) //最大条数    .build()</code></pre><blockquote><p>获取缓存，如果没有则进行计算 或者用getIfPresent 获取缓存</p></blockquote><pre><code>try {    // If the key wasn&#39;t in the &quot;easy to compute&quot; group, we need to    // do things the hard way.    cache.get(key, () -&gt;  doThingsTheHardWay(key));} catch (ExecutionException e) {    throw new OtherException(e.getCause());}</code></pre><blockquote><p>使用cache.put(key, value)方法可以直接向缓存中插入值，这会直接覆盖掉给定键之前映射的值</p></blockquote><hr><blockquote><p>缓存收回策略 ： </p><blockquote><p>1.基于容量的回收（size-based eviction）</p></blockquote></blockquote><pre><code>使用CacheBuilder.maximumSize(long)缓存将尝试回收最近没有使用或总体上很少使用的缓存项。警告：在缓存项的数目达到限定值之前，缓存就可能进行回收操作,通常来说，这种情况发生在缓存项的数目逼近限定值时</code></pre><blockquote><blockquote><p>2.定时回收（Timed Eviction）</p></blockquote></blockquote><pre><code>1.expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于容量回收一样2.expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。</code></pre><blockquote><blockquote><p>3.基于引用的回收（Reference-based Eviction）</p></blockquote></blockquote><pre><code>通过弱引用的键或者弱引用的值，或者软引用的值，guava Cache可以把缓存设置为允许垃圾回收1.CacheBuilder.weakKeys():使用过弱引用存储键值。当被垃圾回收的时候，当前键值没有其他引用的时候缓存项可以被垃圾回收。2.CacheBuilder.weakValues():使用弱引用存储值。3.CacheBuilder.softValues():使用软引用存储值。软引用就是在内存不够是才会按照顺序回收。</code></pre><hr><h5 id="缓存数据的清除"><a href="#缓存数据的清除" class="headerlink" title="缓存数据的清除"></a>缓存数据的清除</h5><pre><code>个别清除：Cache.invalidate(key)批量清除：Cache.invalidateAll(keys)清除所有缓存项：Cache.invalidateAll()</code></pre><h5 id="刷新"><a href="#刷新" class="headerlink" title="刷新"></a>刷新</h5><blockquote><p>刷新操作进行时，缓存仍然可以向其他线程返回旧值，而不像回收操作，读缓存的线程必须等待新值加载完成</p></blockquote><blockquote><p>如果刷新过程抛出异常，缓存将保留旧值，而异常会在记录到日志后被丢弃[swallowed]。</p></blockquote><blockquote><p>重载CacheLoader.reload(K, V)可以扩展刷新时的行为，这个方法允许开发者在计算新值时使用旧的值。</p></blockquote><pre><code>//有些键不需要刷新，并且我们希望刷新是异步完成的LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder()        .maximumSize(1000)        .refreshAfterWrite(1, TimeUnit.MINUTES)        .build(            new CacheLoader&lt;Key, Graph&gt;() {                public Graph load(Key key) { // no checked exception                    return getGraphFromDatabase(key);                }                public ListenableFuture&lt;Key, Graph&gt; reload(final Key key, Graph prevGraph) {                    if (neverNeedsRefresh(key)) {                        return Futures.immediateFuture(prevGraph);                    }else{                        // asynchronous!                        ListenableFutureTask&lt;Key, Graph&gt; task=ListenableFutureTask.create(new Callable&lt;Key, Graph&gt;() {                            public Graph call() {                                return getGraphFromDatabase(key);                            }                        });                        executor.execute(task);                        return task;                    }                }            });</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;使用场景&quot;&gt;&lt;a href=&quot;#使用场景&quot; class=&quot;headerlink&quot; title=&quot;使用场景&quot;&gt;&lt;/a&gt;使用场景&lt;/h4&gt;&lt;p&gt; 首先要有意识的进行缓存的使用。在某值多次使用的时候，可以考虑把当前值获取到并放到缓存中去，使得数据在内存中获取，而非外部存
      
    
    </summary>
    
      <category term="java" scheme="https://BradyYue.github.io/categories/java/"/>
    
    
      <category term="java cache" scheme="https://BradyYue.github.io/tags/java-cache/"/>
    
  </entry>
  
  <entry>
    <title>azkaban-剖析篇</title>
    <link href="https://BradyYue.github.io/2019/12/10/azkaban-%E5%89%96%E6%9E%90%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/10/azkaban-剖析篇/</id>
    <published>2019-12-10T08:34:59.000Z</published>
    <updated>2019-12-17T01:06:34.130Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-Azkaban-前后台参数传递"><a href="#1-Azkaban-前后台参数传递" class="headerlink" title="1.Azkaban-前后台参数传递"></a>1.Azkaban-前后台参数传递</h4><blockquote></blockquote><h4 id="2-Azkaban-用户登录过程"><a href="#2-Azkaban-用户登录过程" class="headerlink" title="2.Azkaban-用户登录过程"></a>2.Azkaban-用户登录过程</h4><blockquote><p>1.用户登录时，首先通过LoginAbstractAzkabanServlet 中的handleAjaxLoginAction 方法进行用户信息处理和认证。</p></blockquote><pre><code>protected void handleAjaxLoginAction(HttpServletRequest req,      HttpServletResponse resp, Map&lt;String, Object&gt; ret)      throws ServletException {    if (hasParam(req, &quot;username&quot;) &amp;&amp; hasParam(req, &quot;password&quot;)) {      Session session = null;      try {              //创建session 进行用户的认证        session = createSession(req);      } catch (UserManagerException e) {        ret.put(&quot;error&quot;, &quot;Incorrect Login. &quot; + e.getMessage());        return;      }      Cookie cookie = new Cookie(SESSION_ID_NAME, session.getSessionId());      cookie.setPath(&quot;/&quot;);      resp.addCookie(cookie);      getApplication().getSessionCache().addSession(session);      ret.put(&quot;status&quot;, &quot;success&quot;);      ret.put(&quot;session.id&quot;, session.getSessionId());    } else {      ret.put(&quot;error&quot;, &quot;Incorrect Login.&quot;);    }  }</code></pre><blockquote><p>2.createSession的验证和创建过程：</p></blockquote><pre><code>private Session createSession(String username, String password, String ip)     throws UserManagerException, ServletException {   UserManager manager = getApplication().getUserManager();   User user = manager.getUser(username, password);   String randomUID = UUID.randomUUID().toString();   Session session = new Session(randomUID, user, ip);   return session; }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-Azkaban-前后台参数传递&quot;&gt;&lt;a href=&quot;#1-Azkaban-前后台参数传递&quot; class=&quot;headerlink&quot; title=&quot;1.Azkaban-前后台参数传递&quot;&gt;&lt;/a&gt;1.Azkaban-前后台参数传递&lt;/h4&gt;&lt;blockquote&gt;

      
    
    </summary>
    
      <category term="azkaban" scheme="https://BradyYue.github.io/categories/azkaban/"/>
    
    
      <category term="azkaban" scheme="https://BradyYue.github.io/tags/azkaban/"/>
    
  </entry>
  
  <entry>
    <title>httpd-常用篇</title>
    <link href="https://BradyYue.github.io/2019/12/10/httpd-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/12/10/httpd-常用篇/</id>
    <published>2019-12-10T05:53:26.000Z</published>
    <updated>2019-12-17T02:28:53.766Z</updated>
    
    <content type="html"><![CDATA[<h4 id="httpd-服务简介"><a href="#httpd-服务简介" class="headerlink" title="httpd 服务简介"></a>httpd 服务简介</h4><hr><h4 id="2-httpd-作为文件服务的使用"><a href="#2-httpd-作为文件服务的使用" class="headerlink" title="2.httpd 作为文件服务的使用"></a>2.httpd 作为文件服务的使用</h4><blockquote><p>安装使用</p></blockquote><pre><code>#安装sudo yum install httpdsudo su#测试配置是否正常httpd -t#starthttpd -k start#stophttpd -k stop</code></pre><blockquote><p>服务目录    /etc/httpd</p></blockquote><blockquote><p>主配置文件    /etc/httpd/conf/httpd.conf</p></blockquote><blockquote><p>网站数据目录    /var/www/html</p></blockquote><blockquote><p>访问日志    /var/log/httpd/access_log</p></blockquote><blockquote><p>错误日志    /var/log/httpd/error_log</p></blockquote><p><a href=".httpd.png">配置结构</a></p><table><thead><tr><th>ServerRoot</th><th>服务目录</th></tr></thead><tbody><tr><td>ServerAdmin</td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr></tbody></table><blockquote><p>对服务机地址目录启动成文件访问服务</p></blockquote><hr><h4 id="3-Httpd-集成ldap"><a href="#3-Httpd-集成ldap" class="headerlink" title="3.Httpd 集成ldap"></a>3.Httpd 集成ldap</h4><blockquote><p>集成前需安装 mod_ldap</p></blockquote><pre><code>sudo suyum -y install mod_ldap</code></pre><blockquote><p>vim conf.d/auth_ldap.conf</p></blockquote><pre><code>&lt;Directory /data/dataplatform/zepplin/http_server/file/&gt;# AuthName &quot;LDAP Authentication&quot;AuthName &quot;zeppelin_file&quot;AuthType BasicAuthBasicProvider ldapAuthLDAPURL &quot;ldap://*****:389/ou=acs,dc=****,dc=com?uid?sub?(objectClass=*)&quot;AuthLDAPBindDN &quot;uid=gateway,ou=open,dc=****,dc=com&quot;AuthLDAPBindPassword &quot;********&quot;Require valid-user&lt;/Directory&gt;</code></pre><blockquote><p>测试配置是否异常 httpd -t</p></blockquote><blockquote><p>重启 httpd -k restart</p></blockquote><h4 id="相关参考"><a href="#相关参考" class="headerlink" title="相关参考"></a>相关参考</h4><blockquote><p><a href="https://www.bookstack.cn/read/linuxprobe/5bb5cdfbbed75940.md" target="_blank" rel="noopener">配置参考地址</a></p></blockquote><blockquote><p><a href="https://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">Apache http 服务器2.4 文档</a></p></blockquote><blockquote><p><a href="https://httpd.apache.org/download.cgi" target="_blank" rel="noopener">download</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;httpd-服务简介&quot;&gt;&lt;a href=&quot;#httpd-服务简介&quot; class=&quot;headerlink&quot; title=&quot;httpd 服务简介&quot;&gt;&lt;/a&gt;httpd 服务简介&lt;/h4&gt;&lt;hr&gt;
&lt;h4 id=&quot;2-httpd-作为文件服务的使用&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="httpd" scheme="https://BradyYue.github.io/categories/httpd/"/>
    
    
      <category term="httpd" scheme="https://BradyYue.github.io/tags/httpd/"/>
    
  </entry>
  
  <entry>
    <title>k8s-问题篇</title>
    <link href="https://BradyYue.github.io/2019/11/12/k8s-%E9%97%AE%E9%A2%98%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/11/12/k8s-问题篇/</id>
    <published>2019-11-12T06:16:23.000Z</published>
    <updated>2019-12-18T06:52:08.313Z</updated>
    
    <content type="html"><![CDATA[<p>####1. Unable to connect to the server: dial tcp 192.168.99.100:8443: connect: no route to host</p><blockquote><p>问题原因：<br>     链接不上服务地址，可能是机器没有启动，或者节点已经丢失。</p></blockquote><blockquote><p>解决方案：<br>    查看运行状态 minikube status<br>     启动机器（测试虚拟机）</p></blockquote><hr><p>####2. error: unable to forward port because pod is not running. Current status=Pending</p><blockquote><p>查看问题：<br>  kubectl get nodes 首先查看node 是不是Ready 状态<br>  kubectl get pods (查看当前的pods)<br>  kubectl describe nodes （查看node 的vm 详细信息）<br>  kubectl get services (查看运行服务)</p></blockquote><hr><p>####3. Kube-proxy: error looking for path of conntrack</p><blockquote><p>kube-proxy 报错，并且 service 的 DNS 解析异常</p></blockquote><pre><code> kube-proxy[2241]: E0502 15:55:13.889842    2241 conntrack.go:42]  conntrack returned error: error looking for path of conntrack: exec: &quot;conntrack&quot;: executable file not found in $PATH</code></pre><blockquote><p>解决方式是安装 conntrack-tools 包后重启 kube-proxy 即可。</p></blockquote><hr><p>####4. “Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?”</p><blockquote><p>问题原因：是因为docker服务没有启动，所以在相应的/var/run/ 路径下找不到docker的进程。<br>解决方式：<br>   1.service docker start<br>   2.查看docker-machine是否安装。<br>  <a href="https://blog.csdn.net/Aaron_80726/article/details/83676014" target="_blank" rel="noopener">其他原因及解决方案</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;####1. Unable to connect to the server: dial tcp 192.168.99.100:8443: connect: no route to host&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;问题原因：&lt;br&gt;     链接不上服务地
      
    
    </summary>
    
      <category term="k8s" scheme="https://BradyYue.github.io/categories/k8s/"/>
    
    
      <category term="k8s-问题篇" scheme="https://BradyYue.github.io/tags/k8s-%E9%97%AE%E9%A2%98%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>k8s-实战篇</title>
    <link href="https://BradyYue.github.io/2019/10/25/k8s-%E5%AE%9E%E6%88%98%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/10/25/k8s-实战篇/</id>
    <published>2019-10-25T02:15:02.000Z</published>
    <updated>2019-12-20T07:49:13.680Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-kubectl-操作"><a href="#1-kubectl-操作" class="headerlink" title="1. kubectl 操作"></a>1. kubectl 操作</h4><h5 id="1-1-kubectl-配置"><a href="#1-1-kubectl-配置" class="headerlink" title="1.1 kubectl 配置"></a>1.1 kubectl 配置</h5><h5 id="1-3-kubectl-权限"><a href="#1-3-kubectl-权限" class="headerlink" title="1.3 kubectl 权限"></a>1.3 kubectl 权限</h5><pre><code>**********************# 权限问题 #*************************查看是否有权限：kubectl auth can-i &lt;list|create|edit|delete&gt; pods</code></pre><h5 id="1-4-kubectl-常用命令"><a href="#1-4-kubectl-常用命令" class="headerlink" title="1.4 kubectl 常用命令"></a>1.4 kubectl 常用命令</h5><pre><code>//批量删除所有的podkubectl get pods | grep Evicted | awk &#39;{print $1}&#39; | xargs kubectl delete pod</code></pre><h4 id="2-minikube操作"><a href="#2-minikube操作" class="headerlink" title="2. minikube操作"></a>2. minikube操作</h4><h5 id="2-1-minikube-安装"><a href="#2-1-minikube-安装" class="headerlink" title="2.1 minikube 安装"></a>2.1 minikube 安装</h5><blockquote><p>1.下载virtualbox</p></blockquote><blockquote><p>2.brew cask install minikube</p></blockquote><blockquote><p>3.minikube start –vm-driver=virtualbox</p></blockquote><blockquote><p>4.minikube config set vm-driver virtualbox</p></blockquote><blockquote><p>5.kubectl version 查看版本</p></blockquote><h5 id="2-2-minikube-常用操作"><a href="#2-2-minikube-常用操作" class="headerlink" title="2.2 minikube 常用操作"></a>2.2 minikube 常用操作</h5><pre><code>#启动并创建集群minikube start#查看仪表盘minikube dashboard#使用现有镜像kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.10#访问时将端口进行公开映射kubectl expose deployment hello-minikube --type=NodePort --port=8080#查看是否已经正在运行kubectl get pods#获取公开服务的URL以查看服务详细信息minikube service hello-minikube --url#curl 获取的url 查看本地集群的详细信息curl http://192.168.99.100:30083#删除 hello-minikube 服务kubectl delete services hello-minikube#删除 hello-minikube 部署kubectl delete deployment hello-minikube#停止本地minikube 集群minikube stop#删除本地minikube 集群minikube delete</code></pre><h5 id="2-3-minikube-的应用和服务"><a href="#2-3-minikube-的应用和服务" class="headerlink" title="2.3 minikube 的应用和服务"></a>2.3 minikube 的应用和服务</h5><pre><code>********************# 应用和服务 #*************#启动minikubeminikube start#部署应用kubectl run hello-minikube --image=k8s.gcr.io/echoserver:1.4 --port=8080#确定deploymentkubectl get deployment#查看部署的应用kubectl get pods#发布应用kubectl expose deployment hello-minikube --type=NodePort#查看发布的内容kubectl get services#访问服务1.虚拟机：curl http://ip:port2.curl $(minikube service hello-minikube --url)#获取服务url 链接minikube service --url service_name#查看控制台minikube dashboard查看所有Kubernetes Pod的部署状态kubectl get po -A#删除服务kubectl delete services hello-minikube#删除应用kubectl delete deployment hello-minikube#删除podskubectl delete pods podName#停止minikubeminikube stop#进入minikube 控制台minikube ssh</code></pre><hr><h5 id="2-4-minikube-集群相关"><a href="#2-4-minikube-集群相关" class="headerlink" title="2.4 minikube 集群相关"></a>2.4 minikube 集群相关</h5><pre><code>**********************# 集群相关 #**************************#获取集群的ipminikube ip#获取集群节点kubectl get nodes#启动第二个本地集群minikube start -p cluster2#停止本地集群minikube stop#删除本地集群minikube delete#删除所有本地集群和配置文件minikube delete --all获取网桥ipminikube ssh &quot;route -n | grep ^0.0.0.0 | awk &#39;{ print \$2 }&#39;&quot;链接到集群minikubeminikube sshtelnet ip port</code></pre><hr><h5 id="2-5-minikube-附加组件"><a href="#2-5-minikube-附加组件" class="headerlink" title="2.5 minikube 附加组件"></a>2.5 minikube 附加组件</h5><pre><code>********************************* 附加组件 ********************#查询可添加的组件minikube addons list#启用组件minikube addons enable &lt;name&gt;#与组件交互minikube addons open &lt;name&gt;#禁用组件minikube addons disable &lt;name&gt;</code></pre><hr><h5 id="2-6-minikube-调试"><a href="#2-6-minikube-调试" class="headerlink" title="2.6 minikube 调试"></a>2.6 minikube 调试</h5><pre><code>************************** 启动调试日志 *******************--v=0将输出INFO级别的日志--v=1将输出警告级别的日志--v=2将输出错误级别的日志--v=3将输出libmachine日志记录--v=7将输出libmachine –debug级日志记录minikube start --v=7 将启动minikube并将所有重要的调试日志输出到stdout#收集虚拟机日志，要调试Kubernetes部署失败的问题，收集Kubernetes pod和内核日志非常有用minikube logs#立即查看启动失败minikube logs --problems#查看所有Kubernetes Pod的部署状态kubectl get po -A</code></pre><h5 id="2-7-重用Docker-守护程序使用本地映像"><a href="#2-7-重用Docker-守护程序使用本地映像" class="headerlink" title="2.7 重用Docker 守护程序使用本地映像"></a>2.7 重用Docker 守护程序使用本地映像</h5><pre><code>eval $(minikube docker-env)docker ps</code></pre><hr><h4 id="4-学习案例"><a href="#4-学习案例" class="headerlink" title="4.学习案例"></a>4.学习案例</h4><h5 id="4"><a href="#4" class="headerlink" title="4."></a>4.</h5><hr><h4 id="5-kubectl应用和服务"><a href="#5-kubectl应用和服务" class="headerlink" title="5.kubectl应用和服务"></a>5.kubectl应用和服务</h4><hr><p>####6. </p><hr><h4 id="10-docker-常用操作"><a href="#10-docker-常用操作" class="headerlink" title="10.docker 常用操作"></a>10.docker 常用操作</h4><h5 id="10-1-镜像的操作"><a href="#10-1-镜像的操作" class="headerlink" title="10.1 镜像的操作"></a>10.1 镜像的操作</h5><pre><code>列出所有的镜像: docker images 停止运行：docker stop iamgesId删除单个镜像：docker rmi imagesId清理所有（慎用）：docker system pruneWARNING! This will remove:  - all stopped containers  - all networks not used by at least one container  - all dangling images  - all dangling build cache 清理镜像：docker image prune 清理容器：docker container prune 删除所有停止的镜像docker image prune -f -a 删除所有停止的容器：docker container prune -f复制文件：docker cp mycontainer:/opt/file.txt /opt/local/docker cp /opt/local/file.txt mycontainer:/opt/</code></pre><hr><h4 id="11-docker-常见问题及解决方案"><a href="#11-docker-常见问题及解决方案" class="headerlink" title="11.docker 常见问题及解决方案"></a>11.docker 常见问题及解决方案</h4><h5 id="11-1-docker日志太多导致磁盘占满"><a href="#11-1-docker日志太多导致磁盘占满" class="headerlink" title="11.1 docker日志太多导致磁盘占满"></a>11.1 docker日志太多导致磁盘占满</h5><blockquote><p>在启动时遇到：No space left on device 官方解决方案：<a href="https://success.docker.com/article/no-space-left-on-device-error" target="_blank" rel="noopener">地址</a></p></blockquote><pre><code>## 1.Sort the /var/lib/docker/containersdu -d1 -h /var/lib/docker/containers | sort -h## 2. 选择要清理的容器进行清理 cat /dev/null &gt;     /var/lib/docker/containers/********## 3.限制日志文件的大小：启动容器时，可以通过参数设置日志文件的大小、日志文件的格式 docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash</code></pre><h4 id="12-kubectl常用故障排查以及修改命令"><a href="#12-kubectl常用故障排查以及修改命令" class="headerlink" title="12.kubectl常用故障排查以及修改命令"></a>12.kubectl常用故障排查以及修改命令</h4><blockquote><p>scale </p></blockquote><pre><code>scale命令进行横向扩展，将原本为1的副本，提高到3kubectl scale --current-replicas=1 --replicas=3 deployment/nginx</code></pre><blockquote><p>autoscale</p></blockquote><pre><code>和scale不同的是autoscale则会根据负载进行调解kubectl autoscale deployment nginx --min=2 --max=5</code></pre><blockquote><p>cordon</p></blockquote><pre><code>查询nodeAddresskubectl get pods -o wide设定nodeAddress，使得nodeAddress不可使用，使用get node确认，其状态显示SchedulingDisabledkubectl cordon nodeAddress案例：设定134不可用：kubectl cordon 192.168.32.134横向扩展：kubectl scale --replicas=6 deployment/nginx发现没有pods 再执行在134这台机器上。</code></pre><blockquote><p>kubectl uncordon</p></blockquote><pre><code>解除限制kubectl uncordon nodeAddress</code></pre><blockquote><p>kubectl drain </p></blockquote><pre><code>drain命令用于对某个node进行设定，是为了设定此node为维护做准备。此命令主要执行的操作是：1. 设定此node不可以使用（cordon)2. evict（回收）了其上的两个pod</code></pre><blockquote><p>kubectl api-versions</p></blockquote><pre><code>查看当前版本的kubernetes的服务器端所支持的api版本信息</code></pre><blockquote><p>kubectl get all -o wide</p></blockquote><pre><code>列出pod services deployment replicaset 的信息</code></pre><blockquote><p>kubectl 可get 的信息</p></blockquote><pre><code>kubectl get deploymentskubectl get podskubectl get namespaces</code></pre><blockquote><p>kubectl 查看详情信息</p></blockquote><pre><code>kubectl describe node 192.168.32.132kubectl describe deployment mysql</code></pre><blockquote><p>kubectl 查看日志</p></blockquote><pre><code>kubectl logs podsName</code></pre><h4 id="13-学习案例2"><a href="#13-学习案例2" class="headerlink" title="13.学习案例2"></a>13.学习案例2</h4><pre><code>[root@node1 wordpress]# cat wordpress-db.yaml---apiVersion: apps/v1beta1kind: Deploymentmetadata:name: mysql-deploylabels:app: mysqlspec:template:metadata:labels:app: mysqlspec:containers:- name: mysqlimage: mysql:5.7imagePullPolicy: IfNotPresentports:- containerPort: 3306name: dbportenv:- name: MYSQL_ROOT_PASSWORDvalue: rootPassW0rd- name: MYSQL_DATABASEvalue: wordpress- name: MYSQL_USERvalue: wordpress- name: MYSQL_PASSWORDvalue: wordpressvolumeMounts:- name: dbmountPath: /var/lib/mysqlvolumes:- name: dbhostPath:path: /var/lib/mysql---apiVersion: v1kind: Servicemetadata:name: mysqlspec:selector:app: mysqlports:- name: mysqlportprotocol: TCPport: 3306targetPort: dbport[root@node1 wordpress]# cat wordpress.yamlapiVersion: apps/v1beta1kind: Deploymentmetadata:name: wordpress-deploylabels:app: wordpressspec:template:metadata:labels:app: wordpressspec:containers:- name: wordpressimage: wordpressimagePullPolicy: IfNotPresentports:- containerPort: 80name: wdportenv:- name: WORDPRESS_DB_HOSTvalue: mysql:3306- name: WORDPRESS_DB_USERvalue: wordpress- name: WORDPRESS_DB_PASSWORDvalue: wordpress---apiVersion: v1kind: Servicemetadata:name: wordpressspec:type: NodePortselector:app: wordpressports:- name: wordpressportprotocol: TCPport: 80targetPort: wdport#### 启动容器kubectl create -f wordpress-db.yamlkubectl create -f wordpress.yaml#### 查看集群信息kubectl get all -A -l app=wordpressNAMESPACE NAME READY STATUS RESTARTS AGEdefault pod/wordpress-deploy-f9c5cf5c6-tj2bc 1/1 Running 0 80mNAMESPACE NAME READY UP-TO-DATE AVAILABLE AGEdefault deployment.apps/wordpress-deploy 1/1 1 1 80mNAMESPACE NAME DESIRED CURRENT READY AGEdefault replicaset.apps/wordpress-deploy-f9c5cf5c6 1 1 1 80m#### 配置ingress[root@node1 wordpress]# cat ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata:name: wordpress-ingressnamespace: defaultannotations:kubernetes.io/ingress.class: &quot;nginx&quot;spec:rules:- host: wordpress.boshao.wanghttp:paths:- backend:serviceName: wordpressservicePort: 80#### 创建ingresskubectl create -f ingress.yaml#### 查看ingres信息[root@node1 wordpress]# kubectl get ing wordpress-ingressNAME HOSTS ADDRESS PORTS AGEwordpress-ingress wordpress.boshao.wang 80 78m[root@node1 wordpress]# kubectl describe ingress wordpress-ingressName: wordpress-ingressNamespace: defaultAddress:Default backend: default-http-backend:80 (&lt;none&gt;)Rules:Host Path Backends---- ---- --------wordpress.boshao.wangwordpress:80 (10.233.70.27:80)Annotations:kubernetes.io/ingress.class: nginxEvents: &lt;none&gt;#### 最后绑定域名wordpress.boshao.wang  到node节点即可。通过ingress-nginx 暴露的端口进行访问，即可。ingress-nginx service/ingress-nginx NodePort 10.233.29.94 &lt;none&gt; 80:31661/TCP,443:30250/TCP 6d2h访问方式：wordpress.boshao.wang → node ip:31661 http://wordpress.boshao.wang:31661/</code></pre><hr><h4 id="参考地址："><a href="#参考地址：" class="headerlink" title="参考地址："></a>参考地址：</h4><blockquote><p><a href="https://minikube.sigs.k8s.io/" target="_blank" rel="noopener">minikube参考</a></p></blockquote><blockquote><p><a href="https://k8smeetup.github.io/docs/user-guide/kubectl/v1.7/#-strong-getting-started-strong-" target="_blank" rel="noopener">命令查询</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-kubectl-操作&quot;&gt;&lt;a href=&quot;#1-kubectl-操作&quot; class=&quot;headerlink&quot; title=&quot;1. kubectl 操作&quot;&gt;&lt;/a&gt;1. kubectl 操作&lt;/h4&gt;&lt;h5 id=&quot;1-1-kubectl-配置&quot;&gt;&lt;a href
      
    
    </summary>
    
      <category term="k8s" scheme="https://BradyYue.github.io/categories/k8s/"/>
    
    
      <category term="k8s-实战篇" scheme="https://BradyYue.github.io/tags/k8s-%E5%AE%9E%E6%88%98%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>python-常用篇</title>
    <link href="https://BradyYue.github.io/2019/10/24/python-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/10/24/python-常用篇/</id>
    <published>2019-10-24T10:26:44.000Z</published>
    <updated>2019-12-11T01:59:05.491Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-pyenv-的使用"><a href="#1-pyenv-的使用" class="headerlink" title="1.pyenv 的使用"></a>1.pyenv 的使用</h4><pre><code> #查看python 版本信息   pyenv versions #python 切换版本   pyenv local 版本号</code></pre><blockquote><p><a href="https://github.com/eteplus/blog/issues/4" target="_blank" rel="noopener">Mac下pyenv与pyenv-virtualenv的安装和使用</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-pyenv-的使用&quot;&gt;&lt;a href=&quot;#1-pyenv-的使用&quot; class=&quot;headerlink&quot; title=&quot;1.pyenv 的使用&quot;&gt;&lt;/a&gt;1.pyenv 的使用&lt;/h4&gt;&lt;pre&gt;&lt;code&gt; #查看python 版本信息
   pyenv v
      
    
    </summary>
    
      <category term="python" scheme="https://BradyYue.github.io/categories/python/"/>
    
    
      <category term="python-常用篇" scheme="https://BradyYue.github.io/tags/python-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>cassandra-案例篇</title>
    <link href="https://BradyYue.github.io/2019/10/15/cassandra-%E6%A1%88%E4%BE%8B%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/10/15/cassandra-案例篇/</id>
    <published>2019-10-15T07:40:19.000Z</published>
    <updated>2019-12-17T01:55:21.739Z</updated>
    
    <content type="html"><![CDATA[<h4 id="java-链接cassandra-查询"><a href="#java-链接cassandra-查询" class="headerlink" title="java 链接cassandra 查询"></a>java 链接cassandra 查询</h4><pre><code>导入依赖 &lt;!-- https://mvnrepository.com/artifact/com.datastax.cassandra/cassandra-driver-core --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;    &lt;artifactId&gt;cassandra-driver-core&lt;/artifactId&gt;    &lt;version&gt;3.7.1&lt;/version&gt; &lt;/dependency&gt;import com.datastax.driver.core.Cluster;import com.datastax.driver.core.ResultSet;import com.datastax.driver.core.Row;import com.datastax.driver.core.Session;import java.util.List;/** * @author xianchang.yue * @date 2019-10-15 14:59 */public class TestCassandra {    public static void main(String[] args) {        Cluster cluster = null;        try {            cluster = Cluster.builder().addContactPoints(&quot;127.0.0.1&quot;).withPort(9042).build();            Session session = cluster.connect();            ResultSet execute = session.execute(&quot;select * from system_schema.keyspaces&quot;);            List&lt;Row&gt; all = execute.all();            for (Row row : all) {                String keyspace_name = row.getString(&quot;keyspace_name&quot;);                System.out.println(keyspace_name);            }        } finally {            if (cluster != null) {                cluster.close();            }        }    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;java-链接cassandra-查询&quot;&gt;&lt;a href=&quot;#java-链接cassandra-查询&quot; class=&quot;headerlink&quot; title=&quot;java 链接cassandra 查询&quot;&gt;&lt;/a&gt;java 链接cassandra 查询&lt;/h4&gt;&lt;pre&gt;
      
    
    </summary>
    
      <category term="cassandra" scheme="https://BradyYue.github.io/categories/cassandra/"/>
    
    
      <category term="cassandra-案例篇" scheme="https://BradyYue.github.io/tags/cassandra-%E6%A1%88%E4%BE%8B%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>k8s-学习篇</title>
    <link href="https://BradyYue.github.io/2019/10/15/k8s-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/10/15/k8s-学习篇/</id>
    <published>2019-10-15T04:03:49.000Z</published>
    <updated>2019-12-18T06:51:01.624Z</updated>
    
    <content type="html"><![CDATA[<h4 id="k8s-介绍"><a href="#k8s-介绍" class="headerlink" title="k8s 介绍"></a>k8s 介绍</h4><p>Kubernetes 是一个生产级的开源平台，用于协调计算机集群内部和跨计算机集群的应用程序容器的分发(调度)和运行。<br>一个 Master 是集群的调度节点。<br>nodes 是应用程序实际运行的工作节点。</p><h4 id="k8s-重要组件"><a href="#k8s-重要组件" class="headerlink" title="k8s 重要组件"></a>k8s 重要组件</h4><p>k8s核心组件：</p><blockquote><p>etcd保存了整个集群的状态；  </p></blockquote><blockquote><p>apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；  </p></blockquote><blockquote><p>controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；  </p></blockquote><blockquote><p>scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；  </p></blockquote><blockquote><p>kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；  </p></blockquote><blockquote><p>Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）；  </p></blockquote><blockquote><p>kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；  </p></blockquote><p>推荐的Add-ons：</p><blockquote><p>kube-dns负责为整个集群提供DNS服务</p></blockquote><blockquote><p>Ingress Controller为服务提供外网入口</p></blockquote><blockquote><p>Heapster提供资源监控</p></blockquote><blockquote><p>Dashboard提供GUI</p></blockquote><blockquote><p>Federation提供跨可用区的集群</p></blockquote><blockquote><p>Fluentd-elasticsearch提供集群日志采集、存储与查询</p></blockquote><h4 id="k8s-部署"><a href="#k8s-部署" class="headerlink" title="k8s 部署"></a>k8s 部署</h4><p>在k8s中，通过发布 Deployment，可以创建应用程序 (docker image) 的实例 (docker container)，这个实例会被包含在称为 Pod 的概念中，Pod 是 k8s 中最小单元的可管理单元</p><p>在 k8s 集群中发布 Deployment 后，Deployment 将指示 k8s 如何创建和更新应用程序的实例，master 节点将应用程序实例调度到集群中的具体的节点上。</p><p>创建应用程序实例后，Kubernetes Deployment Controller 会持续监控这些实例。如果运行实例的 worker 节点关机或被删除，则 Kubernetes Deployment Controller 将在群集中资源最优的另一个 worker 节点上重新创建一个新的实例。这提供了一种自我修复机制来解决机器故障或维护问题。</p><p>在容器编排之前的时代，各种安装脚本通常用于启动应用程序，但是不能够使应用程序从机器故障中恢复。通过创建应用程序实例并确保它们在集群节点中的运行实例个数，Kubernetes Deployment 提供了一种完全不同的方式来管理应用程序。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/ingress/</a></p><p>nginx官方介绍：<a href="https://www.nginx.com/products/nginx/kubernetes-ingress-controller" target="_blank" rel="noopener">https://www.nginx.com/products/nginx/kubernetes-ingress-controller</a></p><h4 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h4><p><a href="https://kubernetes.github.io/ingress-nginx/deploy/#prerequisite-generic-deployment-command" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/deploy/#prerequisite-generic-deployment-command</a></p><p>首先先下载相关的yaml文件，保存到本地。</p><p>deployments：<br>kubectl apply -f <a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml</a></p><p>service： 这里官方提供了各种云平台，系统等相关配置。我们这里是自建的k8s集群，所以我们选择裸机版本。</p><p>Bare-metal<br>Using NodePort:</p><p>kubectl apply -f <a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/baremetal/service-nodeport.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/baremetal/service-nodeport.yaml</a></p><p>安装完后。看看集群信息。</p><p>[root@node1 ingress-nginx]# kubectl get all -A -l app.kubernetes.io/name=ingress-nginx<br>NAMESPACE NAME READY STATUS RESTARTS AGE<br>ingress-nginx pod/nginx-ingress-controller-79f6884cf6-vh2w2 1/1 Running 0 5d3h</p><p>NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE<br>ingress-nginx service/ingress-nginx NodePort 10.233.29.94 <none> 80:31661/TCP,443:30250/TCP 6d2h</none></p><p>NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE<br>ingress-nginx deployment.apps/nginx-ingress-controller 1/1 1 1 6d3h</p><p>NAMESPACE NAME DESIRED CURRENT READY AGE<br>ingress-nginx replicaset.apps/nginx-ingress-controller-79f6884cf6 1 1 1 6d3h</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;k8s-介绍&quot;&gt;&lt;a href=&quot;#k8s-介绍&quot; class=&quot;headerlink&quot; title=&quot;k8s 介绍&quot;&gt;&lt;/a&gt;k8s 介绍&lt;/h4&gt;&lt;p&gt;Kubernetes 是一个生产级的开源平台，用于协调计算机集群内部和跨计算机集群的应用程序容器的分发(调度
      
    
    </summary>
    
      <category term="k8s" scheme="https://BradyYue.github.io/categories/k8s/"/>
    
    
      <category term="k8s-学习篇" scheme="https://BradyYue.github.io/tags/k8s-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>sql-常用篇</title>
    <link href="https://BradyYue.github.io/2019/10/15/sql-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://BradyYue.github.io/2019/10/15/sql-常用篇/</id>
    <published>2019-10-15T03:17:16.000Z</published>
    <updated>2019-10-15T03:17:44.017Z</updated>
    
    <content type="html"><![CDATA[<h4 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h4><p><a href="https://www.sqlstyle.guide/zh/" target="_blank" rel="noopener">https://www.sqlstyle.guide/zh/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;编程规范&quot;&gt;&lt;a href=&quot;#编程规范&quot; class=&quot;headerlink&quot; title=&quot;编程规范&quot;&gt;&lt;/a&gt;编程规范&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://www.sqlstyle.guide/zh/&quot; target=&quot;_blank&quot; rel=&quot;
      
    
    </summary>
    
      <category term="sql" scheme="https://BradyYue.github.io/categories/sql/"/>
    
    
      <category term="sql-常用篇" scheme="https://BradyYue.github.io/tags/sql-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
</feed>
