<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蜗牛笔记</title>
  
  <subtitle>骑士的心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://23yue23.github.io/"/>
  <updated>2019-05-20T02:56:39.123Z</updated>
  <id>https://23yue23.github.io/</id>
  
  <author>
    <name>Brady</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mysql系列之问题及解决</title>
    <link href="https://23yue23.github.io/2019/05/20/mysql%E7%B3%BB%E5%88%97%E4%B9%8B%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3/"/>
    <id>https://23yue23.github.io/2019/05/20/mysql系列之问题及解决/</id>
    <published>2019-05-20T02:54:59.000Z</published>
    <updated>2019-05-20T02:56:39.123Z</updated>
    
    <content type="html"><![CDATA[<h4 id="RROR-2002-HY000-Can’t-connect-to-local-MySQL-server-through-socket-‘-tmp-mysql-sock’-2"><a href="#RROR-2002-HY000-Can’t-connect-to-local-MySQL-server-through-socket-‘-tmp-mysql-sock’-2" class="headerlink" title="RROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)"></a>RROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">主要原因是mysql 服务没有启动</span><br><span class="line">解决：mysql.server start</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;RROR-2002-HY000-Can’t-connect-to-local-MySQL-server-through-socket-‘-tmp-mysql-sock’-2&quot;&gt;&lt;a href=&quot;#RROR-2002-HY000-Can’t-connect-to-l
      
    
    </summary>
    
      <category term="mysql" scheme="https://23yue23.github.io/categories/mysql/"/>
    
    
      <category term="mysql-问题" scheme="https://23yue23.github.io/tags/mysql-%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra系列之系统参数优化</title>
    <link href="https://23yue23.github.io/2019/05/17/Cassandra%E7%B3%BB%E5%88%97%E4%B9%8B%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>https://23yue23.github.io/2019/05/17/Cassandra系列之系统参数优化/</id>
    <published>2019-05-17T07:04:40.000Z</published>
    <updated>2019-05-17T07:59:12.694Z</updated>
    
    <content type="html"><![CDATA[<p>Cassandra不同于普通的应用程序，它是分布式数据库，它要大口吃内存，吃磁盘，吃CPU，所以机器要进行特殊的配置，以适应其需要。</p><h4 id="使用最新的64位的jdk8的最新发布版本。"><a href="#使用最新的64位的jdk8的最新发布版本。" class="headerlink" title="使用最新的64位的jdk8的最新发布版本。"></a>使用最新的64位的jdk8的最新发布版本。</h4><hr><h4 id="时钟同步，开启NTP服务"><a href="#时钟同步，开启NTP服务" class="headerlink" title="时钟同步，开启NTP服务."></a>时钟同步，开启NTP服务.</h4><blockquote><p>cassandra是分布式存储，就靠时间戳解决数据冲突，所以始终必须同步</p></blockquote><hr><h4 id="TCP参数设置"><a href="#TCP参数设置" class="headerlink" title="TCP参数设置"></a>TCP参数设置</h4><blockquote><p>在低带宽环境下，防火墙会检测闲置的连接并关闭，为了保护节点之间，或者多个DC节点之间的连接，建议如下配置系统参数</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w</span><br><span class="line">net.ipv4.tcp_keepalive_time=60</span><br><span class="line">net.ipv4.tcp_keepalive_probes=3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=10</span><br></pre></td></tr></table></figure><blockquote><p>设置这个就是可以快速的发现底层的TCP连接是否已经关闭，它间隔60秒开始探测3次，每次探测间隔10秒，也就是说最多在60+3*10=90秒内就可以检测到连接被中断。<br>为了支撑上千个数据库连接，还建议修改以下参数</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w</span><br><span class="line">net.core.rmem_max=16777216</span><br><span class="line">net.core.wmem_max=16777216</span><br><span class="line">net.core.rmem_default=16777216</span><br><span class="line">net.core.wmem_default=16777216</span><br><span class="line">net.core.optmem_max=40960</span><br><span class="line">net.ipv4.tcp_rmem=4096 87380 16777216</span><br><span class="line">net.ipv4.tcp_wmem=4096 65536 16777216</span><br></pre></td></tr></table></figure><blockquote><p>为了让参数永久生效，记得把它们写入系统配置文件/etc/sysctl.conf里</p></blockquote><hr><h4 id="禁用CPU动态跳频功能。"><a href="#禁用CPU动态跳频功能。" class="headerlink" title="禁用CPU动态跳频功能。"></a>禁用CPU动态跳频功能。</h4><blockquote><p>最近的linux系统增加了一个新特性，就是可以动态调整CPU频率，就是在机器低负载的时候，可以降低CPU频率，以达到降低功耗的目的。<br>这种动态调频功能会影响cassandra数据库的吞吐量。建议禁用，让CPU一直维持恒定的频率输出，尽管这很耗电，但是保证你的数据库的吞吐量。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">禁用方式：</span><br><span class="line"></span><br><span class="line">for CPUFREQ in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line">do</span><br><span class="line">[ -f $CPUFREQ ] || continue</span><br><span class="line">echo -n performance &gt; $CPUFREQ</span><br><span class="line">done</span><br></pre></td></tr></table></figure><hr><h4 id="禁用zone-reclaim-mode"><a href="#禁用zone-reclaim-mode" class="headerlink" title="禁用zone_reclaim_mode"></a>禁用zone_reclaim_mode</h4><blockquote><p>官方建议禁用，这个是关于多核CPU使用NUMA架构，分别访问内存，内存回收方面的一个参数<br>这个参数的解释，可以参考：<br><a href="http://linuxinsight.com/proc_sys_vm_zone_reclaim_mode.html" target="_blank" rel="noopener">http://linuxinsight.com/proc_sys_vm_zone_reclaim_mode.html</a><br>这里面有一句话，当你的机器用作文件服务器，或者你的大部分内存需要用于系统文件缓存的时候，你需要禁用这个功能。<br>我们的Cassandra就相当于文件服务器，它对IO是依赖的，它需要系统内存用于大量缓存DB文件。所以要禁用这个功能。<br>echo 0 &gt; /proc/sys/vm/zone_reclaim_mode<br>Cassandra官方描述了如果不禁用这个参数带来的后果：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、随机CPU尖峰带来时延增加，吞吐量增加。</span><br><span class="line">2、程序假死，什么也不做。</span><br><span class="line">3、一些突然发生又消失的莫名异常。</span><br><span class="line">4、重启机器，可能在一段时间内不再出现异常。</span><br></pre></td></tr></table></figure><hr><h4 id="资源限制放开。"><a href="#资源限制放开。" class="headerlink" title="资源限制放开。"></a>资源限制放开。</h4><blockquote><p>cassandra会使用很多内存，很多连接，很多文件，所以一律放开。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;cassandra_user&gt; – memlock unlimited</span><br><span class="line">&lt;cassandra_user&gt; – nofile 100000</span><br><span class="line">&lt;cassandra_user&gt; – nproc 32768</span><br><span class="line">&lt;cassandra_user&gt; – as unlimited</span><br></pre></td></tr></table></figure><blockquote><p>这个加入到/etc/security/limits.conf 里（不同操作系统，可能不同，后面不再注明）<br>vm.max_map_count = 1048575   将这个加入到 /etc/sysctl.conf 里</p></blockquote><hr><h4 id="禁用swap"><a href="#禁用swap" class="headerlink" title="禁用swap"></a>禁用swap</h4><blockquote><p>关闭 sudo swapoff –all<br>修改 /etc/fstab. 去掉swap挂载。<br>swap文件内存交换区，当你的内存不够的时候，使用文件内存，这会让你的数据库卡成狗的，一律禁用。</p></blockquote><hr><h4 id="文件预"><a href="#文件预" class="headerlink" title="文件预"></a>文件预</h4><blockquote><p>默认保持64k即可</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 64 &gt; /sys/class/block/&#123;sda&#125;/queue/read_ahead_kb</span><br></pre></td></tr></table></figure><blockquote><p>如果是ssd，设置为8k</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 8 &gt; /sys/class/block/&#123;sda&#125;/queue/read_ahead_kb</span><br></pre></td></tr></table></figure><blockquote><p>如果是ssd，还要设置下面的参数进行优化。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">echo deadline &gt; /sys/block/sda/queue/scheduler</span><br><span class="line">#OR…</span><br><span class="line">#echo noop &gt; /sys/block/sda/queue/scheduler</span><br><span class="line">touch /var/lock/subsys/local</span><br><span class="line">echo 0 &gt; /sys/class/block/sda/queue/rotational</span><br></pre></td></tr></table></figure><hr><h4 id="确保以上参数重启机器后仍然有效。"><a href="#确保以上参数重启机器后仍然有效。" class="headerlink" title="确保以上参数重启机器后仍然有效。"></a>确保以上参数重启机器后仍然有效。</h4><hr><h4 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h4><p><a href="https://zhaoyanblog.com/archives/1005.html" target="_blank" rel="noopener">赵岩的博客</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Cassandra不同于普通的应用程序，它是分布式数据库，它要大口吃内存，吃磁盘，吃CPU，所以机器要进行特殊的配置，以适应其需要。&lt;/p&gt;
&lt;h4 id=&quot;使用最新的64位的jdk8的最新发布版本。&quot;&gt;&lt;a href=&quot;#使用最新的64位的jdk8的最新发布版本。&quot; cl
      
    
    </summary>
    
      <category term="Cassandra" scheme="https://23yue23.github.io/categories/Cassandra/"/>
    
    
      <category term="Cassandra-系统优化" scheme="https://23yue23.github.io/tags/Cassandra-%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>linux系列之端口占有</title>
    <link href="https://23yue23.github.io/2019/05/17/linux%E7%B3%BB%E5%88%97%E4%B9%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E6%9C%89/"/>
    <id>https://23yue23.github.io/2019/05/17/linux系列之端口占有/</id>
    <published>2019-05-17T06:51:25.000Z</published>
    <updated>2019-05-20T10:01:14.418Z</updated>
    
    <content type="html"><![CDATA[<h4 id="使用lsof"><a href="#使用lsof" class="headerlink" title="使用lsof"></a>使用lsof</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i:80</span><br></pre></td></tr></table></figure><h4 id="使用netstat"><a href="#使用netstat" class="headerlink" title="使用netstat"></a>使用netstat</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -anp|grep port</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;使用lsof&quot;&gt;&lt;a href=&quot;#使用lsof&quot; class=&quot;headerlink&quot; title=&quot;使用lsof&quot;&gt;&lt;/a&gt;使用lsof&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gut
      
    
    </summary>
    
      <category term="linux" scheme="https://23yue23.github.io/categories/linux/"/>
    
    
      <category term="linux-端口" scheme="https://23yue23.github.io/tags/linux-%E7%AB%AF%E5%8F%A3/"/>
    
  </entry>
  
  <entry>
    <title>cassandra系列之问题总结</title>
    <link href="https://23yue23.github.io/2019/05/17/cassandra%E7%B3%BB%E5%88%97%E4%B9%8B%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    <id>https://23yue23.github.io/2019/05/17/cassandra系列之问题总结/</id>
    <published>2019-05-17T06:17:21.000Z</published>
    <updated>2019-05-17T07:57:29.597Z</updated>
    
    <content type="html"><![CDATA[<h4 id="为什么不可以设置listen-address为0-0-0-0（意思是监听所有地址）？"><a href="#为什么不可以设置listen-address为0-0-0-0（意思是监听所有地址）？" class="headerlink" title="为什么不可以设置listen_address为0.0.0.0（意思是监听所有地址）？"></a>为什么不可以设置listen_address为0.0.0.0（意思是监听所有地址）？</h4><blockquote><p>Cassandra是一个基于gossip协议的分布式系统，监听地址是用来告诉其它节点来访问的，告诉别的节点说“连接我任何地址都可以”，是一个糟糕的想法，如果集群中不同的节点使用了不同方式的地址，悲剧的事情就要发生了。<br>如果你不想为你集群中的每个节点单独配置ip（非常可以理解）,你可以不配，空着它，Cassandra将会使用InetAddress.getLocalHost()来选择地址，然后只要你或者你的运维团队保证这个是正确的(/etc/hosts/,dns 等等要配置对)。<br>一个例外是JMX,他默认监听的地址是0.0.0.0（这个是java的bug 6425769）<br>请看CASSANDRA-256 和 CASSANDRA-43获取这方面更多的细节。</p></blockquote><hr><h4 id="cassandra用了哪些端口？"><a href="#cassandra用了哪些端口？" class="headerlink" title="cassandra用了哪些端口？"></a>cassandra用了哪些端口？</h4><blockquote><p>默认7000作为集群通信端口（如果开启了SSL就是7001端口）。<br>9042端口用于native协议的客户端连接。<br>7199端口用于JMX，<br>9160端口用于废弃的Thrift接口。<br>内部节点通信以及native协议的端口在cassandra配置文件里可以配置。JMX端口可以在cassandra-env.sh配置（通过JVM的参数)。所有端口都是TCP的。</p></blockquote><hr><h4 id="当往集群中增加新节点的时候，对于存在的数据发生了什么？"><a href="#当往集群中增加新节点的时候，对于存在的数据发生了什么？" class="headerlink" title="当往集群中增加新节点的时候，对于存在的数据发生了什么？"></a>当往集群中增加新节点的时候，对于存在的数据发生了什么？</h4><blockquote><p>当一个新节点加入到集群，它将会自动连接集群中的其它节点，并且去复制正确的数据到本地，同样的增加、替换、移动、删除节点都是这样的。</p></blockquote><hr><h4 id="我删除了数据，但是磁盘使用率没有变化，这是为什么？"><a href="#我删除了数据，但是磁盘使用率没有变化，这是为什么？" class="headerlink" title="我删除了数据，但是磁盘使用率没有变化，这是为什么？"></a>我删除了数据，但是磁盘使用率没有变化，这是为什么？</h4><blockquote><p>写入到cassandra里的数据会被持久化到SSTable文件里，SSTable文件是不可改变的，也就是说当你执行删除的时候，数据不会从文件中被去除掉的。<br>相反，一个标记（也叫tombstone)会被写入用于标记对应记录的新状态。不用担心，当数据和tombstone发生第一次compaction的时候，数据会被删除掉，相应的磁盘空间也被回收，你可以了解关于Compaction的更多细节。</p></blockquote><hr><h4 id="为什么用nodetool-ring只能看到一条记录？-即便所有节点输出的日志里可以看出，他们都发现彼此加入到了这个ring。"><a href="#为什么用nodetool-ring只能看到一条记录？-即便所有节点输出的日志里可以看出，他们都发现彼此加入到了这个ring。" class="headerlink" title="为什么用nodetool ring只能看到一条记录？ 即便所有节点输出的日志里可以看出，他们都发现彼此加入到了这个ring。"></a>为什么用nodetool ring只能看到一条记录？ 即便所有节点输出的日志里可以看出，他们都发现彼此加入到了这个ring。</h4><blockquote><p>这个发生于你的所有节点都配了通用的token，不要这么做。<br>这经常发生于哪些使用VM部署cassandra的用户，（特别是使用Debian package，它会在安装完自动启动cassandra，所以会生成token并保存它。），安装好后就把VM整个克隆出另外的节点。<br>增很容易修复，只要把数据目录以及commitlog目录删除，然后保证每个节点是随机生成的token，再启动就可以了。</p></blockquote><hr><h4 id="我可以修改一个正在运行中的集群中的keyspace的副本因子吗？"><a href="#我可以修改一个正在运行中的集群中的keyspace的副本因子吗？" class="headerlink" title="我可以修改一个正在运行中的集群中的keyspace的副本因子吗？"></a>我可以修改一个正在运行中的集群中的keyspace的副本因子吗？</h4><blockquote><p>可以，但是修改后需要执行repair或者cleanup来改变已存数据的副本个数。<br>首先使用cqlsh修改目标keyspace的副本因子。<br>如果你是减少副本因子，你可以执行nodetool cleanup去删除多余的副本数据，对每个节点都要执行。<br>如果你是增加副本因子，你需要执行nodetool repair来保证数据的副本个数满足当前的配置。 Repair只要对每个副本集执行一次即可。这是个敏感的操作，这会影响集群的性能。强烈建议执行rolling repair，因为试图一次修复整个集群的话，那可能是个坑。</p></blockquote><hr><h4 id="可以使用cassandra存储大的二进制字段吗？"><a href="#可以使用cassandra存储大的二进制字段吗？" class="headerlink" title="可以使用cassandra存储大的二进制字段吗？"></a>可以使用cassandra存储大的二进制字段吗？</h4><blockquote><p>Cassandra并没有对存储大文件或者二进制，以及这样一个二进制数据被经常读，也就是整个发送到客户端的情况进行优化。因为存储小的二进制数据（小于1MB)应该不是问题。但是还是建议把大的二进制数据分隔成小块。<br>需要特别注意的是，任何大于16MB的值，将被Cassandra拒绝掉，这是由max_mutation_size_in_kb配置项决定的（这个配置项默认是commitlog_segment_size_in_mb的一半，commitlog_segment_size_in_mb默认是32M)。</p></blockquote><hr><h4 id="Nodetool连接远程服务器的时候，提示“Connection-refused-to-host-127-0-1-1”-，这是为什么？"><a href="#Nodetool连接远程服务器的时候，提示“Connection-refused-to-host-127-0-1-1”-，这是为什么？" class="headerlink" title="Nodetool连接远程服务器的时候，提示“Connection refused to host: 127.0.1.1” ，这是为什么？"></a>Nodetool连接远程服务器的时候，提示“Connection refused to host: 127.0.1.1” ，这是为什么？</h4><blockquote><p>nodetool依赖JMX，JMX依赖RMI。RMI在两端通信的时候会根据需要创建自己的listenners和connectors。通常，这些都是底层透明的，但是不正确的hostname解析，无论是在连接方还是被连接方，都会导致错乱和这样的拒绝异常。<br>如果你在使用DNS。确保两端机器的/etc/hosts文件是正确的。如果还是失败的，你可以尝试通过jvm选项-Djava.rmi.server.hostname=指定你要连接的远程机器名称给JMX接口，配置项大体在cassandra-env.sh文件的靠下的位置。</p></blockquote><hr><h4 id="端口占用"><a href="#端口占用" class="headerlink" title="端口占用"></a>端口占用</h4><blockquote><p>错误：<br> Cassandra关闭后，重启，提示，7199端口被占用，分析原因是关闭时使用的ctrl+c，实际上并没有关闭cassandra服务进程，所以提示端口已被使用； </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yxcdeMacBook-Pro:3.11.4 yxc$ cqlsh</span><br><span class="line">Connection error: (&apos;Unable to connect to any servers&apos;, &#123;&apos;127.0.0.1&apos;: error(61, &quot;Tried connecting to [(&apos;127.0.0.1&apos;, 9042)]. Last error: Connection refused&quot;)&#125;)</span><br></pre></td></tr></table></figure><blockquote><p>解决：<br>找出使用7199端口的进程<br>lsof -i:7199<br>杀死残留进程<br>kill direct_pid</p></blockquote><hr><h4 id="版本不一致"><a href="#版本不一致" class="headerlink" title="版本不一致"></a>版本不一致</h4><blockquote><p>错误： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Connection error: </span><br><span class="line">(‘Unable to connect to any servers’, </span><br><span class="line">&#123;‘127.0.0.1’: ProtocolError(“cql_version ‘3.3.0’ is not supported by remote (w/ native protocol). Supported versions: [u’3.3.1’]”,)&#125;)</span><br></pre></td></tr></table></figure><blockquote><p>解决： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">修改cassandra_home/bin/cqlsh.py: </span><br><span class="line">DEFAULT_CQLVER = ‘3.3.0’为DEFAULT_CQLVER = ‘3.3.1’；</span><br></pre></td></tr></table></figure><hr><h4 id="All-host-s-tried-for-query-failed"><a href="#All-host-s-tried-for-query-failed" class="headerlink" title="All host(s) tried for query failed"></a>All host(s) tried for query failed</h4><blockquote><p>错误： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">message: ‘All host(s) tried for query failed. First host tried, </span><br><span class="line">127.0.0.1:9042: Error: connect ECONNREFUSED 127.0.0.1:9042. </span><br><span class="line">See innerErrors.’ &#125;</span><br></pre></td></tr></table></figure><blockquote><p>解决： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">修改cassandra_home/conf/cassandra.yaml: </span><br><span class="line">start_native_transport=false改为start_native_transport=true;</span><br></pre></td></tr></table></figure><hr><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://zhaoyanblog.com/archives/957.html" target="_blank" rel="noopener">赵岩</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;为什么不可以设置listen-address为0-0-0-0（意思是监听所有地址）？&quot;&gt;&lt;a href=&quot;#为什么不可以设置listen-address为0-0-0-0（意思是监听所有地址）？&quot; class=&quot;headerlink&quot; title=&quot;为什么不可以设置
      
    
    </summary>
    
      <category term="Cassandra" scheme="https://23yue23.github.io/categories/Cassandra/"/>
    
    
      <category term="Cassandra-问题总结" scheme="https://23yue23.github.io/tags/Cassandra-%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Druid之调研</title>
    <link href="https://23yue23.github.io/2019/05/17/Druid%E4%B9%8B%E8%B0%83%E7%A0%94/"/>
    <id>https://23yue23.github.io/2019/05/17/Druid之调研/</id>
    <published>2019-05-17T05:49:39.000Z</published>
    <updated>2019-05-17T05:50:46.151Z</updated>
    
    <content type="html"><![CDATA[<ol><li><a href="https://blog.csdn.net/bigtree_3721/article/category/6956082" target="_blank" rel="noopener">druid 系列csdn</a></li><li></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/bigtree_3721/article/category/6956082&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;druid 系列csdn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Homebrew-使用</title>
    <link href="https://23yue23.github.io/2019/05/17/Homebrew-%E4%BD%BF%E7%94%A8/"/>
    <id>https://23yue23.github.io/2019/05/17/Homebrew-使用/</id>
    <published>2019-05-17T02:56:28.000Z</published>
    <updated>2019-05-17T06:17:57.292Z</updated>
    
    <content type="html"><![CDATA[<p>安装路径：/usr/local/Cellar/</p><blockquote><p>查找软件包</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew search wget</span><br></pre></td></tr></table></figure><blockquote><p>安装软件包</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install wget</span><br></pre></td></tr></table></figure><blockquote><p>列出已安装的软件包</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew list</span><br></pre></td></tr></table></figure><blockquote><p>删除软件包</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew remove wget</span><br></pre></td></tr></table></figure><blockquote><p>查看软件包信息</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew info wget</span><br></pre></td></tr></table></figure><blockquote><p>列出软件包的依赖关系</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew deps wget</span><br></pre></td></tr></table></figure><blockquote><p>更新brew</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew update</span><br></pre></td></tr></table></figure><blockquote><p>列出过时的软件包（已安装但不是最新版本）</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew outdated</span><br></pre></td></tr></table></figure><blockquote><p>更新过时的软件包（全部或指定）</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew upgrade 或 brew upgrade wget</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;安装路径：/usr/local/Cellar/&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;查找软件包&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;s
      
    
    </summary>
    
      <category term="工具" scheme="https://23yue23.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Homebrew-使用" scheme="https://23yue23.github.io/tags/Homebrew-%E4%BD%BF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra系列之不同key之间的区别</title>
    <link href="https://23yue23.github.io/2019/05/15/Cassandra%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8D%E5%90%8Ckey%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://23yue23.github.io/2019/05/15/Cassandra系列之不同key之间的区别/</id>
    <published>2019-05-15T09:37:26.000Z</published>
    <updated>2019-05-15T09:58:19.525Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Single-column-Primary-Key"><a href="#Single-column-Primary-Key" class="headerlink" title="Single column Primary Key"></a>Single column Primary Key</h4><blockquote><p>Primary Key 可以由一列或多列组成,用于从表中检索数据，如果 Primary Key 由一列组成，那么称为 Single column Primary Key&gt; 如下：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE iteblog_user (first_name text , last_name text, PRIMARY KEY (first_name)) ;</span><br></pre></td></tr></table></figure><blockquote><p>我们在检索数据的时候需要指定 Primary Key,不指定查询数据会抛以下异常：</p></blockquote> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">InvalidRequest: Error from server: code=2200 [Invalid query] </span><br><span class="line">message=&quot;Cannot execute this query as it might involve data filtering and thus may have unpredictable performance. </span><br><span class="line">If you want to execute this query despite the performance unpredictability, use ALLOW FILTERING&quot;</span><br></pre></td></tr></table></figure><h4 id="Composite-Primary-Key"><a href="#Composite-Primary-Key" class="headerlink" title="Composite Primary Key"></a>Composite Primary Key</h4><blockquote><p>如果 Primary Key 由多列组成，那么这种情况称为 Compound Primary Key 或 Composite Primary Key  如下：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE iteblog_user_composite (first_name text , last_name text, PRIMARY KEY (first_name, last_name)) ;</span><br></pre></td></tr></table></figure><blockquote><p>其中 first_name 称为 Partition key，last_name 称为 Clustering key（也可以称为 Clustering column）。在这种情况下，下面查询的前三条都是合法的，最后一条是非法的。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cqlsh:iteblog_keyspace&gt; select * from iteblog_user_composite;</span><br><span class="line"> </span><br><span class="line">cqlsh:iteblog_keyspace&gt; select * from iteblog_user_composite where first_name = &apos;iteblog&apos;;</span><br><span class="line"> </span><br><span class="line">cqlsh:iteblog_keyspace&gt; select * from iteblog_user_composite where first_name = &apos;iteblog&apos; and last_name = &apos;hadoop&apos;;</span><br><span class="line"> </span><br><span class="line">//非法查询</span><br><span class="line">cqlsh:iteblog_keyspace&gt; select * from iteblog_user_composite where last_name = &apos;hadoop&apos;;</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">&gt; Partition key 和 Clustering key(查询的时候不可以仅指定，需要和partition key 组合) 也可以由多个字段组成，如果 Partition key 由多个字段组成，称之为 Composite partition key：</span><br></pre></td></tr></table></figure><p>create table iteblog_multiple (<br>      k_part_one text,<br>      k_part_two int,<br>      k_clust_one text,<br>      k_clust_two int<br>      data text,<br>      PRIMARY KEY((k_part_one, k_part_two), k_clust_one, k_clust_two)<br>  );<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;小知识：使用 Composite partition key 的一个原因</span><br><span class="line">其实一个 Partition 对应的 Cell 个数在 Cassandra 里面是有限制的。理论上来说，一个 Partition 的 Cell 个数大约在20亿个（231）。所以采用了 Composite partition key，我们可以将数据分散到不同的 Partition，这样有利于将同一个 Partition 的 Cell 个数减少。</span><br><span class="line"></span><br><span class="line">#### Partition key &amp; Clustering key &amp; Primary Key 作用</span><br><span class="line"></span><br><span class="line">&gt; Partition Key：将数据分散到集群的 node 上</span><br><span class="line"></span><br><span class="line">&gt; Primary Key：在 Single column Primary Key 情况下作用和 Partition Key 一样；在 Composite Primary Key 情况下，组合 Partition key 字段决定数据的分发的节点；</span><br><span class="line"></span><br><span class="line">&gt; Clustering Key：决定同一个分区内相同 Partition Key 数据的排序，默认为升序，我们可以在建表语句里面手动设置排序的方式（DESC 或 ASC）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">***</span><br></pre></td></tr></table></figure></p><p>转载自过往记忆（<a href="https://www.iteblog.com/）" target="_blank" rel="noopener">https://www.iteblog.com/）</a><br>本文链接: 【Apache Cassandra Composite KeyPartition keyClustering key 介绍<br>（<a href="https://www.iteblog.com/archives/2534.html）" target="_blank" rel="noopener">https://www.iteblog.com/archives/2534.html）</a><br><code>`</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Single-column-Primary-Key&quot;&gt;&lt;a href=&quot;#Single-column-Primary-Key&quot; class=&quot;headerlink&quot; title=&quot;Single column Primary Key&quot;&gt;&lt;/a&gt;Single colu
      
    
    </summary>
    
      <category term="Cassandra" scheme="https://23yue23.github.io/categories/Cassandra/"/>
    
    
      <category term="Cassandra-命令" scheme="https://23yue23.github.io/tags/Cassandra-%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra系列之常用操作命令</title>
    <link href="https://23yue23.github.io/2019/05/15/Cassandra%E7%B3%BB%E5%88%97%E4%B9%8B%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/"/>
    <id>https://23yue23.github.io/2019/05/15/Cassandra系列之常用操作命令/</id>
    <published>2019-05-15T09:33:51.000Z</published>
    <updated>2019-05-20T02:02:23.457Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="http://www.myoak.info/post/12/" target="_blank" rel="noopener">cassandra mac os 安装</a></p></blockquote><h4 id="shell-命令"><a href="#shell-命令" class="headerlink" title="shell 命令"></a>shell 命令</h4><h5 id="登陆"><a href="#登陆" class="headerlink" title="登陆"></a>登陆</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cqlsh -u cassandra -p cassandra --connect-timeout 300</span><br></pre></td></tr></table></figure><h5 id="查看集群信息"><a href="#查看集群信息" class="headerlink" title="查看集群信息"></a>查看集群信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodetool  describecluster</span><br></pre></td></tr></table></figure><h5 id="查看节点状态"><a href="#查看节点状态" class="headerlink" title="查看节点状态"></a>查看节点状态</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodetool    status</span><br></pre></td></tr></table></figure><h5 id="重启节点"><a href="#重启节点" class="headerlink" title="重启节点"></a>重启节点</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart scylla-server</span><br></pre></td></tr></table></figure><h4 id="Cql操作"><a href="#Cql操作" class="headerlink" title="Cql操作"></a>Cql操作</h4><h5 id="查看版本"><a href="#查看版本" class="headerlink" title="查看版本"></a>查看版本</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW VERSION</span><br></pre></td></tr></table></figure><h5 id="keyspaces-操作"><a href="#keyspaces-操作" class="headerlink" title="keyspaces 操作"></a>keyspaces 操作</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查看</span><br><span class="line">desc keyspaces;</span><br><span class="line">#使用</span><br><span class="line">use keyspaceName</span><br></pre></td></tr></table></figure><h5 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#table list</span><br><span class="line">describe tables;</span><br><span class="line"></span><br><span class="line">#查看表结构</span><br><span class="line">describe table table_name;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://www.myoak.info/post/12/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cassandra mac os 安装&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;sh
      
    
    </summary>
    
      <category term="Cassandra" scheme="https://23yue23.github.io/categories/Cassandra/"/>
    
    
      <category term="Cassandra-命令" scheme="https://23yue23.github.io/tags/Cassandra-%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra系列之走进Cassandra</title>
    <link href="https://23yue23.github.io/2019/05/15/Cassandra%E7%B3%BB%E5%88%97%E4%B9%8B%E8%B5%B0%E8%BF%9BCassandra/"/>
    <id>https://23yue23.github.io/2019/05/15/Cassandra系列之走进Cassandra/</id>
    <published>2019-05-15T08:52:03.000Z</published>
    <updated>2019-05-15T09:39:56.625Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h3><blockquote><p>Apache Cassandra 是一个开源的、分布式、无中心、弹性可扩展、高可用、容错、一致性可调、面向行的数据库，它基于 Amazon Dynamo 的分布式设计和 Google Bigtable 的数据模型，Cassandra 其协议是 P2P 的，并使用 gossip 来维护存活或死亡节点的列表（gossip 协议介绍：<a href="https://www.iteblog.com/archives/2505.html）由" target="_blank" rel="noopener">https://www.iteblog.com/archives/2505.html）由</a> Facebook 创建，在一些最流行的网站中得到应用.</p></blockquote><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><h4 id="分布式和去中心化（Distributed-and-Decentralized）："><a href="#分布式和去中心化（Distributed-and-Decentralized）：" class="headerlink" title="分布式和去中心化（Distributed and Decentralized）："></a>分布式和去中心化（Distributed and Decentralized）：</h4><blockquote><p>可以运行在多台机器上，并呈现给用户一个一致的整体；</p></blockquote><blockquote><p>Cassandra 是无中心的，也就是说每个节点都是一样的，协议是 P2P 的，并使用 gossip 来维护存活或死亡节点的列表。</p></blockquote><h4 id="弹性可扩展："><a href="#弹性可扩展：" class="headerlink" title="弹性可扩展："></a>弹性可扩展：</h4><blockquote><p>集群可以不间断的情况下，方便扩展或缩减服务的规模，不需要重新启动进程，不必修改应用的查询，也无需自己手工重新均衡数据分布，只要加入新的计算机，Cassandra 就会自动地发现它并让它开始工作。</p></blockquote><h4 id="高可用和容错："><a href="#高可用和容错：" class="headerlink" title="高可用和容错："></a>高可用和容错：</h4><blockquote><p>可以在不中断系统的情况下替换故障节点，还可以把数据分布到多个数据中心里，从而提供更好的本地访问性能，并且在某一数据中心发生火灾、洪水等不可抗灾难的时候防止系统彻底瘫痪</p></blockquote><h4 id="可调节一致性："><a href="#可调节一致性：" class="headerlink" title="可调节一致性："></a>可调节一致性：</h4><blockquote><ol><li>通过副本因子（replication factor），你可以决定准备牺牲多少性能来换取一致性。 副本因子是你要求更新在集群中传播到的节点数（注意，更新包括所有增加、删除和更新操作）。</li></ol></blockquote><blockquote><ol start="2"><li>一致性级别（consistency level）参数，这个参数决定了多少个副本写入成功才可以认定写操作是成功的，或者读取过程中读到多少个副本正确就可以认定是读成功的。这里 Cassandra 把决定一致性程度的权利留给了客户自己。</li></ol></blockquote><blockquote><ol start="3"><li>所以，如果需要的话，你可以设定一致性级别和副本因子相等，从而达到一个较高的一致性水平，不过这样就必须付出同步阻塞操作的代价，只有所有节点都被更新完成才能成功返回一次更新。而实际上，Cassandra 一般都不会这么来用，原因显而易见（这样就丧失了可用性目标，影响性能，而且这不是你选择 Cassandra 的初衷）。而如果一个客户端设置一致性级别低于副本因子的话，即使有节点宕机了，仍然可以写成功。</li></ol></blockquote><blockquote><ol start="4"><li>总体来说，Cassandra 更倾向于 CP，虽然它也可以通过调节一致性水平达到 AP；但是不推荐你这么设置。其CAP 定律的详细介绍可参见<a href="https://www.iteblog.com/archives/2352.html" target="_blank" rel="noopener">《分布式系统一致性问题、CAP定律以及 BASE 理论》</a>以及<a href="https://www.iteblog.com/archives/2390.html" target="_blank" rel="noopener">《一篇文章搞清楚什么是分布式系统 CAP 定理》</a>。</li></ol></blockquote><h4 id="面向行"><a href="#面向行" class="headerlink" title="面向行"></a>面向行</h4><blockquote><p>它的数据结构不是关系型的，而是一个多维稀疏哈希表。稀疏（Sparse）意味着任何一行都可能会有一列或者几列。更确切地说，应该把 Cassandra 看做是一个有索引的、面向行的存储系统。</p></blockquote><h4 id="灵活的模式（Flexible-Schema）"><a href="#灵活的模式（Flexible-Schema）" class="headerlink" title="灵活的模式（Flexible Schema）"></a>灵活的模式（Flexible Schema）</h4><blockquote><p>从 3.0 版本开始，不推荐使用基于 Thrift API 的动态列创建的 API，并且 Cassandra 底层存储已经重新实现了，以更紧密地与 CQL 保持一致。 Cassandra 并没有完全限制动态扩展架构的能力，但它的工作方式却截然不同。 CQL 集合（比如 list、set、尤其是 map）提供了在无结构化的格式里面添加内容的能力，从而能扩展现有的模式。CQL 还提供了改变列的类型的能力，以支持 JSON 格式的文本的存储。</p></blockquote><h4 id="高性能-High-Performance"><a href="#高性能-High-Performance" class="headerlink" title="高性能(High Performance)"></a>高性能(High Performance)</h4><blockquote><p>设计之初就特别考虑了要充分利用多处理器和多核计算机的性能，并考虑在分布于多个数据中心的大量这类服务器上运行。它可以一致而且无缝地扩展到数百台机器，存储数 TB 的数据。Cassandra 已经显示出了高负载下的良好表现，在一个非常普通的工作站上，Cassandra 也可以提供非常高的写吞吐量。而如果你增加更多的服务器，你还可以继续保持 Cassandra 所有的特性而无需牺牲性能</p></blockquote><hr><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><h4 id="大规模部署"><a href="#大规模部署" class="headerlink" title="大规模部署"></a>大规模部署</h4><blockquote><p>单节点不易发挥它的性能，多个节点部署cassandra才是最佳选择</p></blockquote><h4 id="写密集、统计和分析型工作"><a href="#写密集、统计和分析型工作" class="headerlink" title="写密集、统计和分析型工作"></a>写密集、统计和分析型工作</h4><blockquote><p>Cassandra 是为优异的写吞吐量而特别优化的。 早期用于存储用户状态更新、社交网络、建议/评价以及应用统计都是很好的应用场景。现又适用于窗口化的时间序列数据库，用于文档搜索的反向索引，以及分布式任务优先级队列。</p></blockquote><h4 id="地区分布"><a href="#地区分布" class="headerlink" title="地区分布"></a>地区分布</h4><blockquote><p>支持多地分布的数据存储，Cassandra 可以很容易配置成将数据分布到多个数据中心的存储方式。如果你有一个全球部署的应用，那么让数据贴近用户会获得不错的性能收益，Cassandra 正适合这种应用场合。</p></blockquote><h4 id="变化的应用"><a href="#变化的应用" class="headerlink" title="变化的应用"></a>变化的应用</h4><blockquote><p>正在“初创阶段”，业务会不断改进，Cassandra 这种灵活的模式的数据模型可能更适合你。这让你的数据库能更快地跟上业务改进的步伐。</p></blockquote><hr><blockquote><p>参考地址：<a href="https://www.iteblog.com/archives/2530.html" target="_blank" rel="noopener">cassandra 简介</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;简介：&quot;&gt;&lt;a href=&quot;#简介：&quot; class=&quot;headerlink&quot; title=&quot;简介：&quot;&gt;&lt;/a&gt;简介：&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Apache Cassandra 是一个开源的、分布式、无中心、弹性可扩展、高可用、容错、一致性可调、面向
      
    
    </summary>
    
      <category term="Cassandra" scheme="https://23yue23.github.io/categories/Cassandra/"/>
    
    
      <category term="Cassandra-简介" scheme="https://23yue23.github.io/tags/Cassandra-%E7%AE%80%E4%BB%8B/"/>
    
  </entry>
  
  <entry>
    <title>flink系列之windows视窗</title>
    <link href="https://23yue23.github.io/2019/05/14/flink%E7%B3%BB%E5%88%97%E4%B9%8Bwindows%E8%A7%86%E7%AA%97/"/>
    <id>https://23yue23.github.io/2019/05/14/flink系列之windows视窗/</id>
    <published>2019-05-14T03:38:33.000Z</published>
    <updated>2019-05-14T03:39:02.448Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink-windows" scheme="https://23yue23.github.io/tags/flink-windows/"/>
    
  </entry>
  
  <entry>
    <title>flink系列之scala API</title>
    <link href="https://23yue23.github.io/2019/05/14/flink%E7%B3%BB%E5%88%97%E4%B9%8Bscala-API/"/>
    <id>https://23yue23.github.io/2019/05/14/flink系列之scala-API/</id>
    <published>2019-05-14T02:04:38.000Z</published>
    <updated>2019-05-16T09:45:26.452Z</updated>
    
    <content type="html"><![CDATA[<h5 id="scala-API-扩展"><a href="#scala-API-扩展" class="headerlink" title="scala API 扩展"></a>scala API 扩展</h5><blockquote><p>dataSet </p></blockquote> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.flink.api.scala.extensions._</span><br></pre></td></tr></table></figure><blockquote><p>dataStream</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.flink.streaming.api.scala.extensions._</span><br></pre></td></tr></table></figure><blockquote><p>将Java中的Iterable对象转换为Scala的Iterable(scala的集合操作效率高，简洁)</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.JavaConverters._</span><br><span class="line">val T1: java.lang.Iterable</span><br><span class="line">val scalaT1 = T1.asScala.toList</span><br></pre></td></tr></table></figure><p>###dataStream:</p><blockquote><p>map 采用一个元素并生成一个元素。 【DataStream→DataStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.map &#123; x =&gt; (x,1) &#125;</span><br></pre></td></tr></table></figure><blockquote><p>flatmap 采用一个元素并生成零个，一个或多个元素。 【DataStream→DataStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.flatMap &#123; str =&gt; str.split(&quot; &quot;) &#125;</span><br></pre></td></tr></table></figure><blockquote><p>filter 保留函数返回true的元素 【DataStream→DataStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.filter &#123; _ != 0 &#125;</span><br></pre></td></tr></table></figure><blockquote><p>keyBy 根据key进行分区  【DataStream→KeyedStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(&quot;someKey&quot;) // Key by field &quot;someKey&quot;</span><br><span class="line">dataStream.keyBy(0) // Key by the first element of a Tuple</span><br></pre></td></tr></table></figure><blockquote><p>reduce 滚动计算和   【KeyedStream→DataStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keyedStream.reduce &#123; _ + _ &#125;</span><br></pre></td></tr></table></figure><blockquote><p>fold 将当前元素与最后折叠的值组合并发出新值。 【KeyedStream→DataStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val result: DataStream[String] =</span><br><span class="line">    keyedStream.fold(&quot;start&quot;)((str, i) =&gt; &#123; str + &quot;-&quot; + i &#125;)</span><br><span class="line">    </span><br><span class="line">    当应用于序列（1,2,3,4,5）时发出序列“start-1”，“start-1-2”，“start-1-2-3”,. ..</span><br></pre></td></tr></table></figure><blockquote><p>聚合函数 sum <em> min </em> max <em> minBy </em> maxBy  【KeyedStream→DataStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">keyedStream.sum(0)</span><br><span class="line">keyedStream.sum(&quot;key&quot;)</span><br><span class="line">keyedStream.min(0)</span><br><span class="line">keyedStream.min(&quot;key&quot;)</span><br><span class="line">keyedStream.max(0)</span><br><span class="line">keyedStream.max(&quot;key&quot;)</span><br><span class="line">keyedStream.minBy(0)</span><br><span class="line">keyedStream.minBy(&quot;key&quot;)</span><br><span class="line">keyedStream.maxBy(0)</span><br><span class="line">keyedStream.maxBy(&quot;key&quot;)</span><br><span class="line"></span><br><span class="line">参数为tuple 的索引 或 具体的key值</span><br><span class="line">min和minBy之间的差异是min返回最小值，而minBy返回该字段中具有最小值的元素（max和maxBy相同）</span><br></pre></td></tr></table></figure><blockquote><p>Window 可以在KeyedStream上定义Windows，对每个key中的数据进行分组  【KeyedStream→WindowedStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Last 5 seconds of data</span><br><span class="line">dataStream.keyBy(0).window(TumblingEventTimeWindows.of(Time.seconds(5)))</span><br></pre></td></tr></table></figure><blockquote><p>WindowAll 在常规DataStream上定义，对所有流事件进行分组【DataStream→AllWindowedStream】</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Last 5 seconds of data</span><br><span class="line">dataStream.windowAll(TumblingEventTimeWindows.of(Time.seconds(5))) </span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line"> </span><br><span class="line">&gt; Union 联合流，创建包含来自所有流的所有元素的新流 【DataStream *→DataStream】</span><br></pre></td></tr></table></figure><p>dataStream.union(otherStream1, otherStream2, …)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Window Join  在给定密钥和公共窗口上连接两个数据流 【DataStream，DataStream→DataStream】</span><br></pre></td></tr></table></figure></p><p>dataStream.join(otherStream)<br>    .where(<key selector>).equalTo(<key selector>)<br>    .window(TumblingEventTimeWindows.of(Time.seconds(3)))<br>    .apply { … }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Connect “连接”两个保留其类型的数据流，允许两个流之间的共享状态。 【DataStream,DataStream → ConnectedStreams】</span><br></pre></td></tr></table></figure></key></key></p><p>someStream : DataStream[Int] = …<br>otherStream : DataStream[String] = …</p><p>val connectedStreams = someStream.connect(otherStream)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Split 根据某些标准将流拆分为两个或更多个流。【DataStream→SplitStream】</span><br></pre></td></tr></table></figure><p>val split = someDataStream.split(<br>  (num: Int) =&gt;<br>    (num % 2) match {<br>      case 0 =&gt; List(“even”)<br>      case 1 =&gt; List(“odd”)<br>    }<br>)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; select 从拆分流中选择一个或多个流。【SplitStream→DataStream】</span><br></pre></td></tr></table></figure></p><p>val even = split select “even”<br>val odd = split select “odd”<br>val all = split.select(“even”,”odd”)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Iterate 【DataStream → IterativeStream → DataStream】</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 从记录中提取时间戳，以便使用使用事件时间语义的窗口 【DataStream→DataStream】</span><br></pre></td></tr></table></figure></p><p>stream.assignTimestamps { timestampExtractor }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### Physical partitioning</span><br><span class="line"></span><br><span class="line">&gt; Custom partitioning 使用用户定义的分区程序为每个元素选择目标任务 【DataStream → DataStream】</span><br></pre></td></tr></table></figure></p><p>dataStream.partitionCustom(partitioner, “someKey”)<br>dataStream.partitionCustom(partitioner, 0)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Random partitioning 均匀分布随机分配元素 【DataStream → DataStream】</span><br></pre></td></tr></table></figure></p><p>dataStream.shuffle()<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Rebalancing （循环分区)分区元素循环，每个分区创建相等的负载。在存在数据偏斜时用于性能优化。   【DataStream → DataStream】</span><br></pre></td></tr></table></figure></p><p>dataStream.rebalance()<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Rescaling  【DataStream → DataStream】</span><br></pre></td></tr></table></figure></p><p>dataStream.rescale()</p><p>分区元素，循环，到下游操作的子集。如果您希望拥有管道<br>例如:<br>从源的每个并行实例扇出到多个映射器的子集以分配负载但又不希望发生rebalance（）会产生完全重新平衡，那么这非常有用。<br>这将仅需要本地数据传输而不是通过网络传输数据，具体取决于其他配置值，例如TaskManagers的插槽数。</p><p>上游操作发送元素的下游操作的子集取决于上游和下游操作的并行度。<br>例如:<br>如果上游操作具有并行性2并且下游操作具有并行性4，则一个上游操作将元素分配给两个下游操作，而另一个上游操作将分配给另外两个下游操作。<br>另一方面，如果下游操作具有并行性2而上游操作具有并行性4，那么两个上游操作将分配到一个下游操作，而另外两个上游操作将分配到其他下游操作。</p><p>在不同并行度不是彼此的倍数的情况下，一个或多个下游操作将具有来自上游操作的不同数量的输入。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">![连接模式](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/rescale.svg)</span><br><span class="line"></span><br><span class="line">&gt;Broadcasting Broadcasts elements to every partition【DataStream → DataStream】</span><br></pre></td></tr></table></figure></p><p>dataStream.broadcast()<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### Task chaining and resource groups</span><br><span class="line"></span><br><span class="line">&gt;Start new chain 从这个运算符开始，开始一个新的链。两个映射器将被链接，并且过滤器将不会链接到第一个映射器。</span><br></pre></td></tr></table></figure></p><p>someStream.filter(…).map(…).startNewChain().map(…)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;Disable chaining</span><br></pre></td></tr></table></figure></p><p>someStream.map(…).disableChaining()<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; Set slot sharing group 用于隔离插槽,将把具有相同插槽共享组的操作放入同一个插槽，同时保留其他插槽中没有插槽共享组的操作.如果所有输入操作都在同一个插槽共享组中，则插槽共享组将继承输入操作。默认插槽共享组的名称为“default”，可以通过调用slotSharingGroup（“default”）将操作显式放入此组中。</span><br></pre></td></tr></table></figure></p><p>someStream.filter(…).slotSharingGroup(“name”)<br><code>`</code></p><blockquote><p>注意：这些函数只能在DataStream转换后立即使用，因为它们引用了前一个转换。可以使用someStream.map(…).startNewChain()，但不能使用someStream.startNewChain()。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;scala-API-扩展&quot;&gt;&lt;a href=&quot;#scala-API-扩展&quot; class=&quot;headerlink&quot; title=&quot;scala API 扩展&quot;&gt;&lt;/a&gt;scala API 扩展&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;dataSet &lt;/p&gt;
&lt;/bl
      
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink-scalaAPI" scheme="https://23yue23.github.io/tags/flink-scalaAPI/"/>
    
  </entry>
  
  <entry>
    <title>代码库之邮件发送</title>
    <link href="https://23yue23.github.io/2019/05/06/%E4%BB%A3%E7%A0%81%E5%BA%93%E4%B9%8B%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81/"/>
    <id>https://23yue23.github.io/2019/05/06/代码库之邮件发送/</id>
    <published>2019-05-06T04:02:06.000Z</published>
    <updated>2019-05-06T04:08:25.547Z</updated>
    
    <content type="html"><![CDATA[<h4 id="scala-版本示例："><a href="#scala-版本示例：" class="headerlink" title="scala 版本示例："></a>scala 版本示例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">import org.slf4j.LoggerFactory</span><br><span class="line"></span><br><span class="line">import javax.mail._</span><br><span class="line">import javax.mail.internet.InternetAddress</span><br><span class="line">import javax.mail.internet.MimeMessage</span><br><span class="line">import java.util.Properties</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">object Mail &#123;</span><br><span class="line">  val logger = LoggerFactory.getLogger(Mail.getClass)</span><br><span class="line">  val bodyHtml = &quot;&lt;!DOCTYPE html PUBLIC -//W3C//DTD HTML 4.01 Transitional//ENhttp://www.w3.org/TR/html4/loose.dtd&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=Content-Type content=text/html; charset=utf-8 pageEncoding=UTF-8&gt;&lt;/head&gt;&lt;body&gt;%s&lt;/body&gt;&lt;/html&gt;&quot;</span><br><span class="line">  val prop = new Properties()</span><br><span class="line">  prop.put(&quot;mail.smtp.host&quot;,&quot;smtp.exmail.qq.com&quot;)</span><br><span class="line">  prop.put(&quot;mail.smtp.auth&quot;,&quot;true&quot;)</span><br><span class="line">  prop.put(&quot;mail.smtp.connectiontimeout&quot;,&quot;10000&quot;)</span><br><span class="line">  prop.put(&quot;mail.smtp.timeout&quot;,&quot;20000&quot;)</span><br><span class="line"></span><br><span class="line">  def send(address: String, title: String, content: String) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      val addresses = address.split(&quot;,&quot;).map(new InternetAddress(_).asInstanceOf[Address])</span><br><span class="line">      val authenticator = new SMTPAuthenticator(&quot;username@qq.com&quot;, &quot;password&quot;)</span><br><span class="line">      val sendMailSession = Session.getDefaultInstance(prop, authenticator)</span><br><span class="line">      val newMessage = new MimeMessage(sendMailSession)</span><br><span class="line">      newMessage.setFrom(new InternetAddress(&quot;username@qq.com&quot;))</span><br><span class="line">      newMessage.setRecipients(Message.RecipientType.TO, addresses)</span><br><span class="line">      newMessage.setSubject(title)</span><br><span class="line">      val html = String.format(bodyHtml, content)</span><br><span class="line">      newMessage.setContent(html, &quot;text/html;charset=utf-8&quot;)</span><br><span class="line">      Transport.send(newMessage)</span><br><span class="line">      logger.info(&quot;send an email to address[&#123;&#125;] title[&#123;&#125;] content[&#123;&#125;]&quot;, addresses, title, content);</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: MessagingException =&gt; logger.info(&quot;error occur when mail&quot;, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  class SMTPAuthenticator(username: String, password: String) extends Authenticator &#123;</span><br><span class="line">    override def getPasswordAuthentication: PasswordAuthentication = new PasswordAuthentication(username, password)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;scala-版本示例：&quot;&gt;&lt;a href=&quot;#scala-版本示例：&quot; class=&quot;headerlink&quot; title=&quot;scala 版本示例：&quot;&gt;&lt;/a&gt;scala 版本示例：&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;tabl
      
    
    </summary>
    
      <category term="代码库" scheme="https://23yue23.github.io/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/"/>
    
    
      <category term="代码-email" scheme="https://23yue23.github.io/tags/%E4%BB%A3%E7%A0%81-email/"/>
    
  </entry>
  
  <entry>
    <title>kafka系列之优化consumer</title>
    <link href="https://23yue23.github.io/2019/04/29/kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BC%98%E5%8C%96consumer-1/"/>
    <id>https://23yue23.github.io/2019/04/29/kafka系列之优化consumer-1/</id>
    <published>2019-04-29T12:49:59.000Z</published>
    <updated>2019-04-29T12:51:57.436Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="kafka" scheme="https://23yue23.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://23yue23.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka系列之优化consumer</title>
    <link href="https://23yue23.github.io/2019/04/29/kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BC%98%E5%8C%96consumer/"/>
    <id>https://23yue23.github.io/2019/04/29/kafka系列之优化consumer/</id>
    <published>2019-04-29T12:49:13.000Z</published>
    <updated>2019-04-29T12:52:17.024Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="kafka" scheme="https://23yue23.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka系列之优化producer</title>
    <link href="https://23yue23.github.io/2019/04/29/kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BC%98%E5%8C%96producer/"/>
    <id>https://23yue23.github.io/2019/04/29/kafka系列之优化producer/</id>
    <published>2019-04-29T12:46:48.000Z</published>
    <updated>2019-04-29T12:52:32.408Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="kafka" scheme="https://23yue23.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://23yue23.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka系列之基本命令</title>
    <link href="https://23yue23.github.io/2019/04/29/kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"/>
    <id>https://23yue23.github.io/2019/04/29/kafka系列之基本命令/</id>
    <published>2019-04-29T12:45:43.000Z</published>
    <updated>2019-04-29T12:46:08.720Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="kafka" scheme="https://23yue23.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://23yue23.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>spark系列之-问题汇总</title>
    <link href="https://23yue23.github.io/2019/04/29/spark%E7%B3%BB%E5%88%97%E4%B9%8B-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    <id>https://23yue23.github.io/2019/04/29/spark系列之-问题汇总/</id>
    <published>2019-04-29T12:38:35.000Z</published>
    <updated>2019-04-29T12:39:55.258Z</updated>
    
    <content type="html"><![CDATA[<h5 id="org-apache-spark-SparkException-Could-not-find-CoarseGrainedScheduler"><a href="#org-apache-spark-SparkException-Could-not-find-CoarseGrainedScheduler" class="headerlink" title="org.apache.spark.SparkException: Could not find CoarseGrainedScheduler."></a>org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.</h5><blockquote><ol><li>这个可能是一个资源问题，应该给任务分配更多的 cores 和Executors，并且分配更多的内存。并且需要给RDD分配更多的分区 </li><li>在配置资源中加入这句话也许能解决你的问题：<br> –conf spark.dynamicAllocation.enabled=false</li><li>经过一般调试，发现原来是因为spark任务生成task任务过少，而任务提交时所指定的Excutor 数过多导致，故调小 –num-executors 参数问题得以解决。</li></ol></blockquote><hr><p>##### </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;org-apache-spark-SparkException-Could-not-find-CoarseGrainedScheduler&quot;&gt;&lt;a href=&quot;#org-apache-spark-SparkException-Could-not-find-Coar
      
    
    </summary>
    
      <category term="spark" scheme="https://23yue23.github.io/categories/spark/"/>
    
    
      <category term="spark-问题" scheme="https://23yue23.github.io/tags/spark-%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Mac OS之使用</title>
    <link href="https://23yue23.github.io/2019/04/29/Mac-OS%E4%B9%8B%E4%BD%BF%E7%94%A8/"/>
    <id>https://23yue23.github.io/2019/04/29/Mac-OS之使用/</id>
    <published>2019-04-29T12:27:28.000Z</published>
    <updated>2019-05-17T06:19:41.702Z</updated>
    
    <content type="html"><![CDATA[<h4 id="快捷键："><a href="#快捷键：" class="headerlink" title="快捷键："></a>快捷键：</h4><p>退出关闭应用：Command+Q</p><hr><h4 id="目录地址："><a href="#目录地址：" class="headerlink" title="目录地址："></a>目录地址：</h4><blockquote><p>软件的安装目录</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/Library/Application Support</span><br></pre></td></tr></table></figure><blockquote><p>brew 安装路径</p></blockquote><pre><code>/usr/local/Cellar/</code></pre><h4 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h4><blockquote><p><a href="https://blog.csdn.net/k12104/article/details/84104261" target="_blank" rel="noopener">Mac Beyond Compare4 破解方法</a></p></blockquote><blockquote><p>[]</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;快捷键：&quot;&gt;&lt;a href=&quot;#快捷键：&quot; class=&quot;headerlink&quot; title=&quot;快捷键：&quot;&gt;&lt;/a&gt;快捷键：&lt;/h4&gt;&lt;p&gt;退出关闭应用：Command+Q&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&quot;目录地址：&quot;&gt;&lt;a href=&quot;#目录地址：&quot; clas
      
    
    </summary>
    
      <category term="工具" scheme="https://23yue23.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="mac-使用" scheme="https://23yue23.github.io/tags/mac-%E4%BD%BF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>经典文章</title>
    <link href="https://23yue23.github.io/2019/04/29/%E7%BB%8F%E5%85%B8%E6%96%87%E7%AB%A0/"/>
    <id>https://23yue23.github.io/2019/04/29/经典文章/</id>
    <published>2019-04-29T05:37:39.000Z</published>
    <updated>2019-05-17T05:43:46.230Z</updated>
    
    <content type="html"><![CDATA[<h4 id="技术文章"><a href="#技术文章" class="headerlink" title="技术文章"></a>技术文章</h4><blockquote><ol><li><a href="https://tech.meituan.com/2014/06/30/mysql-index.html" target="_blank" rel="noopener">MySQL索引原理及慢查询优化</a></li><li><a href="https://tech.meituan.com/2018/10/18/meishi-data-flink.html" target="_blank" rel="noopener">美团点评基于 Flink 的实时数仓建设实践</a></li><li><a href="https://mp.weixin.qq.com/s/lhP4B6jA0CQpjT1PdlYmQw" target="_blank" rel="noopener">从零开始入门推荐算法工程师</a></li></ol></blockquote><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><blockquote><ol><li><a href="https://tech.meituan.com/2018/04/16/study-vs-work.html" target="_blank" rel="noopener">工作中如何做好技术积累</a></li><li><a href="http://openskill.cn/article/488" target="_blank" rel="noopener">学习新技术的10个技巧</a></li><li><a href></a></li><li><a href></a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;技术文章&quot;&gt;&lt;a href=&quot;#技术文章&quot; class=&quot;headerlink&quot; title=&quot;技术文章&quot;&gt;&lt;/a&gt;技术文章&lt;/h4&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://tech.meituan.com/2014/06/3
      
    
    </summary>
    
      <category term="经典文章" scheme="https://23yue23.github.io/categories/%E7%BB%8F%E5%85%B8%E6%96%87%E7%AB%A0/"/>
    
    
      <category term="经典文章" scheme="https://23yue23.github.io/tags/%E7%BB%8F%E5%85%B8%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>mysql系列之-问题汇总</title>
    <link href="https://23yue23.github.io/2019/04/29/mysql%E7%B3%BB%E5%88%97%E4%B9%8B-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    <id>https://23yue23.github.io/2019/04/29/mysql系列之-问题汇总/</id>
    <published>2019-04-29T05:08:45.000Z</published>
    <updated>2019-04-29T05:10:40.170Z</updated>
    
    <content type="html"><![CDATA[<p>###om.mysql.jdbc.exceptions.jdbc4.CommunicationsException:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">om.mysql.jdbc.exceptions.jdbc4.CommunicationsException:The last packet successfully received from the server was 44,024,462 milliseconds ago.  The last packet sent successfully to the server was 44,024,462 milliseconds ago. is longer than the server configured value of &apos;wait_timeout&apos;. You should consider either expiring and/or testing connection validity before use in your application, increasing the server configured values for client timeouts, or using the Connector/J connection property &apos;autoReconnect=true&apos; to avoid this problem.</span><br></pre></td></tr></table></figure></p><p>解决方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.在连接上添加这个设置</span><br><span class="line">&amp;autoReconnect=true&amp;failOverReadOnly=false</span><br><span class="line">2.每次使用完记得归还连接</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;###om.mysql.jdbc.exceptions.jdbc4.CommunicationsException:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span cl
      
    
    </summary>
    
      <category term="mysql" scheme="https://23yue23.github.io/categories/mysql/"/>
    
    
      <category term="mysql-问题" scheme="https://23yue23.github.io/tags/mysql-%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
</feed>
