<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蜗牛笔记</title>
  
  <subtitle>骑士的心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://23yue23.github.io/"/>
  <updated>2019-04-28T08:43:44.630Z</updated>
  <id>https://23yue23.github.io/</id>
  
  <author>
    <name>Brady</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>spark系列之--调优记录</title>
    <link href="https://23yue23.github.io/2019/04/28/spark%E7%B3%BB%E5%88%97%E4%B9%8B-%E8%B0%83%E4%BC%98%E8%AE%B0%E5%BD%95/"/>
    <id>https://23yue23.github.io/2019/04/28/spark系列之-调优记录/</id>
    <published>2019-04-28T06:23:46.000Z</published>
    <updated>2019-04-28T08:43:44.630Z</updated>
    
    <content type="html"><![CDATA[<h4 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h4><blockquote><ol><li>分配资源、并行度、RDD架构与缓存</li><li>shuffle调优</li><li>spark算子调优</li><li>JVM调优、广播大变量。</li></ol></blockquote><h5 id="性能调优之在实际项目中分配更多资源："><a href="#性能调优之在实际项目中分配更多资源：" class="headerlink" title="性能调优之在实际项目中分配更多资源："></a>性能调优之在实际项目中分配更多资源：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/spark/bin/spark-submit</span><br><span class="line">--class cn.spark.sparktest.core.WordCountCluster \</span><br><span class="line">--num-executors 80 \  配置executor的数量</span><br><span class="line">--driver-memory 6g \  配置driver的内存（影响不大）</span><br><span class="line">--executor-memory 6g \  配置每个executor的内存大小</span><br><span class="line">--executor-cores 3 \  配置每个executor的cpu core数量(RDD cache/shuffle/task执行)</span><br><span class="line">--master yarn-cluster \</span><br><span class="line">--queue root.default \</span><br><span class="line">--conf spark.yarn.executor.memoryOverhead=2048 \  executor堆外内存</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \ 连接的超时时长</span><br><span class="line">/usr/local/spark/spark.jar \</span><br><span class="line">$&#123;1&#125;</span><br></pre></td></tr></table></figure><hr><h5 id="性能调优之在实际项目中调节并行度："><a href="#性能调优之在实际项目中调节并行度：" class="headerlink" title="性能调优之在实际项目中调节并行度："></a>性能调优之在实际项目中调节并行度：</h5><blockquote><ol><li>并行度：其实就是指的是，Spark作业中，各个stage的task数量，也就代表了Spark作业的在各个阶段（stage）的并行度。</li><li>官方是推荐，task数量，设置成spark application总cpu core数量的2~3倍，比如150个cpu core，基本要设置task数量为300~500；</li><li>SparkConf conf = new SparkConf().set(“spark.default.parallelism”, “500”)</li></ol></blockquote><hr><h5 id="性能调优之在实际项目中重构RDD架构以及RDD持久化："><a href="#性能调优之在实际项目中重构RDD架构以及RDD持久化：" class="headerlink" title="性能调优之在实际项目中重构RDD架构以及RDD持久化："></a>性能调优之在实际项目中重构RDD架构以及RDD持久化：</h5><blockquote><ol><li>RDD架构重构与优化</li><li>公共RDD一定要实现持久化,对于要多次计算和使用的公共RDD，一定要进行持久化。</li><li>持久化，是可以进行序列化的<br>sessionid2actionRDD=sessionid2actionRDD.persist(StorageLevel.MEMORY_ONLY());<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MEMORY_ONLY    直接以Java对象的形式存储于JVM的内存中</span><br><span class="line">MYMORY_AND_DISK    存储于JVM的内存+磁盘</span><br><span class="line">MEMORY_ONLY_SER    序列化存储于内存中</span><br><span class="line">MEMORY_AND_DISK_SER    序列化存储于内存+磁盘</span><br></pre></td></tr></table></figure></code></pre></li></ol></blockquote><blockquote><ol start="4"><li>为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化</li></ol></blockquote><hr><h5 id="性能调优之在实际项目中广播大变量（1m-100m）："><a href="#性能调优之在实际项目中广播大变量（1m-100m）：" class="headerlink" title="性能调优之在实际项目中广播大变量（1m~100m）："></a>性能调优之在实际项目中广播大变量（1m~100m）：</h5><blockquote><ol><li>默认的情况下，task执行的算子中，使用了外部的变量，每个task都会获取一份变量的副本，有什么缺点呢？<pre><code>网络传输的开销、耗费内存、RDD持久化到内存（内存不够，持续到磁盘）、task创建对象导致gc；</code></pre></li></ol></blockquote><blockquote><ol start="2"><li>广播变量，初始的时候，就在Drvier上有一份副本。</li></ol></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；</span><br><span class="line">如果本地没有，那么就从Driver远程拉取变量副本，并保存在本地的BlockManager中；</span><br><span class="line">此后这个executor上的task，都会直接使用本地的BlockManager中的副本。</span><br><span class="line">executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，举例越近越好。</span><br><span class="line">sc.boradcast();</span><br></pre></td></tr></table></figure><hr><h5 id="性能调优之在实际项目中使用Kryo序列化"><a href="#性能调优之在实际项目中使用Kryo序列化" class="headerlink" title="性能调优之在实际项目中使用Kryo序列化:"></a>性能调优之在实际项目中使用Kryo序列化:</h5><blockquote><ol><li>默认情况下，Spark内部是使用Java的序列化机制，ObjectOutputStream / ObjectInputStream，对象输入输出流机制，来进行序列化。</li><li>Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。</li><li>Kryo序列化机制，一旦启用以后，会生效的几个地方：<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1、算子函数中使用到的外部变量</span><br><span class="line">2、持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER</span><br><span class="line">3、shuffle</span><br><span class="line">    .set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">    .registerKryoClasses(new Class[]&#123;CategorySortKey.class&#125;)</span><br></pre></td></tr></table></figure></code></pre></li></ol></blockquote><blockquote><ol start="4"><li>序列化<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2、注册你使用到的，需要通过Kryo序列化的，一些自定义类，SparkConf.registerKryoClasses()</span><br></pre></td></tr></table></figure></code></pre></li></ol></blockquote><hr><h5 id="性能调优之在实际项目中使用fastutil优化数据格式"><a href="#性能调优之在实际项目中使用fastutil优化数据格式" class="headerlink" title="性能调优之在实际项目中使用fastutil优化数据格式:"></a>性能调优之在实际项目中使用fastutil优化数据格式:</h5><blockquote><ol><li>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；</li><li>fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set，好处在于，fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度；</li></ol></blockquote><p>fastutil也提供了64位的array、set和list，以及高性能快速的，以及实用的IO类，来处理二进制和文本类型的文件；fastutil最新版本要求Java 7以及以上版本；</p><p>fastutil的每一种集合类型，都实现了对应的Java中的标准接口（比如fastutil的map，实现了Java的Map接口），因此可以直接放入已有系统的任何代码中。</p><p>fastutil还提供了一些JDK标准类库中没有的额外功能（比如双向迭代器）。<br>fastutil除了对象和原始类型为元素的集合，fastutil也提供引用类型的支持，但是对引用类型是使用等于号（=）进行比较的，而不是equals()方法。</p><blockquote><ol start="3"><li>maven 依赖<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;fastutil&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;fastutil&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;5.0.9&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li></ol></blockquote><hr><h5 id="性能调优之在实际项目中调节数据本地化等待时长："><a href="#性能调优之在实际项目中调节数据本地化等待时长：" class="headerlink" title="性能调优之在实际项目中调节数据本地化等待时长："></a>性能调优之在实际项目中调节数据本地化等待时长：</h5><blockquote><ol><li>PROCESS_LOCAL：进程本地化；NODE_LOCAL：节点本地化；NO_PREF：对于task来说，没有好坏之分；RACK_LOCAL：机架本地化；ANY：数据和task可能在集群中的任何地方，而且不在一个机架中，性能最差；</li><li>观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。<br>日志里面会显示，starting task。。。，PROCESS LOCAL（不用调节）、NODE LOCAL、ANY（调节一下数据本地化的等待时长），反复调节，每次调节完以后，再来运行，观察日志</li><li>怎么调节？<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark.locality.wait，默认是3s；6s，10s</span><br><span class="line">默认情况下，下面3个的等待时长，都是跟上面那个是一样的，都是3s</span><br><span class="line">spark.locality.wait.process</span><br><span class="line">spark.locality.wait.node</span><br><span class="line">spark.locality.wait.rack</span><br><span class="line">new SparkConf()</span><br><span class="line">  .set(&quot;spark.locality.wait&quot;, &quot;10&quot;)</span><br></pre></td></tr></table></figure></li></ol></blockquote><hr><h4 id="JVM-调优"><a href="#JVM-调优" class="headerlink" title="JVM 调优"></a>JVM 调优</h4><h5 id="JVM调优之原理概述以及降低cache操作的内存占比"><a href="#JVM调优之原理概述以及降低cache操作的内存占比" class="headerlink" title="JVM调优之原理概述以及降低cache操作的内存占比:"></a>JVM调优之原理概述以及降低cache操作的内存占比:</h5><blockquote><ol><li>full gc / minor gc，无论是快，还是慢，都会导致jvm的工作线程停止工作，stop the world。简而言之，就是说，gc的时候，spark停止工作了。等着垃圾回收结束。</li><li>spark中，堆内存又被划分成了两块儿，存储内存和执行内存；<pre><code>一句话，让task执行算子函数时，有更多的内存可以使用。</code></pre></li></ol></blockquote><hr><h5 id="JVM调优之调节executor堆外内存与连接等待时长-在spark-sbmit中修改-："><a href="#JVM调优之调节executor堆外内存与连接等待时长-在spark-sbmit中修改-：" class="headerlink" title="JVM调优之调节executor堆外内存与连接等待时长(在spark-sbmit中修改)："></a>JVM调优之调节executor堆外内存与连接等待时长(在spark-sbmit中修改)：</h5><blockquote><ol><li>有时候，如果你的spark作业处理的数据量特别特别大，几亿数据量；然后spark作业一运行，时不时的报错，shuffle file cannot find，executor、task lost，out of memory（内存溢出）；–conf spark.yarn.executor.memoryOverhead=2048</li><li>有时候，无法建立网络连接；会卡住；ok，spark默认的网络连接的超时时长，是60s；如果卡住60s都无法建立连接的话，那么就宣告失败了:一串file id。uuid（dsfsfd-2342vs–sdf–sdfsd）。not found。file lost。<br> –conf spark.core.connection.ack.wait.timeout=300</li></ol></blockquote><hr><h4 id="Shuffle调优"><a href="#Shuffle调优" class="headerlink" title="Shuffle调优"></a>Shuffle调优</h4><h5 id="Shuffle调优之原理概述："><a href="#Shuffle调优之原理概述：" class="headerlink" title="Shuffle调优之原理概述："></a>Shuffle调优之原理概述：</h5><blockquote><ol><li>在spark中，主要是以下几个算子：groupByKey、reduceByKey、countByKey、join，等等。</li><li>shuffle，一定是分为两个stage来完成的。因为这其实是个逆向的过程，不是stage决定shuffle，是shuffle决定stage。</li><li>shuffle前半部分的task在写入数据到磁盘文件之前，都会先写入一个一个的内存缓冲，内存缓冲满溢之后，再spill溢写到磁盘文件中。</li></ol></blockquote><hr><h5 id="Shuffle调优之合并map端输出文件："><a href="#Shuffle调优之合并map端输出文件：" class="headerlink" title="Shuffle调优之合并map端输出文件："></a>Shuffle调优之合并map端输出文件：</h5><blockquote><ol><li>开启shuffle map端输出文件合并的机制；默认情况下，是不开启的，就是会发生如上所述的大量map端输出文件的操作，严重影响性能。</li><li>new SparkConf().set(“spark.shuffle.consolidateFiles”, “true”)<br>new SparkConf().set(“spark.shuffle.consolidateFiles”, “true”)</li></ol></blockquote><hr><h5 id="Shuffle调优之合并map端输出文件：-1"><a href="#Shuffle调优之合并map端输出文件：-1" class="headerlink" title="Shuffle调优之合并map端输出文件："></a>Shuffle调优之合并map端输出文件：</h5><blockquote><ol><li>map端内存缓冲：spark.shuffle.file.buffer，默认32k  <pre><code>reduce端内存占比：spark.shuffle.memoryFraction，0.2</code></pre></li><li>调节的时候的原则。spark.shuffle.file.buffer，每次扩大一倍，然后看看效果，64，128；<br>spark.shuffle.memoryFraction，每次提高0.1，看看效果。<br>不能调节的太大，太大了以后过犹不及，因为内存资源是有限的，你这里调节的太大了，其他环节的内存使用就会有问题了。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">new SparkConf().set(&quot;spark.shuffle.file.buffer&quot;, &quot;64&quot;)</span><br><span class="line">new SparkConf().set(&quot;spark.shuffle.memoryFraction&quot;, &quot;0.3&quot;)</span><br></pre></td></tr></table></figure></li></ol></blockquote><hr><h5 id="Shuffle调优之HashShuffleManager与SortShuffleManager"><a href="#Shuffle调优之HashShuffleManager与SortShuffleManager" class="headerlink" title="Shuffle调优之HashShuffleManager与SortShuffleManager"></a>Shuffle调优之HashShuffleManager与SortShuffleManager</h5><blockquote><ol><li>spark.shuffle.manager：hash、sort、tungsten-sort（自己实现内存管理），spark 1.2.x版本以后，默认的shuffle manager，是SortShuffleManager。<br>   spark.shuffle.sort.bypassMergeThreshold：200（默认值为200）</li><li>SortShuffleManager会避免像HashShuffleManager那样，默认就去创建多份磁盘文件。一个task，只会写入一个磁盘文件，不同reduce task的数据，用offset来划分界定。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">new SparkConf().set(&quot;spark.shuffle.manager&quot;, &quot;sort&quot;)</span><br><span class="line">new SparkConf().set(&quot;spark.shuffle.sort.bypassMergeThreshold&quot;, &quot;550&quot;)</span><br></pre></td></tr></table></figure></li></ol></blockquote><hr><h4 id="算子调优"><a href="#算子调优" class="headerlink" title="算子调优"></a>算子调优</h4><h5 id="算子调优之MapPartitions提升Map类操作性能"><a href="#算子调优之MapPartitions提升Map类操作性能" class="headerlink" title="算子调优之MapPartitions提升Map类操作性能:"></a>算子调优之MapPartitions提升Map类操作性能:</h5><blockquote><ol><li>如果是普通的map，比如一个partition中有1万条数据；function要执行和计算1万次。但是，使用MapPartitions操作之后，一个task仅仅会执行一次function，function一次接收所有的partition数据。只要执行一次就可以了，性能比较高。</li><li>但是，可能就OOM，内存溢出。   </li></ol></blockquote><hr><h5 id="算子调优之filter过后使用coalesce减少分区数量："><a href="#算子调优之filter过后使用coalesce减少分区数量：" class="headerlink" title="算子调优之filter过后使用coalesce减少分区数量："></a>算子调优之filter过后使用coalesce减少分区数量：</h5><blockquote><ol><li>就会导致有些task运行的速度很快；有些task运行的速度很慢。这就是数据倾斜。</li><li>coalesce算子：主要就是用于在filter操作之后，针对每个partition的数据量各不相同的情况，来压缩partition的数量。减少partition的数量，而且让每个partition的数据量都尽量均匀紧凑。</li></ol></blockquote><hr><h5 id="算子调优之使用foreachPartition优化写数据库性能："><a href="#算子调优之使用foreachPartition优化写数据库性能：" class="headerlink" title="算子调优之使用foreachPartition优化写数据库性能："></a>算子调优之使用foreachPartition优化写数据库性能：</h5><pre><code>&gt; 1. 用了foreachPartition算子之后，好处在哪里？    1、对于我们写的function函数，就调用一次，一次传入一个partition所有数据；    2、主要创建或者获取一个数据库连接就可以；    3、只要向数据库发送一次SQL语句和多组参数即可；&gt; 2. 很有可能会发生OOM，内存溢出的问题。    一个partition大概是1千条左右用foreach，跟用foreachPartition，性能的提升达到了2~3分钟。</code></pre><hr><h5 id="算子调优之使用repartition解决Spark-SQL低并行度的性能问题："><a href="#算子调优之使用repartition解决Spark-SQL低并行度的性能问题：" class="headerlink" title="算子调优之使用repartition解决Spark SQL低并行度的性能问题："></a>算子调优之使用repartition解决Spark SQL低并行度的性能问题：</h5><pre><code>repartition算子，你用Spark SQL这一步的并行度和task数量，肯定是没有办法去改变了。但是呢，可以将你用Spark SQL查询出来的RDD，使用repartition算子，去重新进行分区，此时可以分区成多个partition，比如从20个partition，分区成100个。</code></pre><hr><h5 id="算子调优之reduceByKey本地聚合介绍："><a href="#算子调优之reduceByKey本地聚合介绍：" class="headerlink" title="算子调优之reduceByKey本地聚合介绍："></a>算子调优之reduceByKey本地聚合介绍：</h5><pre><code>reduceByKey，相较于普通的shuffle操作（比如groupByKey），它的一个特点，就是说，会进行map端的本地聚合</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;性能调优&quot;&gt;&lt;a href=&quot;#性能调优&quot; class=&quot;headerlink&quot; title=&quot;性能调优&quot;&gt;&lt;/a&gt;性能调优&lt;/h4&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;分配资源、并行度、RDD架构与缓存&lt;/li&gt;
&lt;li&gt;shuffle调优&lt;/li&gt;
&lt;
      
    
    </summary>
    
      <category term="spark" scheme="https://23yue23.github.io/categories/spark/"/>
    
    
      <category term="spark" scheme="https://23yue23.github.io/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>1.grafana系列之--调研</title>
    <link href="https://23yue23.github.io/2019/04/28/1-grafana%E7%B3%BB%E5%88%97%E4%B9%8B-%E8%B0%83%E7%A0%94/"/>
    <id>https://23yue23.github.io/2019/04/28/1-grafana系列之-调研/</id>
    <published>2019-04-28T03:38:55.000Z</published>
    <updated>2019-04-28T03:50:06.402Z</updated>
    
    <content type="html"><![CDATA[<h5 id="参考地址："><a href="#参考地址：" class="headerlink" title="参考地址："></a>参考地址：</h5><blockquote><ol><li><a href="https://grafana.com" target="_blank" rel="noopener">官网</a></li><li><a href="https://grafana.com/docs/tutorials/screencasts/" target="_blank" rel="noopener">官网视频</a></li></ol></blockquote><h5 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h5><blockquote><ol><li><a href="https://grafana.com/docs/plugins/installation/" target="_blank" rel="noopener">插件安装步骤</a></li><li><a href="https://grafana.com/plugins" target="_blank" rel="noopener">插件搜索</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;参考地址：&quot;&gt;&lt;a href=&quot;#参考地址：&quot; class=&quot;headerlink&quot; title=&quot;参考地址：&quot;&gt;&lt;/a&gt;参考地址：&lt;/h5&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://grafana.com&quot; target=&quot;_
      
    
    </summary>
    
      <category term="grafana" scheme="https://23yue23.github.io/categories/grafana/"/>
    
    
      <category term="grafana" scheme="https://23yue23.github.io/tags/grafana/"/>
    
  </entry>
  
  <entry>
    <title>3.1-flink系列之--数据类型和序列化</title>
    <link href="https://23yue23.github.io/2019/04/26/3-1-flink%E7%B3%BB%E5%88%97%E4%B9%8B-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://23yue23.github.io/2019/04/26/3-1-flink系列之-数据类型和序列化/</id>
    <published>2019-04-26T06:38:37.000Z</published>
    <updated>2019-04-26T08:45:18.573Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink" scheme="https://23yue23.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>2.2-flink系列之--分布式运行环境</title>
    <link href="https://23yue23.github.io/2019/04/26/2-2-flink%E7%B3%BB%E5%88%97%E4%B9%8B-%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/"/>
    <id>https://23yue23.github.io/2019/04/26/2-2-flink系列之-分布式运行环境/</id>
    <published>2019-04-26T06:29:56.000Z</published>
    <updated>2019-04-26T08:45:11.765Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink" scheme="https://23yue23.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>2.1-flink系列之--编程模型</title>
    <link href="https://23yue23.github.io/2019/04/26/2-1-flink%E7%B3%BB%E5%88%97%E4%B9%8B-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
    <id>https://23yue23.github.io/2019/04/26/2-1-flink系列之-编程模型/</id>
    <published>2019-04-26T06:29:27.000Z</published>
    <updated>2019-04-26T08:45:20.292Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink" scheme="https://23yue23.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列之--学习网站 (实时更新)</title>
    <link href="https://23yue23.github.io/2019/04/26/flink%E7%B3%BB%E5%88%97%E4%B9%8B-%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"/>
    <id>https://23yue23.github.io/2019/04/26/flink系列之-学习网站/</id>
    <published>2019-04-26T06:02:29.000Z</published>
    <updated>2019-04-26T12:30:31.810Z</updated>
    
    <content type="html"><![CDATA[<h4 id="flink-学习（系列）"><a href="#flink-学习（系列）" class="headerlink" title="flink 学习（系列）"></a>flink 学习（系列）</h4><blockquote><ol><li><a href="https://flink.apache.org/" target="_blank" rel="noopener">flink官网</a></li><li><a href="https://training.ververica.com" target="_blank" rel="noopener">training</a></li><li><a href="https://github.com/flink-china/flink-training-course/blob/master/%E8%AF%BE%E7%A8%8B%E8%A1%A8%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89.md" target="_blank" rel="noopener">flink-阿里巴巴课程</a></li><li><a href="https://blog.csdn.net/yanghua_kobe/column/info/apacheflink" target="_blank" rel="noopener">flink-vinoYang博客</a></li><li><a href="http://wuchong.me/" target="_blank" rel="noopener">flink-云邪博客</a></li><li><a href="https://blog.csdn.net/liguohuabigdata/article/category/7279020" target="_blank" rel="noopener">云星数据-大数据团队</a></li></ol></blockquote><hr><h4 id="flink-代码"><a href="#flink-代码" class="headerlink" title="flink 代码"></a>flink 代码</h4><blockquote><ol><li><a href="https://github.com/apache/flink" target="_blank" rel="noopener">flink</a></li><li><a href="https://github.com/zhisheng17/flink-learning/" target="_blank" rel="noopener">flink-learning</a></li><li><a href="https://github.com/ververica" target="_blank" rel="noopener">flink-training-exercises</a></li></ol></blockquote><hr><h4 id="flink-书籍"><a href="#flink-书籍" class="headerlink" title="flink 书籍"></a>flink 书籍</h4><blockquote><ol><li>flink基础教程</li><li>[#]</li></ol></blockquote><hr><h4 id="博客-单篇"><a href="#博客-单篇" class="headerlink" title="博客(单篇)"></a>博客(单篇)</h4><blockquote><ol><li><a href="https://www.ververica.com/what-is-stream-processing" target="_blank" rel="noopener">什么是流处理</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;flink-学习（系列）&quot;&gt;&lt;a href=&quot;#flink-学习（系列）&quot; class=&quot;headerlink&quot; title=&quot;flink 学习（系列）&quot;&gt;&lt;/a&gt;flink 学习（系列）&lt;/h4&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink-学习" scheme="https://23yue23.github.io/tags/flink-%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>flink系列之--问题汇总（实时更新）</title>
    <link href="https://23yue23.github.io/2019/04/26/flink%E7%B3%BB%E5%88%97%E4%B9%8B-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%EF%BC%88%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <id>https://23yue23.github.io/2019/04/26/flink系列之-问题汇总（实时更新）/</id>
    <published>2019-04-26T05:21:39.000Z</published>
    <updated>2019-04-26T06:53:34.567Z</updated>
    
    <content type="html"><![CDATA[<h4 id="隐式转换器的异常："><a href="#隐式转换器的异常：" class="headerlink" title="隐式转换器的异常："></a>隐式转换器的异常：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">确保导入：</span><br><span class="line">import org.apache.flink.streaming.api.scala._（DataStream API）</span><br><span class="line">import org.apache.flink.api.scala._（DataSet API）</span><br></pre></td></tr></table></figure><hr><h4 id="如果在使用泛型参数的函数或类中使用Flink操作，则TypeInformation必须可用于该参数。这可以通过使用上下文绑定来实现"><a href="#如果在使用泛型参数的函数或类中使用Flink操作，则TypeInformation必须可用于该参数。这可以通过使用上下文绑定来实现" class="headerlink" title="如果在使用泛型参数的函数或类中使用Flink操作，则TypeInformation必须可用于该参数。这可以通过使用上下文绑定来实现"></a>如果在使用泛型参数的函数或类中使用Flink操作，则TypeInformation必须可用于该参数。这可以通过使用上下文绑定来实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def myFunction[T: TypeInformation](input: DataSet[T]): DataSet[Seq[T]] = &#123;</span><br><span class="line">  input.reduceGroup( i =&gt; i.toSeq )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h4 id="ClassCastException：X无法强制转换为X"><a href="#ClassCastException：X无法强制转换为X" class="headerlink" title="ClassCastException：X无法强制转换为X"></a>ClassCastException：X无法强制转换为X</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.尝试classloader.resolve-order: parent-first在配置中进行设置</span><br><span class="line">2.从不同的执行尝试缓存类</span><br><span class="line">3.通过child-first类加载进行类复制</span><br></pre></td></tr></table></figure><hr><h4 id="AbstractMethodError或NoSuchFieldError"><a href="#AbstractMethodError或NoSuchFieldError" class="headerlink" title="AbstractMethodError或NoSuchFieldError"></a>AbstractMethodError或NoSuchFieldError</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">存在依赖项版本冲突,确保所有依赖项版本都一致。</span><br></pre></td></tr></table></figure><hr><h4 id="事件正在进行，DataStream应用程序不产生任何输出"><a href="#事件正在进行，DataStream应用程序不产生任何输出" class="headerlink" title="事件正在进行，DataStream应用程序不产生任何输出"></a>事件正在进行，DataStream应用程序不产生任何输出</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.如果您的DataStream应用程序使用事件时间，请检查您的水印是否已更新。</span><br><span class="line">  如果没有产生水印，事件时间窗口可能永远不会触发，应用程序将不会产生任何结果。</span><br><span class="line">2.您可以在Flink的Web UI（水印部分）中查看水印是否正在取得进展。</span><br></pre></td></tr></table></figure><hr><h4 id="exception-reporting-“Insufficient-number-of-network-buffers”"><a href="#exception-reporting-“Insufficient-number-of-network-buffers”" class="headerlink" title="exception reporting “Insufficient number of network buffers”"></a>exception reporting “Insufficient number of network buffers”</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.原因可能：以很高的并发来执行flink ,增加了网络缓冲区的数量。</span><br><span class="line">  默认情况下，Flink占用网络缓冲区的JVM堆大小的10％，最小为64MB，最大为1GB。</span><br><span class="line">2.可以通过修改一下以下参数来调整：</span><br><span class="line">taskmanager.network.memory.fraction</span><br><span class="line">taskmanager.network.memory.min</span><br><span class="line">taskmanager.network.memory.max</span><br></pre></td></tr></table></figure><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/config.html#configuring-the-network-buffers" title="flink 配置信息" target="_blank" rel="noopener">flink 配置信息</a></p><hr><h4 id="由于javadoc错误无法构建maven项目"><a href="#由于javadoc错误无法构建maven项目" class="headerlink" title="由于javadoc错误无法构建maven项目"></a>由于javadoc错误无法构建maven项目</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">三个选择：</span><br><span class="line">1.修复错误</span><br><span class="line">2.禁用严格检查</span><br><span class="line">3.在建造时跳过Javadoc</span><br><span class="line"></span><br><span class="line">&lt;plugins&gt;</span><br><span class="line">  &lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">      &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">  &lt;/plugin&gt;</span><br><span class="line">&lt;/plugins&gt;</span><br><span class="line"></span><br><span class="line">构建时跳过javadoc</span><br><span class="line">mvn -Dmaven.javadoc.skip=true verify</span><br></pre></td></tr></table></figure><p>参考：</p><blockquote><p>flink官网：<a href="https://flink.apache.org/gettinghelp.html" target="_blank" rel="noopener">https://flink.apache.org/gettinghelp.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;隐式转换器的异常：&quot;&gt;&lt;a href=&quot;#隐式转换器的异常：&quot; class=&quot;headerlink&quot; title=&quot;隐式转换器的异常：&quot;&gt;&lt;/a&gt;隐式转换器的异常：&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;t
      
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink-问题" scheme="https://23yue23.github.io/tags/flink-%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>1.flink系列之--为什么要学习flink</title>
    <link href="https://23yue23.github.io/2019/04/26/1-flink%E7%B3%BB%E5%88%97%E4%B9%8B-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0flink/"/>
    <id>https://23yue23.github.io/2019/04/26/1-flink系列之-为什么要学习flink/</id>
    <published>2019-04-26T04:39:33.000Z</published>
    <updated>2019-04-26T04:45:11.285Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是flink"><a href="#什么是flink" class="headerlink" title="什么是flink"></a>什么是flink</h4><blockquote><p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。</p></blockquote><h4 id="flink-特点"><a href="#flink-特点" class="headerlink" title="flink 特点:"></a>flink 特点:</h4><blockquote><ol><li>其异步和增量检查点算法确保对处理延迟的影响最小，同时保证一次性状态一致性。<ol start="2"><li>随处部署应用程序: 常见的集群资源管理器（如Hadoop YARN，Apache Mesos和Kubernetes）集成，但也可以设置为作为独立集群运行</li></ol></li><li>处理无界和有界数据</li><li>充分利用内存性能: 任务状态始终保留在内存中，如果状态大小超过可用内存，则保存在访问高效的磁盘上数据结构中<br><img src="https://flink.apache.org/img/local-state.png" alt title="flink 使用内存保存状态"><ul><li>性能：每天处理数万亿个事件；维护多个TB的状态；在数千个内核的运行</li></ul></li></ol></blockquote><hr><h4 id="flink丰富状态功能："><a href="#flink丰富状态功能：" class="headerlink" title="flink丰富状态功能："></a>flink丰富状态功能：</h4><blockquote><ol><li>多状态基元：Flink为不同的数据结构提供状态基元，例如原子值，列表或映射。</li><li>可插拔状态后端：应用程序状态由可插拔状态后端管理和检查点。(内存或RocksDB 存储或自定义)</li><li>完全一次的状态一致性。</li><li>非常大的状态：由于其异步和增量检查点算法，Flink能够维持几兆兆字节的应用程序状态。</li><li>可扩展的应用程序：Flink通过将状态重新分配给更多或更少的工作人员来支持有状态应用程序的扩展。</li></ol></blockquote><hr><h4 id="flink-的容错机制："><a href="#flink-的容错机制：" class="headerlink" title="flink 的容错机制："></a>flink 的容错机制：</h4><blockquote><ol><li>一致的检查点: 如果发生故障，将重新启动应用程序并从最新检查点加载其状态,此功能可以保证一次性状态一致性。</li><li>高效检查点: Flink可以执行异步和增量检查点，以便将检查点对应用程序的延迟SLA的影响保持在非常小的水平。</li><li>端到端完全一次: Flink为特定存储系统提供事务接收器，保证数据只写出一次，即使出现故障</li><li>与集群管理器集成: Flink与集群管理器紧密集成，例如Hadoop YARN，Mesos或Kubernetes。当进程失败时，将自动启动一个新进程来接管其工作。</li><li>高可用性设置: Flink具有高可用性模式，可消除所有单点故障。HA模式基于Apache ZooKeeper，这是一种经过验证的可靠分布式协调服务。</li><li>Savepoints操作：用于启动状态兼容的应用程序并初始化其状态。<blockquote><p>适用场景：</p><ol><li>程序版本升级。</li><li>程序迁移集群。</li><li>flink 版本更新。</li><li>暂停和恢复、存档。 </li><li>A/B测试：启动同一保存点的所有版本来比较两个（或更多）不同版本的应用程序的性能或质量。</li></ol></blockquote></li></ol></blockquote><hr><h4 id="flink-丰富time功能"><a href="#flink-丰富time功能" class="headerlink" title="flink 丰富time功能:"></a>flink 丰富time功能:</h4><blockquote><ol><li>Event-time Mode(事件时间):根据事件的时间戳计算结果</li><li>Watermark Support（水印支持）:使用水印来推断事件时间应用中的时间，也可以使用水印来推断事件时间应用中的时间。</li><li>Late Data Handling(延迟数据处理):当使用水印在事件 - 时间模式下处理流时，可能会在所有相关事件到达之前完成计算.</li><li>Processing-time Mode(处理时间):由处理机器的挂钟时间触发的计算,处理时间模式适用于具有严格的低延迟要求的某些应用，这些要求可以容忍近似结果.</li></ol></blockquote><hr><h4 id="flink-分层API"><a href="#flink-分层API" class="headerlink" title="flink 分层API:"></a>flink 分层API:</h4><blockquote><p><img src="https://flink.apache.org/img/api-stack.png" alt title="flink 分层API"></p></blockquote><blockquote><ol><li>ProcessFunctions:提供对时间和状态的细粒度控制,可以任意修改其状态并注册将在未来触发回调函数的定时器,因此，它可以根据许多有状态事件驱动的应用程序的需要实现复杂的事件业务逻辑:open -&gt; processElement -&gt; onTimer（<a href="https://flink.apache.org/usecases.html#eventDrivenApps" target="_blank" rel="noopener">相关介绍</a>）</li><li>DataStream API: 提供了许多常见的流处理操作，如窗口，记录在-A-时间变换，并丰富事件原语</li><li>SQL和Table API: Table API和SQL利用Apache Calcite进行解析，验证和查询优化,它们可以与DataStream和DataSet API无缝集成，并支持用户定义的标量，聚合和表值函数。</li></ol></blockquote><hr><h4 id="flink-Libraries"><a href="#flink-Libraries" class="headerlink" title="flink Libraries:"></a>flink Libraries:</h4><blockquote><ol><li>复杂事件处理（CEP）:CEP库的应用包括网络入侵检测，业务流程监控和欺诈检测。</li><li>DataSet API: 用于批处理应用程序的核心API。</li><li>Gelly：Gelly是一个可扩展的图形处理和分析库。</li></ol></blockquote><hr><h4 id="flink-监控方式："><a href="#flink-监控方式：" class="headerlink" title="flink 监控方式："></a>flink 监控方式：</h4><blockquote><ol><li>Web UI:可以检查，监视和调试正在运行的应用程序。</li><li>日志记录：Flink实现了流行的slf4j日志记录界面，并与日志框架log4j或logback集成。</li><li>指标：Flink具有复杂的指标系统，可收集和报告系统和用户定义的指标。</li><li>REST API：Flink公开REST API以提交新应用程序，获取正在运行的应用程序的保存点或取消应用程序。</li></ol></blockquote><hr><p>参考：</p><blockquote><p>flink官网: <a href="https://flink.apache.org/flink-applications.html" target="_blank" rel="noopener">https://flink.apache.org/flink-applications.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;什么是flink&quot;&gt;&lt;a href=&quot;#什么是flink&quot; class=&quot;headerlink&quot; title=&quot;什么是flink&quot;&gt;&lt;/a&gt;什么是flink&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Apache Flink是一个框架和分布式处理引擎，用于对无界和有
      
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink" scheme="https://23yue23.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>markDown-使用</title>
    <link href="https://23yue23.github.io/2019/04/25/markDown-%E4%BD%BF%E7%94%A8/"/>
    <id>https://23yue23.github.io/2019/04/25/markDown-使用/</id>
    <published>2019-04-25T07:37:41.000Z</published>
    <updated>2019-04-25T09:45:23.911Z</updated>
    
    <content type="html"><![CDATA[<h6 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># h1  最大</span><br><span class="line">## h2</span><br><span class="line">### h3</span><br><span class="line">#### h4</span><br><span class="line">##### h5</span><br><span class="line">###### h6 最小</span><br></pre></td></tr></table></figure><hr><h6 id="段落及区块引用"><a href="#段落及区块引用" class="headerlink" title="段落及区块引用"></a>段落及区块引用</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;</span><br></pre></td></tr></table></figure><hr><h6 id="插入链接和图片"><a href="#插入链接和图片" class="headerlink" title="插入链接和图片"></a>插入链接和图片</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">链接 []()</span><br><span class="line">[点击跳转至百度](http://www.baidu.com)</span><br><span class="line">图片 ![图片alt](图片地址 &apos;&apos;图片title&apos;&apos;)</span><br><span class="line">![图片](https://user-gold-cdn.xitu.io/2018/4/18/162d75d959444389?w=1240&amp;h=703&amp;f=jpeg&amp;s=56927)</span><br></pre></td></tr></table></figure><hr><h6 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">* | + | - 是无序列表</span><br><span class="line">1. 数字点加空格 是有序列表</span><br><span class="line"></span><br><span class="line">列表中加入了区块引用，区域引用标记符也需要缩进4个空格</span><br><span class="line">上一级和下一级之间敲三个空格即可</span><br><span class="line">示例：</span><br><span class="line">* 段落一</span><br><span class="line">    &gt; 区块标记一</span><br><span class="line">      &gt;&gt;区块标记二</span><br><span class="line">* 段落二</span><br><span class="line">    &gt; 区块标记二</span><br></pre></td></tr></table></figure><hr><h6 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">***</span><br></pre></td></tr></table></figure><hr><h6 id="强调"><a href="#强调" class="headerlink" title="强调"></a>强调</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">*这里是斜体*</span><br><span class="line">**这里是加粗**</span><br><span class="line">***这里是斜线加粗***</span><br><span class="line">～～这里是删除线～～</span><br></pre></td></tr></table></figure><hr><h6 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">单行代码：单反引号包裹</span><br><span class="line">代码块：三个反引号包裹。</span><br></pre></td></tr></table></figure><hr><h6 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">表头|条目一|条目二</span><br><span class="line">:---:|:---:|:---:</span><br><span class="line">项目|项目一|项目二</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">第二行分割表头和内容。</span><br><span class="line">- 有一个就行，为了对齐，多加了几个</span><br><span class="line">文字默认居左</span><br><span class="line">-两边加：表示文字居中</span><br><span class="line">-右边加：表示文字居右</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;标签&quot;&gt;&lt;a href=&quot;#标签&quot; class=&quot;headerlink&quot; title=&quot;标签&quot;&gt;&lt;/a&gt;标签&lt;/h6&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span 
      
    
    </summary>
    
      <category term="工具" scheme="https://23yue23.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="https://23yue23.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>启程</title>
    <link href="https://23yue23.github.io/2019/04/24/%E5%90%AF%E7%A8%8B/"/>
    <id>https://23yue23.github.io/2019/04/24/启程/</id>
    <published>2019-04-24T06:02:32.000Z</published>
    <updated>2019-04-24T08:36:28.646Z</updated>
    
    <content type="html"><![CDATA[<hr><p>我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，<strong>Cmd Markdown</strong> 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown：</p><blockquote><ul><li>整理知识，学习笔记</li><li>发布日记，杂文，所见所想</li><li>撰写发布技术文稿（代码支持）</li><li>撰写发布学术论文（LaTeX 公式支持）</li></ul></blockquote><p><img src="https://www.zybuluo.com/static/img/logo.png" alt="cmd-markdown-logo"></p><p>除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载：</p><h3 id="Windows-Mac-Linux-全平台客户端"><a href="#Windows-Mac-Linux-全平台客户端" class="headerlink" title="Windows/Mac/Linux 全平台客户端"></a><a href="https://www.zybuluo.com/cmd/" target="_blank" rel="noopener">Windows/Mac/Linux 全平台客户端</a></h3><blockquote><p>请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 <i class="icon-file"></i> <strong>新文稿</strong> 或者使用快捷键 <code>Ctrl+Alt+N</code>。</p></blockquote><hr><h2 id="什么是-Markdown"><a href="#什么是-Markdown" class="headerlink" title="什么是 Markdown"></a>什么是 Markdown</h2><p>Markdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，<strong>粗体</strong> 或者 <em>斜体</em> 某些文字，更棒的是，它还可以</p><h3 id="1-制作一份待办事宜-Todo-列表"><a href="#1-制作一份待办事宜-Todo-列表" class="headerlink" title="1. 制作一份待办事宜 Todo 列表"></a>1. 制作一份待办事宜 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#13-待办事宜-todo-列表" target="_blank" rel="noopener">Todo 列表</a></h3><ul><li style="list-style: none"><input type="checkbox"> 支持以 PDF 格式导出文稿</li><li style="list-style: none"><input type="checkbox"> 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率</li><li style="list-style: none"><input type="checkbox" checked> 新增 Todo 列表功能</li><li style="list-style: none"><input type="checkbox" checked> 修复 LaTex 公式渲染问题</li><li style="list-style: none"><input type="checkbox" checked> 新增 LaTex 公式编号功能</li></ul><h3 id="2-书写一个质能守恒公式-LaTeX"><a href="#2-书写一个质能守恒公式-LaTeX" class="headerlink" title="2. 书写一个质能守恒公式[^LaTeX]"></a>2. 书写一个质能守恒公式[^LaTeX]</h3><p>$$E=mc^2$$</p><h3 id="3-高亮一段代码-code"><a href="#3-高亮一段代码-code" class="headerlink" title="3. 高亮一段代码[^code]"></a>3. 高亮一段代码[^code]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@requires_authorization</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SomeClass</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># A comment</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure><h3 id="4-高效绘制-流程图"><a href="#4-高效绘制-流程图" class="headerlink" title="4. 高效绘制 流程图"></a>4. 高效绘制 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#7-流程图" target="_blank" rel="noopener">流程图</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: Start</span><br><span class="line">op=&gt;operation: Your Operation</span><br><span class="line">cond=&gt;condition: Yes or No?</span><br><span class="line">e=&gt;end</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure><h3 id="5-高效绘制-序列图"><a href="#5-高效绘制-序列图" class="headerlink" title="5. 高效绘制 序列图"></a>5. 高效绘制 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#8-序列图" target="_blank" rel="noopener">序列图</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Alice-&gt;Bob: Hello Bob, how are you?</span><br><span class="line">Note right of Bob: Bob thinks</span><br><span class="line">Bob--&gt;Alice: I am good thanks!</span><br></pre></td></tr></table></figure><h3 id="6-高效绘制-甘特图"><a href="#6-高效绘制-甘特图" class="headerlink" title="6. 高效绘制 甘特图"></a>6. 高效绘制 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#9-甘特图" target="_blank" rel="noopener">甘特图</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">title 项目开发流程</span><br><span class="line">section 项目确定</span><br><span class="line">    需求分析       :a1, 2016-06-22, 3d</span><br><span class="line">    可行性报告     :after a1, 5d</span><br><span class="line">    概念验证       : 5d</span><br><span class="line">section 项目实施</span><br><span class="line">    概要设计      :2016-07-05  , 5d</span><br><span class="line">    详细设计      :2016-07-08, 10d</span><br><span class="line">    编码          :2016-07-15, 10d</span><br><span class="line">    测试          :2016-07-22, 5d</span><br><span class="line">section 发布验收</span><br><span class="line">    发布: 2d</span><br><span class="line">    验收: 3d</span><br></pre></td></tr></table></figure><h3 id="7-绘制表格"><a href="#7-绘制表格" class="headerlink" title="7. 绘制表格"></a>7. 绘制表格</h3><table><thead><tr><th>项目</th><th style="text-align:right">价格</th><th style="text-align:center">数量</th></tr></thead><tbody><tr><td>计算机</td><td style="text-align:right">\$1600</td><td style="text-align:center">5</td></tr><tr><td>手机</td><td style="text-align:right">\$12</td><td style="text-align:center">12</td></tr><tr><td>管线</td><td style="text-align:right">\$1</td><td style="text-align:center">234</td></tr></tbody></table><h3 id="8-更详细语法说明"><a href="#8-更详细语法说明" class="headerlink" title="8. 更详细语法说明"></a>8. 更详细语法说明</h3><p>想要查看更详细的语法说明，可以参考我们准备的 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown" target="_blank" rel="noopener">Cmd Markdown 简明语法手册</a>，进阶用户可以参考 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#cmd-markdown-高阶语法手册" target="_blank" rel="noopener">Cmd Markdown 高阶语法手册</a> 了解更多高级功能。</p><p>总而言之，不同于其它 <em>所见即所得</em> 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。<strong>Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。</strong> 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。</p><hr><h2 id="什么是-Cmd-Markdown"><a href="#什么是-Cmd-Markdown" class="headerlink" title="什么是 Cmd Markdown"></a>什么是 Cmd Markdown</h2><p>您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 <strong>编辑/发布/阅读</strong> Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。</p><h3 id="1-实时同步预览"><a href="#1-实时同步预览" class="headerlink" title="1. 实时同步预览"></a>1. 实时同步预览</h3><p>我们将 Cmd Markdown 的主界面一分为二，左边为<strong>编辑区</strong>，右边为<strong>预览区</strong>，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！</p><h3 id="2-编辑工具栏"><a href="#2-编辑工具栏" class="headerlink" title="2. 编辑工具栏"></a>2. 编辑工具栏</h3><p>也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 <strong>编辑区</strong> 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。</p><p><img src="https://www.zybuluo.com/static/img/toolbar-editor.png" alt="tool-editor"></p><h3 id="3-编辑模式"><a href="#3-编辑模式" class="headerlink" title="3. 编辑模式"></a>3. 编辑模式</h3><p>完全心无旁骛的方式编辑文字：点击 <strong>编辑工具栏</strong> 最右侧的拉伸按钮或者按下 <code>Ctrl + M</code>，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！</p><h3 id="4-实时的云端文稿"><a href="#4-实时的云端文稿" class="headerlink" title="4. 实时的云端文稿"></a>4. 实时的云端文稿</h3><p>为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 <strong>编辑工具栏</strong> 的最右侧提示 <code>已保存</code> 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。</p><h3 id="5-离线模式"><a href="#5-离线模式" class="headerlink" title="5. 离线模式"></a>5. 离线模式</h3><p>在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。</p><h3 id="6-管理工具栏"><a href="#6-管理工具栏" class="headerlink" title="6. 管理工具栏"></a>6. 管理工具栏</h3><p>为了便于管理您的文稿，在 <strong>预览区</strong> 的顶部放置了如下所示的 <strong>管理工具栏</strong>：</p><p><img src="https://www.zybuluo.com/static/img/toolbar-manager.jpg" alt="tool-manager"></p><p>通过管理工具栏可以：</p><p><i class="icon-share"></i> 发布：将当前的文稿生成固定链接，在网络上发布，分享<br><i class="icon-file"></i> 新建：开始撰写一篇新的文稿<br><i class="icon-trash"></i> 删除：删除当前的文稿<br><i class="icon-cloud"></i> 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地<br><i class="icon-reorder"></i> 列表：所有新增和过往的文稿都可以在这里查看、操作<br><i class="icon-pencil"></i> 模式：切换 普通/Vim/Emacs 编辑模式</p><h3 id="7-阅读工具栏"><a href="#7-阅读工具栏" class="headerlink" title="7. 阅读工具栏"></a>7. 阅读工具栏</h3><p><img src="https://www.zybuluo.com/static/img/toolbar-reader.jpg" alt="tool-manager"></p><p>通过 <strong>预览区</strong> 右上角的 <strong>阅读工具栏</strong>，可以查看当前文稿的目录并增强阅读体验。</p><p>工具栏上的五个图标依次为：</p><p><i class="icon-list"></i> 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落<br><i class="icon-chevron-sign-left"></i> 视图：互换左边编辑区和右边预览区的位置<br><i class="icon-adjust"></i> 主题：内置了黑白两种模式的主题，试试 <strong>黑色主题</strong>，超炫！<br><i class="icon-desktop"></i> 阅读：心无旁骛的阅读模式提供超一流的阅读体验<br><i class="icon-fullscreen"></i> 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境</p><h3 id="8-阅读模式"><a href="#8-阅读模式" class="headerlink" title="8. 阅读模式"></a>8. 阅读模式</h3><p>在 <strong>阅读工具栏</strong> 点击 <i class="icon-desktop"></i> 或者按下 <code>Ctrl+Alt+M</code> 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。</p><h3 id="9-标签、分类和搜索"><a href="#9-标签、分类和搜索" class="headerlink" title="9. 标签、分类和搜索"></a>9. 标签、分类和搜索</h3><p>在编辑区任意行首位置输入以下格式的文字可以标签当前文档：</p><p>标签： 未分类</p><p>标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示：</p><p><img src="https://www.zybuluo.com/static/img/file-list.png" alt="file-list"></p><h3 id="10-文稿发布和分享"><a href="#10-文稿发布和分享" class="headerlink" title="10. 文稿发布和分享"></a>10. 文稿发布和分享</h3><p>在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 <i class="icon-share"></i> (Ctrl+Alt+P) 发布这份文档给好友吧！</p><hr><p>再一次感谢您花费时间阅读这份欢迎稿，点击 <i class="icon-file"></i> (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！</p><p>作者 <a href="http://weibo.com/ghosert" target="_blank" rel="noopener">@ghosert</a><br>2016 年 07月 07日    </p><p>[^LaTeX]: 支持 <strong>LaTeX</strong> 编辑显示支持，例如：$\sum_{i=1}^n a_i=0$， 访问 <a href="http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="noopener">MathJax</a> 参考更多使用方法。</p><p>[^code]: 代码高亮功能支持包括 Java, Python, JavaScript 在内的，<strong>四十一</strong>种主流编程语言。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt;我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，&lt;strong&gt;Cmd Markdown&lt;/strong&gt; 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown：&lt;/p&gt;

      
    
    </summary>
    
      <category term="其他" scheme="https://23yue23.github.io/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="其他" scheme="https://23yue23.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
</feed>
