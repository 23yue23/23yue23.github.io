<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蜗牛笔记</title>
  
  <subtitle>永不设限，尽在自律。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://23yue23.github.io/"/>
  <updated>2019-12-19T11:49:14.347Z</updated>
  <id>https://23yue23.github.io/</id>
  
  <author>
    <name>岳贤昌</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>k8s-aliyun操作</title>
    <link href="https://23yue23.github.io/2019/12/19/k8s-aliyun%E6%93%8D%E4%BD%9C/"/>
    <id>https://23yue23.github.io/2019/12/19/k8s-aliyun操作/</id>
    <published>2019-12-19T11:47:39.000Z</published>
    <updated>2019-12-19T11:49:14.347Z</updated>
    
    <content type="html"><![CDATA[<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><blockquote><p>获取令牌 （需在master 节点）</p></blockquote><pre><code>kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#39;{print $1}&#39;)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;常用命令&quot;&gt;&lt;a href=&quot;#常用命令&quot; class=&quot;headerlink&quot; title=&quot;常用命令&quot;&gt;&lt;/a&gt;常用命令&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;获取令牌 （需在master 节点）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;k
      
    
    </summary>
    
      <category term="k8s-aliyun操作" scheme="https://23yue23.github.io/categories/k8s-aliyun%E6%93%8D%E4%BD%9C/"/>
    
    
      <category term="k8s-aliyun操作" scheme="https://23yue23.github.io/tags/k8s-aliyun%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>java-ThreadLocalRandom篇</title>
    <link href="https://23yue23.github.io/2019/12/19/java-ThreadLocalRandom%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/12/19/java-ThreadLocalRandom篇/</id>
    <published>2019-12-19T08:47:06.000Z</published>
    <updated>2019-12-19T09:11:57.621Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-为什么用？"><a href="#1-为什么用？" class="headerlink" title="1.为什么用？"></a>1.为什么用？</h4><p>因为在Java 7 才引入了 java.util.concurrent.ThreadLocalRandom 类，主要是用于在多线程环境中生成随机数。是 ThreadLocal 类和 Random 类的组合，与当前线程隔离，通过简单地避免对 Random 对象的任何并发访问，在多线程环境中实现了更好的性能。</p><h4 id="2-怎么用？"><a href="#2-怎么用？" class="headerlink" title="2.怎么用？"></a>2.怎么用？</h4><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//当前边界时 int 的边界</span><span class="token keyword">int</span> boundedRandomValue <span class="token operator">=</span> ThreadLocalRandom<span class="token punctuation">.</span><span class="token function">current</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//当前边界时【0，100） 之间，包含0 不包含100</span><span class="token keyword">int</span> boundedRandomValue <span class="token operator">=</span> ThreadLocalRandom<span class="token punctuation">.</span><span class="token function">current</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="3-使用场景"><a href="#3-使用场景" class="headerlink" title="3.使用场景"></a>3.使用场景</h4><pre><code>//可用于大数据倾斜时，用于打散数据。//key + &quot;@&quot; + ThreadLocalRandom.current().nextInt()</code></pre><p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/ed298b30.png" alt="图来自美团技术团队的博客：https://tech.meituan.com/2016/05/12/spark-tuning-pro.html"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-为什么用？&quot;&gt;&lt;a href=&quot;#1-为什么用？&quot; class=&quot;headerlink&quot; title=&quot;1.为什么用？&quot;&gt;&lt;/a&gt;1.为什么用？&lt;/h4&gt;&lt;p&gt;因为在Java 7 才引入了 java.util.concurrent.ThreadLocalRan
      
    
    </summary>
    
      <category term="java" scheme="https://23yue23.github.io/categories/java/"/>
    
    
      <category term="java ThreadLocalRandom" scheme="https://23yue23.github.io/tags/java-ThreadLocalRandom/"/>
    
  </entry>
  
  <entry>
    <title>azkaban-问题篇</title>
    <link href="https://23yue23.github.io/2019/12/19/azkaban-%E9%97%AE%E9%A2%98%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/12/19/azkaban-问题篇/</id>
    <published>2019-12-19T02:26:22.000Z</published>
    <updated>2019-12-19T02:44:07.508Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-azkaban-exec-遇到的问题"><a href="#1-azkaban-exec-遇到的问题" class="headerlink" title="1.azkaban exec 遇到的问题"></a>1.azkaban exec 遇到的问题</h4><h5 id="1-1-Job-failed-Cannot-request-memory-Xms-0-kb-Xmx-0-kb-from-system-for-job"><a href="#1-1-Job-failed-Cannot-request-memory-Xms-0-kb-Xmx-0-kb-from-system-for-job" class="headerlink" title="1.1 Job failed, Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job"></a>1.1 Job failed, Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job</h5><pre><code>异常：    ERROR - Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job job_run_distinct_impression cause: null分析：当前遇到的问题，是在提交作业的时候进行了内存的检查，认为空闲资源不足，抛除的异常。解决：在 azkaban/exec-server/plugins/jobtypes/commonprivate.properties文件中添加memCheck.enable=false参考： https://github.com/azkaban/azkaban/issues/481      https://my.oschina.net/u/2988360/blog/1537561</code></pre><h4 id="2-azkaban-web-遇到的问题"><a href="#2-azkaban-web-遇到的问题" class="headerlink" title="2.azkaban web 遇到的问题"></a>2.azkaban web 遇到的问题</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-azkaban-exec-遇到的问题&quot;&gt;&lt;a href=&quot;#1-azkaban-exec-遇到的问题&quot; class=&quot;headerlink&quot; title=&quot;1.azkaban exec 遇到的问题&quot;&gt;&lt;/a&gt;1.azkaban exec 遇到的问题&lt;/h4&gt;&lt;
      
    
    </summary>
    
      <category term="azkaban" scheme="https://23yue23.github.io/categories/azkaban/"/>
    
    
      <category term="azkaban" scheme="https://23yue23.github.io/tags/azkaban/"/>
    
  </entry>
  
  <entry>
    <title>flink-优化篇</title>
    <link href="https://23yue23.github.io/2019/12/17/flink-%E4%BC%98%E5%8C%96%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/12/17/flink-优化篇/</id>
    <published>2019-12-17T02:33:22.000Z</published>
    <updated>2019-12-19T09:43:41.452Z</updated>
    
    <content type="html"><![CDATA[<h4 id="flink-基础配置层面"><a href="#flink-基础配置层面" class="headerlink" title="flink 基础配置层面"></a>flink 基础配置层面</h4><h5 id="1-程序内部接收外部传参（配置常变的参数）"><a href="#1-程序内部接收外部传参（配置常变的参数）" class="headerlink" title="1.程序内部接收外部传参（配置常变的参数）"></a>1.程序内部接收外部传参（配置常变的参数）</h5><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//解析参数</span><span class="token keyword">val</span> parameters <span class="token operator">=</span> ParameterTool<span class="token punctuation">.</span>fromArgs<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//将参数设置到job 的全局参数中</span>env<span class="token punctuation">.</span>getConfig<span class="token punctuation">.</span>setGlobalJobParameters<span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//register the parameters globally</span><span class="token comment" spellcheck="true">// 获取方式： 外部的参数名</span><span class="token keyword">val</span> parallelisms <span class="token operator">=</span> parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"parallelisms"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt###在继承富函数后 open中初始化查询<span class="token keyword">val</span> params<span class="token operator">:</span> ParameterTool <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getExecutionConfig<span class="token punctuation">.</span>getGlobalJobParameters<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>ParameterTool<span class="token punctuation">]</span><span class="token keyword">val</span> restore <span class="token operator">=</span> params<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"restoreFlag"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim</code></pre><hr><h5 id="2-加载内部配置文件-（配置固定不变的参数）"><a href="#2-加载内部配置文件-（配置固定不变的参数）" class="headerlink" title="2.加载内部配置文件 （配置固定不变的参数）"></a>2.加载内部配置文件 （配置固定不变的参数）</h5><pre class=" language-scala"><code class="language-scala"> <span class="token keyword">def</span> loadConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token punctuation">{</span>     <span class="token keyword">val</span> p <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">val</span> in <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getClassLoader<span class="token punctuation">.</span>getResourceAsStream<span class="token punctuation">(</span><span class="token string">"config.properties"</span><span class="token punctuation">)</span>     p<span class="token punctuation">.</span>load<span class="token punctuation">(</span>in<span class="token punctuation">)</span>     in<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>     p   <span class="token punctuation">}</span></code></pre><hr><h5 id="3-程序中的并行执行设置"><a href="#3-程序中的并行执行设置" class="headerlink" title="3.程序中的并行执行设置"></a>3.程序中的并行执行设置</h5><blockquote><p>并行度的概念</p></blockquote><pre><code> 并行度数和slot 数有关，而slot 数是有taskManager 的核数决定的，</code></pre><blockquote><p>并行设置的方式</p></blockquote><pre><code> 1.可以内部程序接收外部传参数的形式。 2.可以内部程序env.setParallelism(16)的形式设置全局的并行度。 3.可以设置算子级别的并行度 4.命令行中进行全局设置： ./bin/flink run -p 5 ../wordCount-java*.jar</code></pre><blockquote><p>并行度设置优化点：</p></blockquote><pre><code>1. 在设置kafka source的时候，可以设置与partition 数一致的并行度。    这样会启动与分区数对等的flinkKafkaConsumer 实例。每个FlinkKafkaConsumer实例消费的topic和partition则是根据探测到的所有指定topic分区对于并行数量取余数拿到的。    公式：(startIndex+parttion.getPartition())%numParallerSubtasks == currentTaskId2.当然kafka source也可以根据topic的数量进行设置，当数据量少时，可以设置并行度小于partition数。  注意：不要设置并发数大于 partitions 总数，因为这种情况下某些并发因为分配不到 partition 导致没有数据处理。3.#        </code></pre><blockquote><p>并行度设置注意事项：</p></blockquote><pre><code>Apache Flink的并行度设置并不是说越大越好、数据处理的效率就越高。而是需要设置合理的并行度。那么何谓合理呢？Apache Flink的 并行度取决于每个TaskManager上的slot数量而决定的。Flink的JobManager把任务分成子任务提交给slot进行执行。相同的slot共享相同的JVM资源，同时对Flink提供维护的心跳等信息。slot是指TaskManagere的并发执行能力，通常来说TaskManager有多少核CPU也就会有多少个slot。这样来看，我们设置的并行度其实是与TaskManager所有Slot数量有关的</code></pre><hr><h5 id="4-name-和uid-设置的作用"><a href="#4-name-和uid-设置的作用" class="headerlink" title="4.name 和uid 设置的作用"></a>4.name 和uid 设置的作用</h5><hr><h4 id="flink-的容错层面"><a href="#flink-的容错层面" class="headerlink" title="flink 的容错层面"></a>flink 的容错层面</h4><h5 id="1-内部失败重试策略"><a href="#1-内部失败重试策略" class="headerlink" title="1.内部失败重试策略"></a>1.内部失败重试策略</h5><blockquote><p>故障恢复可设置指标：</p></blockquote><blockquote><ul><li>RestartStrategies.fixedDelayRestart  </li><li>RestartStrategies.failureRateRestart</li><li>RestartStrategies.noRestart</li></ul></blockquote><blockquote><ol><li>如果发生故障，系统将尝试重新启动作业3次，并在连续的重新启动尝试之间等待10秒。</li></ol></blockquote><pre class=" language-scala"><code class="language-scala">env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span>RestartStrategies<span class="token punctuation">.</span>fixedDelayRestart<span class="token punctuation">(</span>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">// number of restart attempts</span>  Time<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// delay</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><blockquote><ol start="2"><li>超过设定的指标，则该作业最终将失败（程序常用）</li></ol></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 设置内部 如果10分钟内连续失败3次，或者每次失败间隔时间超过15s 将认为不可恢复，则作业失败。其他情况作业默认启用内部恢复策略，直到作业恢复。</span>env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span>RestartStrategies<span class="token punctuation">.</span>failureRateRestart<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>   org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>time<span class="token punctuation">.</span>Time<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>MINUTES<span class="token punctuation">)</span><span class="token punctuation">,</span>   org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>time<span class="token punctuation">.</span>Time<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><blockquote><ol start="3"><li>不设置重试策略，作业有异常时直接失败。</li></ol></blockquote><pre class=" language-scala"><code class="language-scala"> env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span>RestartStrategies<span class="token punctuation">.</span>noRestart<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><hr><h4 id="flink-状态数据层面"><a href="#flink-状态数据层面" class="headerlink" title="flink 状态数据层面"></a>flink 状态数据层面</h4><h5 id="1-checkpoint-优化设置"><a href="#1-checkpoint-优化设置" class="headerlink" title="1.checkpoint 优化设置"></a>1.checkpoint 优化设置</h5><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//设置checkpoint 快照时间为5分钟</span>env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">300000l</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//设置的是事件的处理时间</span><span class="token punctuation">.</span>setStreamTimeCharacteristic<span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>ProcessingTime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">/***设置checkpoint 取消时清理和保留机制：* 1.DELETE_ON_CANCELLATION 工作取消时删除checkpoint 做的检查点。* 2.RETAIN_ON_CANCELLATION 工作取消时保留checkpoint 做的检查点*/</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>enableExternalizedCheckpoints<span class="token punctuation">(</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 设置两个检查点之间的最小间隔，</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMinPauseBetweenCheckpoints<span class="token punctuation">(</span><span class="token number">1000L</span> <span class="token operator">*</span> <span class="token number">60L</span> <span class="token operator">*</span> <span class="token number">5L</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//设置checkpoint的超时时间</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">1000L</span> <span class="token operator">*</span> <span class="token number">60L</span> <span class="token operator">*</span> <span class="token number">30L</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//设置checkpoint 的最大并发数       </span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMaxConcurrentCheckpoints<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//当前path 最好是hdfs 的路径，s3 的路径有时会出现一致性的问题。</span><span class="token keyword">val</span> backend <span class="token operator">=</span> <span class="token keyword">new</span> RocksDBStateBackend<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">/*** 设置rsDB的保存策略* 由于flink 不依赖磁盘上的RocksDB数据进行恢复，因此无需将数据同步到稳定的存储中。* 1.DEFAULT ：所有设置都是默认选项，但不强制写入磁盘* 2.SPINNING_DISK_OPTIMIZED：使用常规硬盘提高性能。* 3.SPINNING_DISK_OPTIMIZED_HIGH_MEM：此配置将会应用大量的内存用于块的缓存和压缩，如果遇到DB内存不足，建议切换为第二种SPINNING_DISK_OPTIMIZED。* 4.FLASH_SSD_OPTIMIZED：使用SSD 提高性能**/</span>backend<span class="token punctuation">.</span>setPredefinedOptions<span class="token punctuation">(</span>PredefinedOptions<span class="token punctuation">.</span>FLASH_SSD_OPTIMIZED<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//设置checkpoint的模式：CheckpointingMode.EXACTLY_ONCE or CheckpointingMode.AT_LEAST_ONCE</span><span class="token comment" spellcheck="true">//默认是使用的 EXACTLY_ONCE</span>env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//将ck保存进行set</span>env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span>backend<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>StateBackend<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><hr><h5 id="2-自动清理程序状态（flink-1-8-And-Processing-Time）"><a href="#2-自动清理程序状态（flink-1-8-And-Processing-Time）" class="headerlink" title="2.自动清理程序状态（flink 1.8+ And Processing Time）"></a>2.自动清理程序状态（flink 1.8+ And Processing Time）</h5><blockquote><p>基本介绍</p></blockquote><pre><code>1.在Flink的DataStream API中，应用程序状态是由状态描述符（state descriptor）来定义的。状态生存时间是通过将StateTtlConfiguration对象传递给状态描述符来配置的。 2.flink 提供多个选项配置状态的生存时间行为* 什么时候重置生存时间？ 默认情况下，当状态被修改时，生存时间就会被更新。我们也可以在读操作访问状态时更新相关项的生存时间，但这样要花费额外的写操作来更新时间戳。*已经过期的数据是否可以访问？ 状态生存时间机制使用的是惰性策略来清除过期状态。这可能导致应用程序会尝试读取过期但尚未删除的状态。用户可以配置对这样的读取请求是否返回过期状态。无论哪种情况，过期状态都会在之后立即被删除。虽然返回已经过期的状态有利于数据可用性，但不返回过期状态更符合相关数据保护法规的要求。*哪种时间语义被用于定义生存时间？ 在Apache Flink 1.8.0中，用户只能根据处理时间（Processing Time）定义状态生存时间。未来的Flink版本中计划支持事件时间（Event Time）。在实现上，状态生存时间特性会额外存储上一次相关状态访问的时间戳。虽然这种方法增加了一些存储开销，但它允许Flink在访问状态、创建检查点、恢复或存储清理过程时可以检查过期状态。3.堆内存状态后端的增量清理适用于堆内存状态后端（FsStateBackend和MemoryStateBackend）。其基本思路是在存储后端的所有状态条目上维护一个全局的惰性迭代器。某些事件（例如状态访问）会触发增量清理，而每次触发增量清理时，迭代器都会向前遍历删除已遍历的过期数据。》注意：首先是增量清理所花费的时间会增加记录处理的延迟。其次，如果没有状态被访问（state accessed）或者没有记录被处理（record processed），过期的状态也将不会被删除。4.RocksDB状态后端利用后台压缩来清理过期状态该策略基于Flink定制的RocksDB压缩过滤器（compaction filter）。RocksDB会定期运行异步的压缩流程以合并数据并减少相关存储的数据量，该定制的压缩过滤器使用生存时间检查状态条目的过期时间戳，并丢弃所有过期值。》注意：启用Flink的生存时间压缩过滤机制后，会放缓RocksDB的压缩速度。4.也可以使用定时器进行状态的清理</code></pre><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//当前是以RocksDB状态后端利用后台压缩来清理过期状态 为例的代码</span>    <span class="token keyword">val</span> ttlConfig <span class="token operator">=</span> StateTtlConfig      <span class="token punctuation">.</span>newBuilder<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>minutes<span class="token punctuation">(</span>parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"ttl-minutes"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">//更新当前时间戳之前，压缩过滤器要处理的状态条目数 默认值1000L</span>      <span class="token punctuation">.</span>cleanupInRocksdbCompactFilter<span class="token punctuation">(</span>parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"query-time-after-num-entries"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setTimeCharacteristic<span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>ProcessingTime<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setUpdateType<span class="token punctuation">(</span>StateTtlConfig<span class="token punctuation">.</span>UpdateType<span class="token punctuation">.</span>OnCreateAndWrite<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setStateVisibility<span class="token punctuation">(</span>StateTtlConfig<span class="token punctuation">.</span>StateVisibility<span class="token punctuation">.</span>NeverReturnExpired<span class="token punctuation">)</span>      <span class="token punctuation">.</span>build    <span class="token keyword">val</span> stateDescriptor <span class="token operator">=</span> <span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span>ArrayBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"state"</span><span class="token punctuation">,</span> createTypeInformation<span class="token punctuation">[</span>ArrayBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//开启状态生存时间</span>    stateDescriptor<span class="token punctuation">.</span>enableTimeToLive<span class="token punctuation">(</span>ttlConfig<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//开启状态client 可查询</span>    stateDescriptor<span class="token punctuation">.</span>setQueryable<span class="token punctuation">(</span><span class="token string">"state"</span><span class="token punctuation">)</span>    state <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getState<span class="token punctuation">(</span>stateDescriptor<span class="token punctuation">)</span></code></pre><h5 id="3-状态数据的使用"><a href="#3-状态数据的使用" class="headerlink" title="3.状态数据的使用"></a>3.状态数据的使用</h5><h4 id="flink-监控层面"><a href="#flink-监控层面" class="headerlink" title="flink 监控层面"></a>flink 监控层面</h4><h5 id><a href="#" class="headerlink" title></a></h5><h4 id="flink-延迟数据的处理"><a href="#flink-延迟数据的处理" class="headerlink" title="flink 延迟数据的处理"></a>flink 延迟数据的处理</h4><p>Watermark机制假设在某个时间点上，不会有比这个时间点更晚的上报数据，常被作为一个时间窗口的结束时间，</p><blockquote><p>生成WaterMaker</p></blockquote><pre><code>流数据中的事件时间戳与Watermark高度相关，事件时间戳的抽取和Watermark的生成也基本是同时进行的，抽取的过程会遇到下面两种情况：1.数据流中已经包含了事件时间戳和Watermark。2.使用抽取算子生成事件时间戳和Watermark，这也是实际应用中更为常见的场景。因为后续的计算都依赖时间，抽取算子最好在数据接入后马上使用。具体而言，抽取算子包含两个函数：第一个函数从数据流的事件中抽取时间戳，并将时间戳赋值到事件的元数据上，第二个函数生成Watermark。</code></pre><h4 id="flink-streamAPI层面"><a href="#flink-streamAPI层面" class="headerlink" title="flink streamAPI层面"></a>flink streamAPI层面</h4><h5 id="1-source-和-sink-常用"><a href="#1-source-和-sink-常用" class="headerlink" title="1.source 和 sink 常用"></a>1.source 和 sink 常用</h5><blockquote><p>source         </p><blockquote><ol><li>flink kafka connector</li></ol><ul><li>基本设置：</li></ul></blockquote></blockquote><pre><code>1.因为 kafka 中数据都是以二进制 byte 形式存储的。读到 Flink 系统中之后，需要将二进制数据转化为具体的 java、scala 对象。具体需要实现一个 schema 类，定义如何序列化和反序列数据，flink 也提供了常用的序列化反序列化的schema类，例如SimpleStringSchema（按字符串方式进行序列化、反序列化），JsonDeserializationSchema 使用 jackson 反序列化 json 格式消息，并返回 ObjectNode，可以使用 .get(“property”) 方法来访问相应字段。2.消费起始位置设置 2.1 setStartFromLatest: 设置最新位置开始读。 2.2 setStartFromEarliest: 设置最早位置开始读. 2.3 setStartFromGroupOffsets: 也是默认的策略，从 group offset 位置读取数据，group offset 指的是 kafka broker 端记录的某个 group 的最后一次的消费位置。但是 kafka broker 端没有该 group 信息，会根据 kafka 的参数&quot;auto.offset.reset&quot;的设置来决定从哪个位置开始消费.注意事项：作业故障从savepoint自动恢复时，以及手动做savepoint时，消费位置从保存状态中恢复，与上面的起始位置设置无关。因为Flink Kafka Consumer 不依赖于提交的 offset 来实现容错保证。提交的 offset 只是一种方法，用于公开 consumer 的进度以便进行监控。3.setCommitOffsetsOnCheckpoints(true)时 会将偏移量提交到checkpoint快照的状态数据中。4.other 配置： 4.1 flink.poll-timeout:配置轮询的超时时间。如果没有可用数据，则等待轮询所需的时间 默认是100毫秒 4.2 flink.partition-discovery.interval-millis 设置参数为非负值，表示开启动态发现的开关，以及设置的时间间隔，下面会以场景的形式进行讲解,也就是下面要说的topic 和 partition 的动态发现。5.topic 和 partition 动态发现    场景一：有一个 Flink 作业需要将五份数据聚合到一起，五份数据对应五个 kafka topic，随着业务增长，新增一类数据，同时新增了一个 kafka topic，如何在不重启作业的情况下作业自动感知新的 topic。    场景二：作业从一个固定的 kafka topic 读数据，开始该 topic 有 10 个 partition，但随着业务的增长数据量变大，需要对 kafka partition 个数进行扩容，由 10 个扩容到 20。该情况下如何在不重启作业情况下动态感知新扩容的 partition？    针对上面两种场景，需要在构建 FlinkKafkaConsumer 时的 properties 中设置 flink.partition-discovery.interval-millis(默认为false) 参数为非负值，表示开启动态发现的开关，而设置的值为发现时间间隔。    原理：FlinkKafkaConsumer 内部会启动一个单独的线程定期去 kafka 获取最新的 meta 信息。    针对场景一：需在构建 FlinkKafkaConsumer 时，topic 的描述可以传一个正则表达式描述的 pattern。每次获取最新 kafka meta 时获取正则匹配的最新 topic 列表。    代码：    val topicStr = &quot;topic1&quot;    val topicPattern: Pattern = java.util.regex.Pattern.compile(&quot;topic[0-9]&quot;)    val consumer = new FlinkKafkaConsumer011[String](topicPattern, new SimpleStringSchema(), props)        针对场景二：设置前面的动态发现参数，在定期获取 kafka 最新 meta 信息时会匹配新的 partition。为了保证数据的正确性，新发现的 partition 从最早的位置开始读取    代码：在properties  设置 flink.partition-discovery.interval-millis:发现时间间隔（毫秒）6.commit offset 方式 提交 offset 的方式分为两种： checkpoint 关闭：        依赖kafka 客户端的auto commit定期提交。        需要设置 enable.auto.commit,auto.commit.interval.ms 参数到配置文件。 checkpoint 开启：构建source 时 setCommitOffsetsOnCheckpoints(true)          offset 自己在checkpoint state 中进行管理和维护。提交kafka offset 和ck时间一致，仅仅为了外部监控消费情况。         通过setCommitOffsetsOnCheckpoints 设置,ck成功后是否提交offset 到kafka 。7.Timestamp Extraction/Watermark 生成  我们知道当 Flink 作业内使用 EventTime 属性时，需要指定从消息中提取时戳和生成水位的函数。  FlinkKakfaConsumer 构造的 source 后直接调用 assignTimestampsAndWatermarks 函数设置水位生成器的好处是此时是每个 partition 一个 watermark assigner，  如下图。source 生成的时戳为多个 partition 时戳对齐后的最小时戳。此时在一个 source 读取多个 partition，并且 partition 之间数据时戳有一定差距的情况下，因为在 source 端 watermark 在 partition 级别有对齐，不会导致数据读取较慢 partition 数据丢失</code></pre><p><img src="https://pic3.zhimg.com/v2-c6614444177e3c59dc86123748db0b4a_r.jpg" alt="flink-kafka-consumer waterMaker"></p><pre><code>8.Producer 分区   8.1 FlinkKafkaProducer 往 kafka 中写数据时，如果不单独设置 partition 策略，会默认使用 FlinkFixedPartitioner，该 partitioner 分区的方式是 task 所在的并发 id 对 topic 总 partition 数取余：parallelInstanceId % partitions.length那么如果sink 的task 为4 partition 为2 则 4/2= 2 则2个并行度往2个partion 里写。那么如果sink 的task 为4 partition 为1 则 4/1= 4 则4个并行度往1个partion 里写。那么如果sink 的task 为2 partition 为4 则 2/4    则2个并行度往2个partion 里写，剩余两个partion 将没有数据。   8.2 构建 FlinkKafkaProducer 时，partition 设置为 null，此时会使用 kafka producer 默认分区方式，非 key 写入的情况下，使用 round-robin 的方式进行分区，每个 task 都会轮循的写下游的所有 partition。该方式下游的 partition 数据会比较均衡，但是缺点是 partition 个数过多的情况下需要维持过多的网络连接，即每个 task 都会维持跟所有 partition 所在 broker 的连接。9.连接kafka容错  Flink kafka 09、010 版本下通过 setLogFailuresOnly 为 false，setFlushOnCheckpoint 为 true，能达到 at-least-once 语义。  setLogFailuresOnly，默认为 false，是控制写 kafka 失败时，是否只打印失败的 log 不抛异常让作业停止。  setFlushOnCheckpoint，默认为 true，是控制是否在 checkpoint 时 fluse 数据到 kafka，保证数据已经写到 kafka。否则数据有可能还缓存在 kafka 客户端的 buffer 中，并没有真正写出到 kafka，此时作业挂掉数据即丢失，不能做到至少一次的语义。  Flink kafka 011 版本下，通过两阶段提交的 sink 结合 kafka 事务的功能，可以保证端到端精准一次 </code></pre><p><a href="https://www.ververica.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka" target="_blank" rel="noopener">flink到kafka精准一次</a></p><hr><blockquote><blockquote><ul><li>构建flink kafka source代码：</li></ul></blockquote></blockquote><pre class=" language-scala"><code class="language-scala"> <span class="token comment" spellcheck="true">//设置kafka</span><span class="token keyword">val</span> props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span>config<span class="token punctuation">.</span>getProperty<span class="token punctuation">(</span>BOOTSTRAP_SERVERS<span class="token punctuation">)</span><span class="token punctuation">)</span>props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> parameters<span class="token punctuation">.</span>getRequired<span class="token punctuation">(</span><span class="token string">"groupid"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">)</span>props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//获取kafka的数据源（如有特殊配制可以根据以上基本设置进行配置）</span><span class="token keyword">val</span> source <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaConsumer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>getProperty<span class="token punctuation">(</span>TOPIC<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span>      <span class="token punctuation">.</span>setCommitOffsetsOnCheckpoints<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>name<span class="token punctuation">(</span><span class="token string">"topic-source"</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>uid<span class="token punctuation">(</span><span class="token string">"topic-source"</span><span class="token punctuation">)</span></code></pre><hr><blockquote><ol start="2"><li>flink mysql Async I/O 访问</li></ol></blockquote><blockquote><ol start="3"><li>flink redis Async I/O 访问</li></ol></blockquote><hr><blockquote><p>sink</p></blockquote><blockquote><blockquote><ol><li>flink sink kafka</li></ol></blockquote></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">val</span> stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">val</span> myProducer <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>        <span class="token string">"localhost:9092"</span><span class="token punctuation">,</span>         <span class="token comment" spellcheck="true">// broker 列表</span>        <span class="token string">"my-topic"</span><span class="token punctuation">,</span>               <span class="token comment" spellcheck="true">// 目标 topic</span>        <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">// 序列化 schema</span><span class="token comment" spellcheck="true">// 0.10+ 版本的 Kafka 允许在将记录写入 Kafka 时附加记录的事件时间戳；</span><span class="token comment" spellcheck="true">// 此方法不适用于早期版本的 Kafka</span>myProducer<span class="token punctuation">.</span>setWriteTimestampToKafka<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>stream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span>myProducer<span class="token punctuation">)</span></code></pre><hr><blockquote><blockquote><ol start="2"><li>flink sink cassandra</li></ol></blockquote></blockquote><blockquote><blockquote><ol start="3"><li>flink sink redis</li></ol></blockquote></blockquote><blockquote><blockquote><ol start="4"><li>flink sink hdfs</li></ol></blockquote></blockquote><blockquote><blockquote><ol start="5"><li>flink sink es</li></ol></blockquote></blockquote><hr><blockquote><p>side outPut的使用</p></blockquote><pre><code>除了DataStream操作产生的主流之外，您还可以产生任意数量的附加副输出结果流。结果流中的数据类型不必与主流中的数据类型匹配，并且不同侧输出的类型也可以不同。</code></pre><hr><h5 id="2-ProcessFunction-的使用"><a href="#2-ProcessFunction-的使用" class="headerlink" title="2.ProcessFunction 的使用"></a>2.ProcessFunction 的使用</h5><h5 id="3-异步加载外部数据"><a href="#3-异步加载外部数据" class="headerlink" title="3.异步加载外部数据"></a>3.异步加载外部数据</h5><h5 id="4-缓存配置文件数据"><a href="#4-缓存配置文件数据" class="headerlink" title="4.缓存配置文件数据"></a>4.缓存配置文件数据</h5><pre class=" language-scala"><code class="language-scala">env<span class="token punctuation">.</span>registerCachedFile<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'myFileCache'</span><span class="token punctuation">)</span>在富函数的open方法中进行获取 <span class="token keyword">val</span> myFile <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getDistributedCache<span class="token punctuation">.</span>getFile<span class="token punctuation">(</span><span class="token string">'MyTestFile'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//flink支持将变量广播到worker上，以供程序运算使用。</span></code></pre><h4 id="flink-应对数据解析"><a href="#flink-应对数据解析" class="headerlink" title="flink 应对数据解析"></a>flink 应对数据解析</h4><blockquote><p>判断数据是否为空</p></blockquote><pre><code> StringUtils.isNotBlank(data)</code></pre><blockquote><p>如果有就获取，没有就为默认值</p></blockquote><pre class=" language-scala"><code class="language-scala"> person<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>name<span class="token punctuation">)</span></code></pre><blockquote><p>时间解析 以秒为单位</p></blockquote><pre class=" language-scala"><code class="language-scala"> <span class="token comment" spellcheck="true">//解析格式以秒为单位的数字事件时间字段，如果解析异常，则用当前系统时间代替，返回秒</span> <span class="token keyword">def</span> parseTimestamp<span class="token punctuation">(</span>timestamp<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token punctuation">{</span>    timestamp<span class="token punctuation">.</span>toLong  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> e<span class="token operator">:</span> Exception <span class="token keyword">=></span>      logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>s<span class="token string">"Parsing event time exception: ${e.getMessage}"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>      System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>  <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">//解析格式为yyyy-MM-dd HH:mm:ss的事件时间字段，如果解析异常，则用当前系统事件代替，返回毫秒</span> <span class="token keyword">def</span> parseDateTime<span class="token punctuation">(</span>dateTime<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token punctuation">{</span>    DateTimeFormat<span class="token punctuation">.</span>forPattern<span class="token punctuation">(</span><span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>withZone<span class="token punctuation">(</span>DateTimeZone<span class="token punctuation">.</span>forID<span class="token punctuation">(</span><span class="token string">"+08:00"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parseDateTime<span class="token punctuation">(</span>dateTime<span class="token punctuation">)</span><span class="token punctuation">.</span>getMillis  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> e<span class="token operator">:</span> Exception <span class="token keyword">=></span>      logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>s<span class="token string">"Parsing event time exception: ${e.getMessage}"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>      System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span></code></pre><blockquote><p>加载配置文件</p></blockquote><pre class=" language-scala"><code class="language-scala"> <span class="token keyword">def</span> loadConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">val</span> p <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">val</span> in <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getClassLoader<span class="token punctuation">.</span>getResourceAsStream<span class="token punctuation">(</span><span class="token string">"config.properties"</span><span class="token punctuation">)</span>    p<span class="token punctuation">.</span>load<span class="token punctuation">(</span>in<span class="token punctuation">)</span>    in<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    p  <span class="token punctuation">}</span></code></pre><blockquote><p>切分日志 split</p></blockquote><pre class=" language-scala"><code class="language-scala">  <span class="token comment" spellcheck="true">//按照制表符切割日志</span>  <span class="token keyword">val</span> splitter <span class="token operator">=</span> Pattern<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"\001"</span><span class="token punctuation">)</span>  <span class="token keyword">def</span> split<span class="token punctuation">(</span>log<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    splitter<span class="token punctuation">.</span>split<span class="token punctuation">(</span>log<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span></code></pre><blockquote><p>josn 的解析（alibaba.fastjson）</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">val</span> tmp <span class="token operator">=</span> <span class="token keyword">try</span><span class="token punctuation">{</span>  <span class="token comment" spellcheck="true">//将json 转化为对象，并获取name 字段的字符串值</span>  JSON<span class="token punctuation">.</span>parseObject<span class="token punctuation">(</span>template<span class="token punctuation">)</span><span class="token punctuation">.</span>getString<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">{</span><span class="token keyword">case</span> e<span class="token operator">:</span>Exception <span class="token keyword">=></span>     logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>s<span class="token string">"Parsing json from template field occur exception: ${e.getMessage}"</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span>    <span class="token string">""</span><span class="token punctuation">}</span></code></pre><blockquote><p>正则表达式对设备id 的匹配</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">val</span> deviceIdReg <span class="token operator">=</span> <span class="token string">"^[0-9a-fA-F]{8}(-[0-9a-fA-F]{4}){3}-[0-9a-fA-F]{12}$"</span><span class="token punctuation">.</span>r<span class="token keyword">def</span> filterDeviceId<span class="token punctuation">(</span>deviceId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    deviceIdReg<span class="token punctuation">.</span>findFirstMatchIn<span class="token punctuation">(</span>deviceId<span class="token punctuation">)</span><span class="token punctuation">.</span>isDefined <span class="token operator">&amp;&amp;</span> deviceId <span class="token operator">!=</span> <span class="token string">"00000000-0000-0000-0000-000000000000"</span>  <span class="token punctuation">}</span></code></pre><blockquote><p>组合字符</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">private</span> <span class="token keyword">val</span> joiner <span class="token operator">=</span> Joiner<span class="token punctuation">.</span>on<span class="token punctuation">(</span><span class="token string">"^"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>useForNull<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token keyword">def</span> join<span class="token punctuation">(</span>str1<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> str2<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> str<span class="token operator">:</span> <span class="token builtin">String</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    joiner<span class="token punctuation">.</span>join<span class="token punctuation">(</span>str1<span class="token punctuation">,</span> str2<span class="token punctuation">,</span> str<span class="token operator">:</span> _<span class="token operator">*</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// result = A^B^C^D</span> <span class="token keyword">val</span> result <span class="token operator">=</span> join<span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">)</span></code></pre><blockquote><p>构建测试类测试数据解析是否正常</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token keyword">import</span> org<span class="token punctuation">.</span>scalatest<span class="token punctuation">.</span>FunSuite<span class="token keyword">import</span> scala<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Source<span class="token keyword">class</span> ScalaTest <span class="token keyword">extends</span> FunSuite <span class="token punctuation">{</span>    test<span class="token punctuation">(</span><span class="token string">"test-parser-data"</span><span class="token punctuation">)</span><span class="token punctuation">{</span>          <span class="token keyword">val</span> dataFilter <span class="token operator">=</span> <span class="token keyword">new</span> DataFilter          <span class="token keyword">val</span> file<span class="token operator">=</span>Source<span class="token punctuation">.</span>fromFile<span class="token punctuation">(</span><span class="token string">"local_file_path"</span><span class="token punctuation">)</span>          <span class="token keyword">val</span> lines <span class="token operator">=</span> file<span class="token punctuation">.</span>getLines        <span class="token keyword">var</span> counter<span class="token punctuation">,</span>total <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>line <span class="token keyword">&lt;-</span> lines<span class="token punctuation">)</span><span class="token punctuation">{</span>            total <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>dataFilter<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                counter <span class="token operator">+=</span> <span class="token number">1</span>                <span class="token keyword">val</span> data <span class="token operator">=</span> 解析完的数据。                printBean<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            <span class="token punctuation">}</span>         <span class="token punctuation">}</span>         println<span class="token punctuation">(</span><span class="token string">"-"</span><span class="token operator">*</span><span class="token number">10</span><span class="token operator">+</span><span class="token string">"counter="</span><span class="token operator">+</span>counter <span class="token operator">+</span><span class="token string">",total="</span><span class="token operator">+</span> total<span class="token punctuation">)</span>         file<span class="token punctuation">.</span>close     <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><blockquote><p>加载定时加载外部数据</p></blockquote><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//设置当前的线程数</span>  <span class="token keyword">var</span> countDown<span class="token operator">:</span> CountDownLatch <span class="token operator">=</span> <span class="token keyword">new</span> CountDownLatch<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token annotation punctuation">@volatile</span> <span class="token keyword">var</span> resultData<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> _  <span class="token keyword">def</span> getUccrAndKvAndDefalut<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>countDown<span class="token punctuation">.</span>getCount <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      countDown<span class="token punctuation">.</span>await<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    resultData  <span class="token punctuation">}</span>  <span class="token comment" spellcheck="true">//创建调度器</span>  <span class="token keyword">var</span> executor<span class="token operator">:</span> ScheduledExecutorService <span class="token operator">=</span> Executors<span class="token punctuation">.</span>newSingleThreadScheduledExecutor<span class="token punctuation">(</span>    <span class="token keyword">new</span> ThreadFactoryBuilder<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>setDaemon<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>setNameFormat<span class="token punctuation">(</span><span class="token string">"loaderData-%d"</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span>build<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">// 开始调度 一开始就执行，每三分钟调度一次</span>  executor<span class="token punctuation">.</span>scheduleAtFixedRate<span class="token punctuation">(</span><span class="token keyword">new</span> Runnable <span class="token punctuation">{</span>    <span class="token keyword">override</span> <span class="token keyword">def</span> run<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>      loadData<span class="token punctuation">(</span><span class="token punctuation">)</span>      logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Sync resultData from filesystem complete"</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>MINUTES<span class="token punctuation">)</span> <span class="token keyword">def</span> loadData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    resultData <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">"1"</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">"A"</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> <span class="token punctuation">(</span>countDown<span class="token punctuation">.</span>getCount <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      countDown<span class="token punctuation">.</span>countDown<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span> <span class="token punctuation">}</span></code></pre><h4 id="flink-排查问题层面"><a href="#flink-排查问题层面" class="headerlink" title="flink 排查问题层面"></a>flink 排查问题层面</h4><h5 id="1-查看-flinkUI-的监控"><a href="#1-查看-flinkUI-的监控" class="headerlink" title="1.查看 flinkUI 的监控"></a>1.查看 flinkUI 的监控</h5><pre><code>1.查看当前作业运行的状态2.如果有checkpoint 快照，首先查看快照是否按照约定的时间触发。3.查看作业是否有背压。-&gt;根据拓扑结构定位错误位置，查看哪里数据产生堆积。4.在EXception 处查看是否有异常信息。5.如果on yarn 上，可以查看container 和 jobmanager的log 来定位错误。</code></pre><hr><h5 id="2-查看kafka-监控，看是否offset-没有提交数据消费延迟"><a href="#2-查看kafka-监控，看是否offset-没有提交数据消费延迟" class="headerlink" title="2.查看kafka 监控，看是否offset 没有提交数据消费延迟"></a>2.查看kafka 监控，看是否offset 没有提交数据消费延迟</h5><blockquote><p>promethus 抓取kafka 的信息，并通过grafana 展现出来。</p></blockquote><hr><h5 id="3-如果发现subTask-有问题，怎么排查"><a href="#3-如果发现subTask-有问题，怎么排查" class="headerlink" title="3.如果发现subTask 有问题，怎么排查"></a>3.如果发现subTask 有问题，怎么排查</h5><p>基本思路是根据restApi来定位:<br><a href="https://juejin.im/post/5d973af2518825096a1874f4" target="_blank" rel="noopener">Flink定位SubTask在哪台机器哪个进程执行</a></p><h5 id="4-keyby-的数据倾斜了怎么办"><a href="#4-keyby-的数据倾斜了怎么办" class="headerlink" title="4.keyby 的数据倾斜了怎么办"></a>4.keyby 的数据倾斜了怎么办</h5><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">//1. 将值进行hash</span><span class="token comment" spellcheck="true">//将keyData 进行hash</span>    <span class="token keyword">val</span> hashCode<span class="token operator">:</span> HashCode <span class="token operator">=</span> Hashing<span class="token punctuation">.</span>murmur3_32<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>hashString<span class="token punctuation">(</span>keyData<span class="token punctuation">,</span> Charset<span class="token punctuation">.</span>forName<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>hashCode<span class="token punctuation">.</span>hashCode<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> Integer<span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">,</span> hashCode<span class="token punctuation">.</span>toString<span class="token punctuation">)</span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;flink-基础配置层面&quot;&gt;&lt;a href=&quot;#flink-基础配置层面&quot; class=&quot;headerlink&quot; title=&quot;flink 基础配置层面&quot;&gt;&lt;/a&gt;flink 基础配置层面&lt;/h4&gt;&lt;h5 id=&quot;1-程序内部接收外部传参（配置常变的参数）&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="flink" scheme="https://23yue23.github.io/categories/flink/"/>
    
    
      <category term="flink-优化篇" scheme="https://23yue23.github.io/tags/flink-%E4%BC%98%E5%8C%96%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>博客编写思路</title>
    <link href="https://23yue23.github.io/2019/12/17/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E6%80%9D%E8%B7%AF/"/>
    <id>https://23yue23.github.io/2019/12/17/博客编写思路/</id>
    <published>2019-12-17T01:13:40.000Z</published>
    <updated>2019-12-18T03:24:55.626Z</updated>
    
    <content type="html"><![CDATA[<h4 id="博客类型分类"><a href="#博客类型分类" class="headerlink" title="博客类型分类"></a>博客类型分类</h4><h5 id="常用篇"><a href="#常用篇" class="headerlink" title="常用篇"></a>常用篇</h5><blockquote><p>主要介绍本知识点和框架常用到的命令和技巧，以及需要注意的事项。</p></blockquote><h5 id="学习篇"><a href="#学习篇" class="headerlink" title="学习篇"></a>学习篇</h5><blockquote><p>主要介绍本知识点和框架的3W， who 是什么，where 应用场景， what 怎么用比较好。</p></blockquote><h5 id="问题篇"><a href="#问题篇" class="headerlink" title="问题篇"></a>问题篇</h5><blockquote><p>在使用本知识点或框架中遇到的问题。</p></blockquote><h5 id="资料篇"><a href="#资料篇" class="headerlink" title="资料篇"></a>资料篇</h5><blockquote><p>扩展本知识点或架构的其他比较好的学习资料。</p></blockquote><h5 id="优化篇"><a href="#优化篇" class="headerlink" title="优化篇"></a>优化篇</h5><blockquote><p>主要编写的是当前组件或架构可优化点。</p></blockquote><h5 id="实战篇"><a href="#实战篇" class="headerlink" title="实战篇"></a>实战篇</h5><blockquote><p>主要演示在知识点实际搭建过程中的操作。</p></blockquote><h5 id="other"><a href="#other" class="headerlink" title="other"></a>other</h5><blockquote><p>主要是小的知识点分类，比如java-JVM篇，java-cache篇，java-多线程篇</p></blockquote><h4 id="博客思想"><a href="#博客思想" class="headerlink" title="博客思想"></a>博客思想</h4><blockquote><p>本站博客，是以练促学，以学促用的理念来进行编写，当然为了取其精华去其糟粕，博客中也会引用总结其他大牛比较好的内容，用来学习。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;博客类型分类&quot;&gt;&lt;a href=&quot;#博客类型分类&quot; class=&quot;headerlink&quot; title=&quot;博客类型分类&quot;&gt;&lt;/a&gt;博客类型分类&lt;/h4&gt;&lt;h5 id=&quot;常用篇&quot;&gt;&lt;a href=&quot;#常用篇&quot; class=&quot;headerlink&quot; title=&quot;常用篇
      
    
    </summary>
    
      <category term="博客编写思路" scheme="https://23yue23.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E6%80%9D%E8%B7%AF/"/>
    
    
      <category term="博客编写思路" scheme="https://23yue23.github.io/tags/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E6%80%9D%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>java-cache篇</title>
    <link href="https://23yue23.github.io/2019/12/17/java-cache%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/12/17/java-cache篇/</id>
    <published>2019-12-16T23:54:44.000Z</published>
    <updated>2019-12-18T06:48:07.391Z</updated>
    
    <content type="html"><![CDATA[<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p> 首先要有意识的进行缓存的使用。在某值多次使用的时候，可以考虑把当前值获取到并放到缓存中去，使得数据在内存中获取，而非外部存储，能极大提高数据获取的速度。但要注意缓存数据的容量大小。</p><h4 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h4><blockquote><p>构建缓存</p></blockquote><pre><code> var cache: Cache[String, String] = CacheBuilder.newBuilder()    .expireAfterAccess(30, TimeUnit.MINUTES)   //过期时间    .maximumSize(30000) //最大条数    .build()</code></pre><blockquote><p>获取缓存，如果没有则进行计算 或者用getIfPresent 获取缓存</p></blockquote><pre><code>try {    // If the key wasn&#39;t in the &quot;easy to compute&quot; group, we need to    // do things the hard way.    cache.get(key, () -&gt;  doThingsTheHardWay(key));} catch (ExecutionException e) {    throw new OtherException(e.getCause());}</code></pre><blockquote><p>使用cache.put(key, value)方法可以直接向缓存中插入值，这会直接覆盖掉给定键之前映射的值</p></blockquote><hr><blockquote><p>缓存收回策略 ： </p><blockquote><p>1.基于容量的回收（size-based eviction）</p></blockquote></blockquote><pre><code>使用CacheBuilder.maximumSize(long)缓存将尝试回收最近没有使用或总体上很少使用的缓存项。警告：在缓存项的数目达到限定值之前，缓存就可能进行回收操作,通常来说，这种情况发生在缓存项的数目逼近限定值时</code></pre><blockquote><blockquote><p>2.定时回收（Timed Eviction）</p></blockquote></blockquote><pre><code>1.expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于容量回收一样2.expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。</code></pre><blockquote><blockquote><p>3.基于引用的回收（Reference-based Eviction）</p></blockquote></blockquote><pre><code>通过弱引用的键或者弱引用的值，或者软引用的值，guava Cache可以把缓存设置为允许垃圾回收1.CacheBuilder.weakKeys():使用过弱引用存储键值。当被垃圾回收的时候，当前键值没有其他引用的时候缓存项可以被垃圾回收。2.CacheBuilder.weakValues():使用弱引用存储值。3.CacheBuilder.softValues():使用软引用存储值。软引用就是在内存不够是才会按照顺序回收。</code></pre><hr><h5 id="缓存数据的清除"><a href="#缓存数据的清除" class="headerlink" title="缓存数据的清除"></a>缓存数据的清除</h5><pre><code>个别清除：Cache.invalidate(key)批量清除：Cache.invalidateAll(keys)清除所有缓存项：Cache.invalidateAll()</code></pre><h5 id="刷新"><a href="#刷新" class="headerlink" title="刷新"></a>刷新</h5><blockquote><p>刷新操作进行时，缓存仍然可以向其他线程返回旧值，而不像回收操作，读缓存的线程必须等待新值加载完成</p></blockquote><blockquote><p>如果刷新过程抛出异常，缓存将保留旧值，而异常会在记录到日志后被丢弃[swallowed]。</p></blockquote><blockquote><p>重载CacheLoader.reload(K, V)可以扩展刷新时的行为，这个方法允许开发者在计算新值时使用旧的值。</p></blockquote><pre><code>//有些键不需要刷新，并且我们希望刷新是异步完成的LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder()        .maximumSize(1000)        .refreshAfterWrite(1, TimeUnit.MINUTES)        .build(            new CacheLoader&lt;Key, Graph&gt;() {                public Graph load(Key key) { // no checked exception                    return getGraphFromDatabase(key);                }                public ListenableFuture&lt;Key, Graph&gt; reload(final Key key, Graph prevGraph) {                    if (neverNeedsRefresh(key)) {                        return Futures.immediateFuture(prevGraph);                    }else{                        // asynchronous!                        ListenableFutureTask&lt;Key, Graph&gt; task=ListenableFutureTask.create(new Callable&lt;Key, Graph&gt;() {                            public Graph call() {                                return getGraphFromDatabase(key);                            }                        });                        executor.execute(task);                        return task;                    }                }            });</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;使用场景&quot;&gt;&lt;a href=&quot;#使用场景&quot; class=&quot;headerlink&quot; title=&quot;使用场景&quot;&gt;&lt;/a&gt;使用场景&lt;/h4&gt;&lt;p&gt; 首先要有意识的进行缓存的使用。在某值多次使用的时候，可以考虑把当前值获取到并放到缓存中去，使得数据在内存中获取，而非外部存
      
    
    </summary>
    
      <category term="java" scheme="https://23yue23.github.io/categories/java/"/>
    
    
      <category term="java cache" scheme="https://23yue23.github.io/tags/java-cache/"/>
    
  </entry>
  
  <entry>
    <title>azkaban-剖析篇</title>
    <link href="https://23yue23.github.io/2019/12/10/azkaban-%E5%89%96%E6%9E%90%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/12/10/azkaban-剖析篇/</id>
    <published>2019-12-10T08:34:59.000Z</published>
    <updated>2019-12-17T01:06:34.130Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-Azkaban-前后台参数传递"><a href="#1-Azkaban-前后台参数传递" class="headerlink" title="1.Azkaban-前后台参数传递"></a>1.Azkaban-前后台参数传递</h4><blockquote></blockquote><h4 id="2-Azkaban-用户登录过程"><a href="#2-Azkaban-用户登录过程" class="headerlink" title="2.Azkaban-用户登录过程"></a>2.Azkaban-用户登录过程</h4><blockquote><p>1.用户登录时，首先通过LoginAbstractAzkabanServlet 中的handleAjaxLoginAction 方法进行用户信息处理和认证。</p></blockquote><pre><code>protected void handleAjaxLoginAction(HttpServletRequest req,      HttpServletResponse resp, Map&lt;String, Object&gt; ret)      throws ServletException {    if (hasParam(req, &quot;username&quot;) &amp;&amp; hasParam(req, &quot;password&quot;)) {      Session session = null;      try {              //创建session 进行用户的认证        session = createSession(req);      } catch (UserManagerException e) {        ret.put(&quot;error&quot;, &quot;Incorrect Login. &quot; + e.getMessage());        return;      }      Cookie cookie = new Cookie(SESSION_ID_NAME, session.getSessionId());      cookie.setPath(&quot;/&quot;);      resp.addCookie(cookie);      getApplication().getSessionCache().addSession(session);      ret.put(&quot;status&quot;, &quot;success&quot;);      ret.put(&quot;session.id&quot;, session.getSessionId());    } else {      ret.put(&quot;error&quot;, &quot;Incorrect Login.&quot;);    }  }</code></pre><blockquote><p>2.createSession的验证和创建过程：</p></blockquote><pre><code>private Session createSession(String username, String password, String ip)     throws UserManagerException, ServletException {   UserManager manager = getApplication().getUserManager();   User user = manager.getUser(username, password);   String randomUID = UUID.randomUUID().toString();   Session session = new Session(randomUID, user, ip);   return session; }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-Azkaban-前后台参数传递&quot;&gt;&lt;a href=&quot;#1-Azkaban-前后台参数传递&quot; class=&quot;headerlink&quot; title=&quot;1.Azkaban-前后台参数传递&quot;&gt;&lt;/a&gt;1.Azkaban-前后台参数传递&lt;/h4&gt;&lt;blockquote&gt;

      
    
    </summary>
    
      <category term="azkaban" scheme="https://23yue23.github.io/categories/azkaban/"/>
    
    
      <category term="azkaban" scheme="https://23yue23.github.io/tags/azkaban/"/>
    
  </entry>
  
  <entry>
    <title>httpd-常用篇</title>
    <link href="https://23yue23.github.io/2019/12/10/httpd-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/12/10/httpd-常用篇/</id>
    <published>2019-12-10T05:53:26.000Z</published>
    <updated>2019-12-17T02:28:53.766Z</updated>
    
    <content type="html"><![CDATA[<h4 id="httpd-服务简介"><a href="#httpd-服务简介" class="headerlink" title="httpd 服务简介"></a>httpd 服务简介</h4><hr><h4 id="2-httpd-作为文件服务的使用"><a href="#2-httpd-作为文件服务的使用" class="headerlink" title="2.httpd 作为文件服务的使用"></a>2.httpd 作为文件服务的使用</h4><blockquote><p>安装使用</p></blockquote><pre><code>#安装sudo yum install httpdsudo su#测试配置是否正常httpd -t#starthttpd -k start#stophttpd -k stop</code></pre><blockquote><p>服务目录    /etc/httpd</p></blockquote><blockquote><p>主配置文件    /etc/httpd/conf/httpd.conf</p></blockquote><blockquote><p>网站数据目录    /var/www/html</p></blockquote><blockquote><p>访问日志    /var/log/httpd/access_log</p></blockquote><blockquote><p>错误日志    /var/log/httpd/error_log</p></blockquote><p><a href=".httpd.png">配置结构</a></p><table><thead><tr><th>ServerRoot</th><th>服务目录</th></tr></thead><tbody><tr><td>ServerAdmin</td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr></tbody></table><blockquote><p>对服务机地址目录启动成文件访问服务</p></blockquote><hr><h4 id="3-Httpd-集成ldap"><a href="#3-Httpd-集成ldap" class="headerlink" title="3.Httpd 集成ldap"></a>3.Httpd 集成ldap</h4><blockquote><p>集成前需安装 mod_ldap</p></blockquote><pre><code>sudo suyum -y install mod_ldap</code></pre><blockquote><p>vim conf.d/auth_ldap.conf</p></blockquote><pre><code>&lt;Directory /data/dataplatform/zepplin/http_server/file/&gt;# AuthName &quot;LDAP Authentication&quot;AuthName &quot;zeppelin_file&quot;AuthType BasicAuthBasicProvider ldapAuthLDAPURL &quot;ldap://*****:389/ou=acs,dc=****,dc=com?uid?sub?(objectClass=*)&quot;AuthLDAPBindDN &quot;uid=gateway,ou=open,dc=****,dc=com&quot;AuthLDAPBindPassword &quot;********&quot;Require valid-user&lt;/Directory&gt;</code></pre><blockquote><p>测试配置是否异常 httpd -t</p></blockquote><blockquote><p>重启 httpd -k restart</p></blockquote><h4 id="相关参考"><a href="#相关参考" class="headerlink" title="相关参考"></a>相关参考</h4><blockquote><p><a href="https://www.bookstack.cn/read/linuxprobe/5bb5cdfbbed75940.md" target="_blank" rel="noopener">配置参考地址</a></p></blockquote><blockquote><p><a href="https://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">Apache http 服务器2.4 文档</a></p></blockquote><blockquote><p><a href="https://httpd.apache.org/download.cgi" target="_blank" rel="noopener">download</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;httpd-服务简介&quot;&gt;&lt;a href=&quot;#httpd-服务简介&quot; class=&quot;headerlink&quot; title=&quot;httpd 服务简介&quot;&gt;&lt;/a&gt;httpd 服务简介&lt;/h4&gt;&lt;hr&gt;
&lt;h4 id=&quot;2-httpd-作为文件服务的使用&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="httpd" scheme="https://23yue23.github.io/categories/httpd/"/>
    
    
      <category term="httpd" scheme="https://23yue23.github.io/tags/httpd/"/>
    
  </entry>
  
  <entry>
    <title>k8s-问题篇</title>
    <link href="https://23yue23.github.io/2019/11/12/k8s-%E9%97%AE%E9%A2%98%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/11/12/k8s-问题篇/</id>
    <published>2019-11-12T06:16:23.000Z</published>
    <updated>2019-12-18T06:52:08.313Z</updated>
    
    <content type="html"><![CDATA[<p>####1. Unable to connect to the server: dial tcp 192.168.99.100:8443: connect: no route to host</p><blockquote><p>问题原因：<br>     链接不上服务地址，可能是机器没有启动，或者节点已经丢失。</p></blockquote><blockquote><p>解决方案：<br>    查看运行状态 minikube status<br>     启动机器（测试虚拟机）</p></blockquote><hr><p>####2. error: unable to forward port because pod is not running. Current status=Pending</p><blockquote><p>查看问题：<br>  kubectl get nodes 首先查看node 是不是Ready 状态<br>  kubectl get pods (查看当前的pods)<br>  kubectl describe nodes （查看node 的vm 详细信息）<br>  kubectl get services (查看运行服务)</p></blockquote><hr><p>####3. Kube-proxy: error looking for path of conntrack</p><blockquote><p>kube-proxy 报错，并且 service 的 DNS 解析异常</p></blockquote><pre><code> kube-proxy[2241]: E0502 15:55:13.889842    2241 conntrack.go:42]  conntrack returned error: error looking for path of conntrack: exec: &quot;conntrack&quot;: executable file not found in $PATH</code></pre><blockquote><p>解决方式是安装 conntrack-tools 包后重启 kube-proxy 即可。</p></blockquote><hr><p>####4. “Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?”</p><blockquote><p>问题原因：是因为docker服务没有启动，所以在相应的/var/run/ 路径下找不到docker的进程。<br>解决方式：<br>   1.service docker start<br>   2.查看docker-machine是否安装。<br>  <a href="https://blog.csdn.net/Aaron_80726/article/details/83676014" target="_blank" rel="noopener">其他原因及解决方案</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;####1. Unable to connect to the server: dial tcp 192.168.99.100:8443: connect: no route to host&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;问题原因：&lt;br&gt;     链接不上服务地
      
    
    </summary>
    
      <category term="k8s" scheme="https://23yue23.github.io/categories/k8s/"/>
    
    
      <category term="k8s-问题篇" scheme="https://23yue23.github.io/tags/k8s-%E9%97%AE%E9%A2%98%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>k8s-实战篇</title>
    <link href="https://23yue23.github.io/2019/10/25/k8s-%E5%AE%9E%E6%88%98%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/25/k8s-实战篇/</id>
    <published>2019-10-25T02:15:02.000Z</published>
    <updated>2019-12-18T06:51:39.277Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-kubectl-操作"><a href="#1-kubectl-操作" class="headerlink" title="1. kubectl 操作"></a>1. kubectl 操作</h4><h5 id="1-1-kubectl-配置"><a href="#1-1-kubectl-配置" class="headerlink" title="1.1 kubectl 配置"></a>1.1 kubectl 配置</h5><h5 id="1-3-kubectl-权限"><a href="#1-3-kubectl-权限" class="headerlink" title="1.3 kubectl 权限"></a>1.3 kubectl 权限</h5><pre><code>**********************# 权限问题 #*************************查看是否有权限：kubectl auth can-i &lt;list|create|edit|delete&gt; pods</code></pre><h4 id="2-minikube操作"><a href="#2-minikube操作" class="headerlink" title="2. minikube操作"></a>2. minikube操作</h4><h5 id="2-1-minikube-安装"><a href="#2-1-minikube-安装" class="headerlink" title="2.1 minikube 安装"></a>2.1 minikube 安装</h5><blockquote><p>1.下载virtualbox</p></blockquote><blockquote><p>2.brew cask install minikube</p></blockquote><blockquote><p>3.minikube start –vm-driver=virtualbox</p></blockquote><blockquote><p>4.minikube config set vm-driver virtualbox</p></blockquote><blockquote><p>5.kubectl version 查看版本</p></blockquote><h5 id="2-2-minikube-常用操作"><a href="#2-2-minikube-常用操作" class="headerlink" title="2.2 minikube 常用操作"></a>2.2 minikube 常用操作</h5><pre><code>#启动并创建集群minikube start#查看仪表盘minikube dashboard#使用现有镜像kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.10#访问时将端口进行公开映射kubectl expose deployment hello-minikube --type=NodePort --port=8080#查看是否已经正在运行kubectl get pods#获取公开服务的URL以查看服务详细信息minikube service hello-minikube --url#curl 获取的url 查看本地集群的详细信息curl http://192.168.99.100:30083#删除 hello-minikube 服务kubectl delete services hello-minikube#删除 hello-minikube 部署kubectl delete deployment hello-minikube#停止本地minikube 集群minikube stop#删除本地minikube 集群minikube delete</code></pre><h5 id="2-3-minikube-的应用和服务"><a href="#2-3-minikube-的应用和服务" class="headerlink" title="2.3 minikube 的应用和服务"></a>2.3 minikube 的应用和服务</h5><pre><code>********************# 应用和服务 #*************#启动minikubeminikube start#部署应用kubectl run hello-minikube --image=k8s.gcr.io/echoserver:1.4 --port=8080#确定deploymentkubectl get deployment#查看部署的应用kubectl get pods#发布应用kubectl expose deployment hello-minikube --type=NodePort#查看发布的内容kubectl get services#访问服务1.虚拟机：curl http://ip:port2.curl $(minikube service hello-minikube --url)#获取服务url 链接minikube service --url service_name#查看控制台minikube dashboard查看所有Kubernetes Pod的部署状态kubectl get po -A#删除服务kubectl delete services hello-minikube#删除应用kubectl delete deployment hello-minikube#删除podskubectl delete pods podName#停止minikubeminikube stop#进入minikube 控制台minikube ssh</code></pre><hr><h5 id="2-4-minikube-集群相关"><a href="#2-4-minikube-集群相关" class="headerlink" title="2.4 minikube 集群相关"></a>2.4 minikube 集群相关</h5><pre><code>**********************# 集群相关 #**************************#获取集群的ipminikube ip#获取集群节点kubectl get nodes#启动第二个本地集群minikube start -p cluster2#停止本地集群minikube stop#删除本地集群minikube delete#删除所有本地集群和配置文件minikube delete --all获取网桥ipminikube ssh &quot;route -n | grep ^0.0.0.0 | awk &#39;{ print \$2 }&#39;&quot;链接到集群minikubeminikube sshtelnet ip port</code></pre><hr><h5 id="2-5-minikube-附加组件"><a href="#2-5-minikube-附加组件" class="headerlink" title="2.5 minikube 附加组件"></a>2.5 minikube 附加组件</h5><pre><code>********************************* 附加组件 ********************#查询可添加的组件minikube addons list#启用组件minikube addons enable &lt;name&gt;#与组件交互minikube addons open &lt;name&gt;#禁用组件minikube addons disable &lt;name&gt;</code></pre><hr><h5 id="2-6-minikube-调试"><a href="#2-6-minikube-调试" class="headerlink" title="2.6 minikube 调试"></a>2.6 minikube 调试</h5><pre><code>************************** 启动调试日志 *******************--v=0将输出INFO级别的日志--v=1将输出警告级别的日志--v=2将输出错误级别的日志--v=3将输出libmachine日志记录--v=7将输出libmachine –debug级日志记录minikube start --v=7 将启动minikube并将所有重要的调试日志输出到stdout#收集虚拟机日志，要调试Kubernetes部署失败的问题，收集Kubernetes pod和内核日志非常有用minikube logs#立即查看启动失败minikube logs --problems#查看所有Kubernetes Pod的部署状态kubectl get po -A</code></pre><h5 id="2-7-重用Docker-守护程序使用本地映像"><a href="#2-7-重用Docker-守护程序使用本地映像" class="headerlink" title="2.7 重用Docker 守护程序使用本地映像"></a>2.7 重用Docker 守护程序使用本地映像</h5><pre><code>eval $(minikube docker-env)docker ps</code></pre><hr><h4 id="4-学习案例"><a href="#4-学习案例" class="headerlink" title="4.学习案例"></a>4.学习案例</h4><h5 id="4"><a href="#4" class="headerlink" title="4."></a>4.</h5><hr><h4 id="5-kubectl应用和服务"><a href="#5-kubectl应用和服务" class="headerlink" title="5.kubectl应用和服务"></a>5.kubectl应用和服务</h4><hr><p>####6. </p><hr><h4 id="10-docker-常用操作"><a href="#10-docker-常用操作" class="headerlink" title="10.docker 常用操作"></a>10.docker 常用操作</h4><h5 id="10-1-镜像的操作"><a href="#10-1-镜像的操作" class="headerlink" title="10.1 镜像的操作"></a>10.1 镜像的操作</h5><pre><code>列出所有的镜像: docker images 停止运行：docker stop iamgesId删除单个镜像：docker rmi imagesId清理所有（慎用）：docker system pruneWARNING! This will remove:  - all stopped containers  - all networks not used by at least one container  - all dangling images  - all dangling build cache 清理镜像：docker image prune 清理容器：docker container prune 删除所有停止的镜像docker image prune -f -a 删除所有停止的容器：docker container prune -f复制文件：docker cp mycontainer:/opt/file.txt /opt/local/docker cp /opt/local/file.txt mycontainer:/opt/</code></pre><hr><h4 id="11-docker-常见问题及解决方案"><a href="#11-docker-常见问题及解决方案" class="headerlink" title="11.docker 常见问题及解决方案"></a>11.docker 常见问题及解决方案</h4><h5 id="11-1-docker日志太多导致磁盘占满"><a href="#11-1-docker日志太多导致磁盘占满" class="headerlink" title="11.1 docker日志太多导致磁盘占满"></a>11.1 docker日志太多导致磁盘占满</h5><blockquote><p>在启动时遇到：No space left on device 官方解决方案：<a href="https://success.docker.com/article/no-space-left-on-device-error" target="_blank" rel="noopener">地址</a></p></blockquote><pre><code>## 1.Sort the /var/lib/docker/containersdu -d1 -h /var/lib/docker/containers | sort -h## 2. 选择要清理的容器进行清理 cat /dev/null &gt;     /var/lib/docker/containers/********## 3.限制日志文件的大小：启动容器时，可以通过参数设置日志文件的大小、日志文件的格式 docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash</code></pre><h4 id="12-kubectl常用故障排查以及修改命令"><a href="#12-kubectl常用故障排查以及修改命令" class="headerlink" title="12.kubectl常用故障排查以及修改命令"></a>12.kubectl常用故障排查以及修改命令</h4><blockquote><p>scale </p></blockquote><pre><code>scale命令进行横向扩展，将原本为1的副本，提高到3kubectl scale --current-replicas=1 --replicas=3 deployment/nginx</code></pre><blockquote><p>autoscale</p></blockquote><pre><code>和scale不同的是autoscale则会根据负载进行调解kubectl autoscale deployment nginx --min=2 --max=5</code></pre><blockquote><p>cordon</p></blockquote><pre><code>查询nodeAddresskubectl get pods -o wide设定nodeAddress，使得nodeAddress不可使用，使用get node确认，其状态显示SchedulingDisabledkubectl cordon nodeAddress案例：设定134不可用：kubectl cordon 192.168.32.134横向扩展：kubectl scale --replicas=6 deployment/nginx发现没有pods 再执行在134这台机器上。</code></pre><blockquote><p>kubectl uncordon</p></blockquote><pre><code>解除限制kubectl uncordon nodeAddress</code></pre><blockquote><p>kubectl drain </p></blockquote><pre><code>drain命令用于对某个node进行设定，是为了设定此node为维护做准备。此命令主要执行的操作是：1. 设定此node不可以使用（cordon)2. evict（回收）了其上的两个pod</code></pre><blockquote><p>kubectl api-versions</p></blockquote><pre><code>查看当前版本的kubernetes的服务器端所支持的api版本信息</code></pre><blockquote><p>kubectl get all -o wide</p></blockquote><pre><code>列出pod services deployment replicaset 的信息</code></pre><blockquote><p>kubectl 可get 的信息</p></blockquote><pre><code>kubectl get deploymentskubectl get podskubectl get namespaces</code></pre><blockquote><p>kubectl 查看详情信息</p></blockquote><pre><code>kubectl describe node 192.168.32.132kubectl describe deployment mysql</code></pre><blockquote><p>kubectl 查看日志</p></blockquote><pre><code>kubectl logs podsName</code></pre><h4 id="13-学习案例2"><a href="#13-学习案例2" class="headerlink" title="13.学习案例2"></a>13.学习案例2</h4><pre><code>[root@node1 wordpress]# cat wordpress-db.yaml---apiVersion: apps/v1beta1kind: Deploymentmetadata:name: mysql-deploylabels:app: mysqlspec:template:metadata:labels:app: mysqlspec:containers:- name: mysqlimage: mysql:5.7imagePullPolicy: IfNotPresentports:- containerPort: 3306name: dbportenv:- name: MYSQL_ROOT_PASSWORDvalue: rootPassW0rd- name: MYSQL_DATABASEvalue: wordpress- name: MYSQL_USERvalue: wordpress- name: MYSQL_PASSWORDvalue: wordpressvolumeMounts:- name: dbmountPath: /var/lib/mysqlvolumes:- name: dbhostPath:path: /var/lib/mysql---apiVersion: v1kind: Servicemetadata:name: mysqlspec:selector:app: mysqlports:- name: mysqlportprotocol: TCPport: 3306targetPort: dbport[root@node1 wordpress]# cat wordpress.yamlapiVersion: apps/v1beta1kind: Deploymentmetadata:name: wordpress-deploylabels:app: wordpressspec:template:metadata:labels:app: wordpressspec:containers:- name: wordpressimage: wordpressimagePullPolicy: IfNotPresentports:- containerPort: 80name: wdportenv:- name: WORDPRESS_DB_HOSTvalue: mysql:3306- name: WORDPRESS_DB_USERvalue: wordpress- name: WORDPRESS_DB_PASSWORDvalue: wordpress---apiVersion: v1kind: Servicemetadata:name: wordpressspec:type: NodePortselector:app: wordpressports:- name: wordpressportprotocol: TCPport: 80targetPort: wdport#### 启动容器kubectl create -f wordpress-db.yamlkubectl create -f wordpress.yaml#### 查看集群信息kubectl get all -A -l app=wordpressNAMESPACE NAME READY STATUS RESTARTS AGEdefault pod/wordpress-deploy-f9c5cf5c6-tj2bc 1/1 Running 0 80mNAMESPACE NAME READY UP-TO-DATE AVAILABLE AGEdefault deployment.apps/wordpress-deploy 1/1 1 1 80mNAMESPACE NAME DESIRED CURRENT READY AGEdefault replicaset.apps/wordpress-deploy-f9c5cf5c6 1 1 1 80m#### 配置ingress[root@node1 wordpress]# cat ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata:name: wordpress-ingressnamespace: defaultannotations:kubernetes.io/ingress.class: &quot;nginx&quot;spec:rules:- host: wordpress.boshao.wanghttp:paths:- backend:serviceName: wordpressservicePort: 80#### 创建ingresskubectl create -f ingress.yaml#### 查看ingres信息[root@node1 wordpress]# kubectl get ing wordpress-ingressNAME HOSTS ADDRESS PORTS AGEwordpress-ingress wordpress.boshao.wang 80 78m[root@node1 wordpress]# kubectl describe ingress wordpress-ingressName: wordpress-ingressNamespace: defaultAddress:Default backend: default-http-backend:80 (&lt;none&gt;)Rules:Host Path Backends---- ---- --------wordpress.boshao.wangwordpress:80 (10.233.70.27:80)Annotations:kubernetes.io/ingress.class: nginxEvents: &lt;none&gt;#### 最后绑定域名wordpress.boshao.wang  到node节点即可。通过ingress-nginx 暴露的端口进行访问，即可。ingress-nginx service/ingress-nginx NodePort 10.233.29.94 &lt;none&gt; 80:31661/TCP,443:30250/TCP 6d2h访问方式：wordpress.boshao.wang → node ip:31661 http://wordpress.boshao.wang:31661/</code></pre><hr><h4 id="参考地址："><a href="#参考地址：" class="headerlink" title="参考地址："></a>参考地址：</h4><blockquote><p><a href="https://minikube.sigs.k8s.io/" target="_blank" rel="noopener">minikube参考</a></p></blockquote><blockquote><p><a href="https://k8smeetup.github.io/docs/user-guide/kubectl/v1.7/#-strong-getting-started-strong-" target="_blank" rel="noopener">命令查询</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-kubectl-操作&quot;&gt;&lt;a href=&quot;#1-kubectl-操作&quot; class=&quot;headerlink&quot; title=&quot;1. kubectl 操作&quot;&gt;&lt;/a&gt;1. kubectl 操作&lt;/h4&gt;&lt;h5 id=&quot;1-1-kubectl-配置&quot;&gt;&lt;a href
      
    
    </summary>
    
      <category term="k8s" scheme="https://23yue23.github.io/categories/k8s/"/>
    
    
      <category term="k8s-实战篇" scheme="https://23yue23.github.io/tags/k8s-%E5%AE%9E%E6%88%98%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>python-常用篇</title>
    <link href="https://23yue23.github.io/2019/10/24/python-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/24/python-常用篇/</id>
    <published>2019-10-24T10:26:44.000Z</published>
    <updated>2019-12-11T01:59:05.491Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-pyenv-的使用"><a href="#1-pyenv-的使用" class="headerlink" title="1.pyenv 的使用"></a>1.pyenv 的使用</h4><pre><code> #查看python 版本信息   pyenv versions #python 切换版本   pyenv local 版本号</code></pre><blockquote><p><a href="https://github.com/eteplus/blog/issues/4" target="_blank" rel="noopener">Mac下pyenv与pyenv-virtualenv的安装和使用</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-pyenv-的使用&quot;&gt;&lt;a href=&quot;#1-pyenv-的使用&quot; class=&quot;headerlink&quot; title=&quot;1.pyenv 的使用&quot;&gt;&lt;/a&gt;1.pyenv 的使用&lt;/h4&gt;&lt;pre&gt;&lt;code&gt; #查看python 版本信息
   pyenv v
      
    
    </summary>
    
      <category term="python" scheme="https://23yue23.github.io/categories/python/"/>
    
    
      <category term="python-常用篇" scheme="https://23yue23.github.io/tags/python-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>cassandra-案例篇</title>
    <link href="https://23yue23.github.io/2019/10/15/cassandra-%E6%A1%88%E4%BE%8B%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/15/cassandra-案例篇/</id>
    <published>2019-10-15T07:40:19.000Z</published>
    <updated>2019-12-17T01:55:21.739Z</updated>
    
    <content type="html"><![CDATA[<h4 id="java-链接cassandra-查询"><a href="#java-链接cassandra-查询" class="headerlink" title="java 链接cassandra 查询"></a>java 链接cassandra 查询</h4><pre><code>导入依赖 &lt;!-- https://mvnrepository.com/artifact/com.datastax.cassandra/cassandra-driver-core --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.datastax.cassandra&lt;/groupId&gt;    &lt;artifactId&gt;cassandra-driver-core&lt;/artifactId&gt;    &lt;version&gt;3.7.1&lt;/version&gt; &lt;/dependency&gt;import com.datastax.driver.core.Cluster;import com.datastax.driver.core.ResultSet;import com.datastax.driver.core.Row;import com.datastax.driver.core.Session;import java.util.List;/** * @author xianchang.yue * @date 2019-10-15 14:59 */public class TestCassandra {    public static void main(String[] args) {        Cluster cluster = null;        try {            cluster = Cluster.builder().addContactPoints(&quot;127.0.0.1&quot;).withPort(9042).build();            Session session = cluster.connect();            ResultSet execute = session.execute(&quot;select * from system_schema.keyspaces&quot;);            List&lt;Row&gt; all = execute.all();            for (Row row : all) {                String keyspace_name = row.getString(&quot;keyspace_name&quot;);                System.out.println(keyspace_name);            }        } finally {            if (cluster != null) {                cluster.close();            }        }    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;java-链接cassandra-查询&quot;&gt;&lt;a href=&quot;#java-链接cassandra-查询&quot; class=&quot;headerlink&quot; title=&quot;java 链接cassandra 查询&quot;&gt;&lt;/a&gt;java 链接cassandra 查询&lt;/h4&gt;&lt;pre&gt;
      
    
    </summary>
    
      <category term="cassandra" scheme="https://23yue23.github.io/categories/cassandra/"/>
    
    
      <category term="cassandra-案例篇" scheme="https://23yue23.github.io/tags/cassandra-%E6%A1%88%E4%BE%8B%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>k8s-学习篇</title>
    <link href="https://23yue23.github.io/2019/10/15/k8s-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/15/k8s-学习篇/</id>
    <published>2019-10-15T04:03:49.000Z</published>
    <updated>2019-12-18T06:51:01.624Z</updated>
    
    <content type="html"><![CDATA[<h4 id="k8s-介绍"><a href="#k8s-介绍" class="headerlink" title="k8s 介绍"></a>k8s 介绍</h4><p>Kubernetes 是一个生产级的开源平台，用于协调计算机集群内部和跨计算机集群的应用程序容器的分发(调度)和运行。<br>一个 Master 是集群的调度节点。<br>nodes 是应用程序实际运行的工作节点。</p><h4 id="k8s-重要组件"><a href="#k8s-重要组件" class="headerlink" title="k8s 重要组件"></a>k8s 重要组件</h4><p>k8s核心组件：</p><blockquote><p>etcd保存了整个集群的状态；  </p></blockquote><blockquote><p>apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；  </p></blockquote><blockquote><p>controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；  </p></blockquote><blockquote><p>scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；  </p></blockquote><blockquote><p>kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；  </p></blockquote><blockquote><p>Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）；  </p></blockquote><blockquote><p>kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；  </p></blockquote><p>推荐的Add-ons：</p><blockquote><p>kube-dns负责为整个集群提供DNS服务</p></blockquote><blockquote><p>Ingress Controller为服务提供外网入口</p></blockquote><blockquote><p>Heapster提供资源监控</p></blockquote><blockquote><p>Dashboard提供GUI</p></blockquote><blockquote><p>Federation提供跨可用区的集群</p></blockquote><blockquote><p>Fluentd-elasticsearch提供集群日志采集、存储与查询</p></blockquote><h4 id="k8s-部署"><a href="#k8s-部署" class="headerlink" title="k8s 部署"></a>k8s 部署</h4><p>在k8s中，通过发布 Deployment，可以创建应用程序 (docker image) 的实例 (docker container)，这个实例会被包含在称为 Pod 的概念中，Pod 是 k8s 中最小单元的可管理单元</p><p>在 k8s 集群中发布 Deployment 后，Deployment 将指示 k8s 如何创建和更新应用程序的实例，master 节点将应用程序实例调度到集群中的具体的节点上。</p><p>创建应用程序实例后，Kubernetes Deployment Controller 会持续监控这些实例。如果运行实例的 worker 节点关机或被删除，则 Kubernetes Deployment Controller 将在群集中资源最优的另一个 worker 节点上重新创建一个新的实例。这提供了一种自我修复机制来解决机器故障或维护问题。</p><p>在容器编排之前的时代，各种安装脚本通常用于启动应用程序，但是不能够使应用程序从机器故障中恢复。通过创建应用程序实例并确保它们在集群节点中的运行实例个数，Kubernetes Deployment 提供了一种完全不同的方式来管理应用程序。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/ingress/</a></p><p>nginx官方介绍：<a href="https://www.nginx.com/products/nginx/kubernetes-ingress-controller" target="_blank" rel="noopener">https://www.nginx.com/products/nginx/kubernetes-ingress-controller</a></p><h4 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h4><p><a href="https://kubernetes.github.io/ingress-nginx/deploy/#prerequisite-generic-deployment-command" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/deploy/#prerequisite-generic-deployment-command</a></p><p>首先先下载相关的yaml文件，保存到本地。</p><p>deployments：<br>kubectl apply -f <a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml</a></p><p>service： 这里官方提供了各种云平台，系统等相关配置。我们这里是自建的k8s集群，所以我们选择裸机版本。</p><p>Bare-metal<br>Using NodePort:</p><p>kubectl apply -f <a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/baremetal/service-nodeport.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/baremetal/service-nodeport.yaml</a></p><p>安装完后。看看集群信息。</p><p>[root@node1 ingress-nginx]# kubectl get all -A -l app.kubernetes.io/name=ingress-nginx<br>NAMESPACE NAME READY STATUS RESTARTS AGE<br>ingress-nginx pod/nginx-ingress-controller-79f6884cf6-vh2w2 1/1 Running 0 5d3h</p><p>NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE<br>ingress-nginx service/ingress-nginx NodePort 10.233.29.94 <none> 80:31661/TCP,443:30250/TCP 6d2h</none></p><p>NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE<br>ingress-nginx deployment.apps/nginx-ingress-controller 1/1 1 1 6d3h</p><p>NAMESPACE NAME DESIRED CURRENT READY AGE<br>ingress-nginx replicaset.apps/nginx-ingress-controller-79f6884cf6 1 1 1 6d3h</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;k8s-介绍&quot;&gt;&lt;a href=&quot;#k8s-介绍&quot; class=&quot;headerlink&quot; title=&quot;k8s 介绍&quot;&gt;&lt;/a&gt;k8s 介绍&lt;/h4&gt;&lt;p&gt;Kubernetes 是一个生产级的开源平台，用于协调计算机集群内部和跨计算机集群的应用程序容器的分发(调度
      
    
    </summary>
    
      <category term="k8s" scheme="https://23yue23.github.io/categories/k8s/"/>
    
    
      <category term="k8s-学习篇" scheme="https://23yue23.github.io/tags/k8s-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>sql-常用篇</title>
    <link href="https://23yue23.github.io/2019/10/15/sql-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/15/sql-常用篇/</id>
    <published>2019-10-15T03:17:16.000Z</published>
    <updated>2019-10-15T03:17:44.017Z</updated>
    
    <content type="html"><![CDATA[<h4 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h4><p><a href="https://www.sqlstyle.guide/zh/" target="_blank" rel="noopener">https://www.sqlstyle.guide/zh/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;编程规范&quot;&gt;&lt;a href=&quot;#编程规范&quot; class=&quot;headerlink&quot; title=&quot;编程规范&quot;&gt;&lt;/a&gt;编程规范&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://www.sqlstyle.guide/zh/&quot; target=&quot;_blank&quot; rel=&quot;
      
    
    </summary>
    
      <category term="sql" scheme="https://23yue23.github.io/categories/sql/"/>
    
    
      <category term="sql-常用篇" scheme="https://23yue23.github.io/tags/sql-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>详细文档设计规范</title>
    <link href="https://23yue23.github.io/2019/10/15/%E8%AF%A6%E7%BB%86%E6%96%87%E6%A1%A3%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/"/>
    <id>https://23yue23.github.io/2019/10/15/详细文档设计规范/</id>
    <published>2019-10-15T02:55:47.000Z</published>
    <updated>2019-11-12T09:07:25.369Z</updated>
    
    <content type="html"><![CDATA[<h4 id="详细设计的目标"><a href="#详细设计的目标" class="headerlink" title="详细设计的目标"></a>详细设计的目标</h4><p>在项目实施之前进行问题、方案等重要项目信息的归纳整理。书写文档的过程中模块负责人能够更深入的思考问题与解决方案，提升对目标的理解、后续工作的质量、效率，降低项目风险。文档本身作为组织资产进行信息载体，发挥长期的价值。</p><h4 id="详细设计文档原则"><a href="#详细设计文档原则" class="headerlink" title="详细设计文档原则"></a>详细设计文档原则</h4><p>能够面向不了解业务&amp;技术背景的人群</p><p>清晰表述完主要问题以及解决方案</p><p>详细设计阶段必须定义接口(也可以单独书写接口文档)</p><p>考虑到测试、运维、产品的主要关注点</p><h4 id="设计文档的格式以及载体"><a href="#设计文档的格式以及载体" class="headerlink" title="设计文档的格式以及载体"></a>设计文档的格式以及载体</h4><p>格式: markdown 或 word(更新时使用审阅模式)</p><p>载体: gitlab , 文档存放项目下doc目录, 每次发版tag携带最新文档</p><h4 id="详细设计的适用场景"><a href="#详细设计的适用场景" class="headerlink" title="详细设计的适用场景"></a>详细设计的适用场景</h4><h5 id="需要写详细设计文档的场景"><a href="#需要写详细设计文档的场景" class="headerlink" title="需要写详细设计文档的场景"></a>需要写详细设计文档的场景</h5><p>新的线上模块</p><p>架构的大调整</p><p>对业务产生较大的影响的版本</p><h5 id="不需要写详细设计文档的场景"><a href="#不需要写详细设计文档的场景" class="headerlink" title="不需要写详细设计文档的场景"></a>不需要写详细设计文档的场景</h5><p>不影响架构bug修复和升级且不影响主体逻辑和接口</p><h4 id="详细设计文档规范"><a href="#详细设计文档规范" class="headerlink" title="详细设计文档规范"></a>详细设计文档规范</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;详细设计的目标&quot;&gt;&lt;a href=&quot;#详细设计的目标&quot; class=&quot;headerlink&quot; title=&quot;详细设计的目标&quot;&gt;&lt;/a&gt;详细设计的目标&lt;/h4&gt;&lt;p&gt;在项目实施之前进行问题、方案等重要项目信息的归纳整理。书写文档的过程中模块负责人能够更深入的思考问题
      
    
    </summary>
    
      <category term="杂七杂八" scheme="https://23yue23.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
    
      <category term="详细文档设计规范" scheme="https://23yue23.github.io/tags/%E8%AF%A6%E7%BB%86%E6%96%87%E6%A1%A3%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>shell-案例篇</title>
    <link href="https://23yue23.github.io/2019/10/15/shell-%E6%A1%88%E4%BE%8B%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/15/shell-案例篇/</id>
    <published>2019-10-15T02:50:56.000Z</published>
    <updated>2019-11-12T09:06:35.412Z</updated>
    
    <content type="html"><![CDATA[<pre><code>## 此shell脚本只在bash解释器下测试运行过, sh解释器不保证一定正确## 关于bash和sh有啥区别, 大家可自行Google, 我建议大家使用bash## 可能大部分Linux系统, bash跟sh不会有太多区别, 但是如果你用Debian或者Ubuntu的话## 你会发现之前写的脚本sh运行会爆出一堆语法错误, 因为他们的sh等于Dash, 很蛋疼.###################PRODUCTLINE=&quot;rta&quot;PROJECT=&quot;ga-device&quot;## 自带出错邮件报警: 尽量使用邮件组而不是使用具体某个人的邮箱## 因为科比曾经说过: 朋友来来走走, 冠军旗帜永不倒## 使用具体某个人的邮箱回头离职了邮件就发不出来了ALARM_ADDR=&quot;bin.li@mobvista.com&quot;ALARM_CC=&quot;bin.li@mobvista.com&quot;## 钉钉报警有个好处是你可以建立群组, 而且可以分类, 不重要的信息你## 可以发到一个群里, 然后大家屏蔽群消息就好, 出问题的时候再去翻## dingtalkid: 钉钉群讨论的ID, 我想不需要我教你怎么获得这个IDALARM_DINGDING_TALKID=&quot;62138ba2d704500d24b21064663659e2288bdf5f6b72d8a8d5895746f2ee0f8f&quot;# https://oapi.dingtalk.com/robot/send?access_token=62138ba2d704500d24b21064663659e2288bdf5f6b72d8a8d5895746f2ee0f8fINFO_DINGDING_TALKID=&quot;d49490482e23f0780bf017ad04cb29d027755e0550578ff4324e48f989e7a4c1&quot;# https://oapi.dingtalk.com/robot/send?access_token=d49490482e23f0780bf017ad04cb29d027755e0550578ff4324e48f989e7a4c1## kibana使用的EleasticSearch的地址, 数据上报到ES, 才能用kibana展示出来## 尽量用公司统一的, 不要自己单独整## 如果觉得别人搞的不好用, 尽量推动别人优化## 而不是自己搭一个扔在那里没人管ES_ADDR=&quot;bj-report-ELB20151027-2124151593.us-east-1.elb.amazonaws.com:80&quot;ES_USER=&quot;mob_report&quot;ES_PASSWD=&quot;Mobvista_256&quot;## 顾名思义, 就是把一个JSON document推到ES## 这里面有一些概念: docid, doc, index, type(如果不知道啥意思, 自行google)## 参数:##   + docid: doc唯一的ID, 很多人喜欢让ES自己生成, 但是这个地方尽量不要,##     因为将来你的任务失败你还会补数呢, 找一个唯一的ID, 或者拼一个出来,##     将来补数原来的doc会被自动覆盖掉, 不至于数据重复##   + doc: json doc##     任何你想塞进去的信息, 如果你足够聪明, 请塞一个格式化好的时间(北京时区)和##     一个时间戳进去function doc2es() {    local __docid=&quot;$1&quot;    local __doc=&quot;$2&quot;    curl -XPUT &quot;$ES_ADDR/mp_rba/cap_updater_jobstatus/$__docid&quot; \         -H &#39;Content-Type: application/json&#39; \         -u &quot;$ES_USER:$ES_PASSWD&quot; -d&quot;$__doc&quot;}## 邮件报警, 会使用全局变量里面的收件人地址 ALARM_ADDR &amp; ALARM_CC## 两个参数:##   + sub: 邮件主题##   + body: 报警内容(别JB图省事, 多写点东西又不会死, 让别人一眼看出来发生了什么吧!)function email_alarm() {    local _sub=$1    local _body=&quot;$2&quot;    cat &quot;$_body&quot; | mail -s &quot;[$PRODUCTLINE][$PROJECT]$_sub&quot; -c &quot;$ALARM_CC&quot; &quot;$ALARM_ADDR&quot;}function send_dingding_msg() {    local _dingtalkid=&quot;$1&quot;    local _msg=&quot;$2&quot;    url=&quot;https://oapi.dingtalk.com/robot/send?access_token=$_dingtalkid&quot;    body=&quot;{         \&quot;msgtype\&quot;: \&quot;text\&quot;,         \&quot;text\&quot;: {             \&quot;content\&quot;: \&quot;[$PRODUCTLINE][$PROJECT] Failed !!! [$_msg]\&quot;         },        \&quot;at\&quot;: {             \&quot;atMobiles\&quot;: [],             \&quot;isAtAll\&quot;: false         }    }&quot;    curl &quot;$url&quot;  -H &#39;Content-Type: application/json&#39; -X POST -d &quot;$body&quot;}## 钉钉报警, 会使用全局变量里面的收件人地址 ALARM_ADDR &amp; ALARM_CC## 参数:##   + msg: 报警内容(别JB图省事, 多写点东西又不会死, 让别人一眼看出来发生了什么吧!)function dingding_alarm() {    send_dingding_msg $ALARM_DINGDING_TALKID &quot;$1&quot;}function dingding_info() {    send_dingding_msg $INFO_DINGDING_TALKID &quot;$1&quot;}## 就是想让输出多个时间而已## 参数: 你想打的消息function info() {    local _msg=&quot;$1&quot;    echo &quot;$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) INFO [$_msg]&quot;}## 就是想让输出多个时间而已## 参数: 你想打的消息function error() {    local _msg=&quot;$1&quot;    echo &quot;$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) ERROR [$_msg]&quot;}## 任务运行结束, 清理掉临时文件## 参数: 给个文件名function clean_file() {    local _f=&quot;$1&quot;    if [ -f $_f ]; then        info &quot;rm $_f&quot;        rm $_f    fi}## 任务运行结束, 备份重要结果文件## 参数: 给个文件名和后缀## 比如: back_file file-name 2019032013function back_file() {    local _f=&quot;$1&quot;    local _postfix=&quot;$2&quot;    if [ -f $_f ]; then        info &quot;mv $_f $_f.$_postfix&quot;        mv $_f $_f.$_postfix    fi}</code></pre><pre><code># 为了方便CTI和CVR的计算, 我们需要从s3拉取一些中间结果下来# 这个地方定义一个下载函数# 希望达到的效果是, 给定一个输入路径, 可以把这个路径下的所有文件都下载下来# 并且导到一个目标文件中# 当然还需要做一下文件大小的check, 别把本地磁盘给撑爆了function download_from_s3_dir() {    local _s3_dir=$1    local _local_file=$2    local _tmp_index=&quot;__tmp_index_for_download_s3_file__$(date +&quot;%s&quot;).$RANDOM&quot;    local _sz_max=4000000000    # local _sz_max=1000    # check file size 1st    if [ -f $_tmp_index ]; then        rm $_tmp_index    fi    run_with_check &quot;aws s3 ls $_s3_dir &gt; $_tmp_index&quot;    if [ 0 -eq $(wc -l $_tmp_index | awk &#39;{print $1}&#39;) ]; then        echo &quot;WARNING: no file in $_s3_dir&quot;        touch $_local_file    else        local _sz_tt=0        for sz in $(cat $_tmp_index | awk &#39;{print $3}&#39;)        do            echo $sz  # debug            _sz_tt=$((_sz_tt+$sz))        done        if [ $_sz_tt -gt $_sz_max ]; then            echo &quot;ERROR: files too large exit!!! [$_sz_tt &gt; $_sz_max]&quot;            exit 1        fi        if [ -f $_local_file ]; then            rm $_local_file        fi        for f in $(cat $_tmp_index | awk &#39;{print $3&quot;|&quot;$4}&#39;)        do            local _sz=$(echo &quot;$f&quot; | awk -F&#39;|&#39; &#39;{print $1}&#39;)            local _ff=$(echo &quot;$f&quot; | awk -F&#39;|&#39; &#39;{print $2}&#39;)            local _ff_local=$_ff&quot;.$(date +&quot;%s&quot;).$RANDOM&quot;            if [ x&quot;0&quot; = x&quot;$_sz&quot; ]; then                continue            fi            run_with_check &quot;aws s3 cp $_s3_dir$_ff $_ff_local&quot;            run_with_check &quot;cat $_ff_local &gt;&gt; $_local_file&quot;            if [ -f $_ff_local ]; then                rm $_ff_local            fi        done    fi    if [ -f $_tmp_index ]; then        rm $_tmp_index    fi}</code></pre><pre><code>## 这个函数我想大家都可以用到## 把你任务一些可能会失败的操作过程, 比如从s3拷个文件## 比如执行一个py脚本, 比如curl一个东西## run_with_check, 发现失败, 自动报警, 而且立马终止任务## 参数: 你要执行的命令## 比如: run_with_check &quot;python demo.py&quot;function run_with_check {    cmd=&quot;$1&quot;    info &quot;$cmd&quot;    eval &quot;$cmd&quot;    if [ 0 -ne $? ]; then        error &quot;[$cmd] failed!!!!! exit !!!!!!!!&quot;        email_alarm &quot;[$PRODUCTLINE][$PROJECT] Failed !!!&quot; &quot;command exit code not 0: $cmd&quot;        dingding_alarm &quot;command exit code not 0: $cmd&quot;        exit 1    fi}</code></pre><h4 id="微信报警接口"><a href="#微信报警接口" class="headerlink" title="微信报警接口"></a>微信报警接口</h4><pre><code>#!/usr/bin/env python# coding:utf-8import sysimport urllib2import timeimport jsonimport requestsimport redisreload(sys)sys.setdefaultencoding(&#39;utf-8&#39;)print sys.argvmessage = sys.argv[3]   # 位置参数获取title 适用于zabbixuser = sys.argv[1] # 位置参数获取content 适用于zabbixPOOL = redis.ConnectionPool(host=&#39;&#39;,port=3721,password=&#39;&#39;,db=1)rs=redis.Redis(connection_pool=POOL)def send_msg(user,message):    # 发送消息    qs_token = rs.get(&#39;weixin&#39;)    url = &quot;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={0}&quot;.format(        qs_token)    payload = {        &quot;touser&quot;:user,        &quot;msgtype&quot;: &quot;text&quot;,        &quot;agentid&quot;: &quot;2&quot;,        &quot;text&quot;: {                   &quot;content&quot;: message        },        &quot;safe&quot;: &quot;0&quot;    }    ret = requests.post(url, data=json.dumps(payload, ensure_ascii=False))    print ret.json()if __name__ == &#39;__main__&#39;:    send_msg(user,message)# 使用方法：python  wetchat.py mail@qq.com subject message</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;## 此shell脚本只在bash解释器下测试运行过, sh解释器不保证一定正确
## 关于bash和sh有啥区别, 大家可自行Google, 我建议大家使用bash
## 可能大部分Linux系统, bash跟sh不会有太多区别, 但是如果你用Debian
      
    
    </summary>
    
      <category term="shell" scheme="https://23yue23.github.io/categories/shell/"/>
    
    
      <category term="shell-案例篇" scheme="https://23yue23.github.io/tags/shell-%E6%A1%88%E4%BE%8B%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>shell-常用篇</title>
    <link href="https://23yue23.github.io/2019/10/15/shell-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/15/shell-常用篇/</id>
    <published>2019-10-15T02:47:25.000Z</published>
    <updated>2019-10-16T06:10:22.565Z</updated>
    
    <content type="html"><![CDATA[<h4 id="shell-编程"><a href="#shell-编程" class="headerlink" title="shell 编程"></a>shell 编程</h4><h5 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h5><pre><code>=    两个字符串相等返回true!=    两个字符串不相等返回true-z    字符串长度为0返回true-n    字符串长度不为0返回true-d file    检测文件是否是目录，如果是，则返回 true-r file    检测文件是否可读，如果是，则返回 true-w file    检测文件是否可写，如果是，则返回 true-x file    检测文件是否可执行，如果是，则返回 true-s file    检测文件是否为空（文件大小是否大于0，不为空返回 true-e file    检测文件（包括目录）是否存在，如果是，则返回 true</code></pre><hr><h5 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h5><pre><code>#!/bin/bash#定义字符串mtext=&quot;hello&quot;  mtext2=&quot;world&quot;#字符串的拼接mtext3=$mtext&quot; &quot;$mtext2  #输出字符串echo $mtext3 #输出字符串长度echo ${#mtext3}  #截取字符串echo ${mtext3:1:4}  </code></pre><hr><h5 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h5><pre><code>#!/bin/bash#定义数组array=(1 2 3 4 5)  array2=(aa bb cc dd ee)  #找到某一个下标的数，然后赋值value=${array[3]}  echo $value  #找到某一个下标的数，然后赋值value2=${array2[3]} echo $value2  #获取数组长度length=${#array[*]} echo $length</code></pre><hr><h5 id="echo"><a href="#echo" class="headerlink" title="echo"></a>echo</h5><pre><code> #输出并且换行echo &quot;hello \nworld&quot; #重定向到文件echo &quot;hello world&quot; &gt; a.txt  #输出当前系统时间echo `date`  </code></pre><hr><h5 id="判断语句"><a href="#判断语句" class="headerlink" title="判断语句"></a>判断语句</h5><pre><code>#!/bin/sh#测试各种字符串比较操作。#shell中对变量的值添加单引号，爽引号和不添加的区别：对类型来说是无关的，即不是添加了引号就变成了字符串类型，#单引号不对相关量进行替换，如不对$符号解释成变量引用，从而用对应变量的值替代，双引号则会进行替代#author:tenfyguoA=&quot;$1&quot;B=&quot;$2&quot;echo &quot;输入的原始值：A=$A,B=$B&quot;#判断字符串是否相等if [ &quot;$A&quot; = &quot;$B&quot; ];thenecho &quot;[ = ]&quot;fi#判断字符串是否相等，与上面的=等价if [ &quot;$A&quot; == &quot;$B&quot; ];thenecho &quot;[ == ]&quot;fi#注意:==的功能在[[]]和[]中的行为是不同的，如下#如果$a以”a”开头(模式匹配)那么将为true if [[ &quot;$A&quot; == a* ]];thenecho &quot;[[ ==a* ]]&quot;fi#如果$a等于a*(字符匹配),那么结果为trueif [[ &quot;$A&quot; == &quot;a*&quot; ]];thenecho &quot;==/&quot;a*/&quot;&quot;fi  #File globbing(通配) 和word splitting将会发生, 此时的a*会自动匹配到对应的当前以a开头的文件#如在当前的目录中有个文件：add_crontab.sh,则下面会输出ok#if [ &quot;add_crontab.sh&quot; == a* ];then #echo &quot;ok&quot;#fiif [ &quot;$A&quot; == a* ];thenecho &quot;[ ==a* ]&quot;fi#如果$a等于a*(字符匹配),那么结果为trueif [ &quot;$A&quot; == &quot;a*&quot; ];thenecho &quot;==/&quot;a*/&quot;&quot;fi#字符串不相等if [ &quot;$A&quot; != &quot;$B&quot; ];thenecho &quot;[ != ]&quot;fi#字符串不相等if [[ &quot;$A&quot; != &quot;$B&quot; ]];thenecho &quot;[[ != ]]&quot;fi#字符串不为空，长度不为0if [ -n &quot;$A&quot; ];thenecho &quot;[ -n ]&quot;fi#字符串为空.就是长度为0.if [ -z &quot;$A&quot; ];thenecho &quot;[ -z ]&quot;fi#需要转义&lt;，否则认为是一个重定向符号if [ $A /&lt; $B ];thenecho &quot;[ &lt; ]&quot;  fiif [[ $A &lt; $B ]];thenecho &quot;[[ &lt; ]]&quot;  fi#需要转义&gt;，否则认为是一个重定向符号if [ $A /&gt; $B ];thenecho &quot;[ &gt; ]&quot;  fiif [[ $A &gt; $B ]];thenecho &quot;[[ &gt; ]]&quot;  fi</code></pre><pre><code>注意：1.if 和 [ ] 之间要有空格2.[ ] 和“ ”之间要有空格3.“ ”和 = 之间要有空格</code></pre><hr><h5 id="test-查看文件是否存在"><a href="#test-查看文件是否存在" class="headerlink" title="test 查看文件是否存在"></a>test 查看文件是否存在</h5><p><a href="https://blog.csdn.net/qq_34337272/article/details/85640050" target="_blank" rel="noopener">https://blog.csdn.net/qq_34337272/article/details/85640050</a></p><pre><code>test $[num1] -eq $[num2]  #判断两个变量是否相等test num1=num2  #判断两个数字是否相等-e file    文件存在则返回真-r file    文件存在并且可读则返回真-w file    文件存在并且可写则返回真-x file    文件存在并且可执行则返回真-s file    文件存在并且内容不为空则返回真-d file    文件目录存在则返回真</code></pre><h5 id="case…-esac"><a href="#case…-esac" class="headerlink" title="case….esac"></a>case….esac</h5><pre><code>case 值 in模式1)    command1    command2    command3    ;;模式2）    command1    command2    command3    ;;*)    command1    command2    command3    ;;esac# 匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。# ;; 与其他语言中的 break 类似，意思是不执行接下来的语句而是跳到整个 case 语句的最后。# *)与default相似，如果上面没有匹配到的模式，则执行*)里的内容。模式支持正则表达式:*       任意字串?       任意字元[abc]   a, b, 或c三字元其中之一[a-n]   从a到n的任一字元|       多重选择举例：#!/bin/sh case $1 instart | begin)    echo &quot;I am started!&quot;      ;;stop | end)    echo &quot;I am stopped!&quot;      ;;*)    echo &quot;Other command!&quot;      ;;esac</code></pre><hr><h5 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h5><pre><code>#!/bin/bashfor i in {1..5}do   echo $idonefor i in 5 6 7 8 9 do   echo $idonefor FILE in $HOME/.bash* do   echo $FILEdone</code></pre><hr><h5 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h5><pre><code>#!/bin/bashCOUNTER=0while [ $COUNTER lt 5 ]do    COUNTER=`expr $COUNTER + 1`        echo $COUNTERdoneecho &#39;请输入。。。&#39;echo &#39;ctrl + d 即可停止该程序&#39;while read FILM do    echo &quot;Yeah! great film the $FILM&quot;done</code></pre><hr><h4 id="Shell-脚本执行返回状态码："><a href="#Shell-脚本执行返回状态码：" class="headerlink" title="Shell 脚本执行返回状态码："></a>Shell 脚本执行返回状态码：</h4><p>状态码</p><table><thead><tr><th>状态码</th><th>含义</th></tr></thead><tbody><tr><td>0</td><td>命令成功完成</td></tr><tr><td>1</td><td>通常的未知错误</td></tr><tr><td>2</td><td>误用shell命令</td></tr><tr><td>126</td><td>命令无法执行</td></tr><tr><td>127</td><td>没有找到命令</td></tr><tr><td>128</td><td>无效的退出参数</td></tr><tr><td>128+x</td><td>使用Linux信号x的致命错误。</td></tr><tr><td>130</td><td>使用Ctrl-C终止的命令</td></tr><tr><td>255</td><td>规范外的退出状态</td></tr></tbody></table><h4 id="Shell-特殊变量列表"><a href="#Shell-特殊变量列表" class="headerlink" title="Shell 特殊变量列表"></a>Shell 特殊变量列表</h4><pre><code>特殊变量列表变量    含义$0    当前脚本的文件名$n    传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。$#    传递给脚本或函数的参数个数。$*    传递给脚本或函数的所有参数。$@    传递给脚本或函数的所有参数。被双引号(“ “)包含时，与 $* 稍有不同，下面将会讲到。$?    上个命令的退出状态，或函数的返回值。$$    当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。</code></pre><h5 id="变量注意事项"><a href="#变量注意事项" class="headerlink" title="变量注意事项"></a>变量注意事项</h5><pre><code>变量名=变量值等号“=”前后不可以有空格变量名不可以直接和其他字符相连，如果想相连，必须用括号：echo “this is $(he)llo!”</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;shell-编程&quot;&gt;&lt;a href=&quot;#shell-编程&quot; class=&quot;headerlink&quot; title=&quot;shell 编程&quot;&gt;&lt;/a&gt;shell 编程&lt;/h4&gt;&lt;h5 id=&quot;运算符&quot;&gt;&lt;a href=&quot;#运算符&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="shell" scheme="https://23yue23.github.io/categories/shell/"/>
    
    
      <category term="shell-常用篇" scheme="https://23yue23.github.io/tags/shell-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>go-常用篇</title>
    <link href="https://23yue23.github.io/2019/10/15/go-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/15/go-常用篇/</id>
    <published>2019-10-15T02:34:37.000Z</published>
    <updated>2019-12-17T02:04:13.591Z</updated>
    
    <content type="html"><![CDATA[<h4 id="编码规范"><a href="#编码规范" class="headerlink" title="编码规范"></a>编码规范</h4><p><a href="http://docscn.studygolang.com/doc/effective_go.html" target="_blank" rel="noopener">http://docscn.studygolang.com/doc/effective_go.html</a></p><h4 id="单测样例"><a href="#单测样例" class="headerlink" title="单测样例"></a>单测样例</h4><p><a href="http://gitlab.mobvista.com/mtech/mtech/blob/master/开发-Go单元测试.md" target="_blank" rel="noopener">http://gitlab.mobvista.com/mtech/mtech/blob/master/开发-Go单元测试.md</a></p><h4 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h4><p>开发可自由选择编辑器，推荐使用IDE：<a href="https://www.jetbrains.com/go/" target="_blank" rel="noopener">https://www.jetbrains.com/go/</a></p><h4 id="常用库"><a href="#常用库" class="headerlink" title="常用库"></a>常用库</h4><p>标准库: <a href="http://docscn.studygolang.com/pkg/" target="_blank" rel="noopener">http://docscn.studygolang.com/pkg/</a><br>日志: <a href="https://github.com/cihub/seelog" target="_blank" rel="noopener">https://github.com/cihub/seelog</a><br>配置: <a href="https://github.com/spf13/viper" target="_blank" rel="noopener">https://github.com/spf13/viper</a><br>uuid: <a href="https://github.com/satori/go.uuid" target="_blank" rel="noopener">https://github.com/satori/go.uuid</a><br>leveldb: <a href="https://github.com/syndtr/goleveldb/leveldb" target="_blank" rel="noopener">https://github.com/syndtr/goleveldb/leveldb</a><br>murmurhash3: <a href="https://github.com/spaolacci/murmur3" target="_blank" rel="noopener">https://github.com/spaolacci/murmur3</a><br>redis: <a href="https://github.com/garyburd/redigo/redis" target="_blank" rel="noopener">https://github.com/garyburd/redigo/redis</a><br>redis-cluster: <a href="https://github.com/chasex/redis-go-cluster" target="_blank" rel="noopener">https://github.com/chasex/redis-go-cluster</a><br>mongo: <a href="http://gopkg.in/mgo.v2" target="_blank" rel="noopener">http://gopkg.in/mgo.v2</a><br>命令行: <a href="http://gopkg.in/alecthomas/kingpin.v2" target="_blank" rel="noopener">http://gopkg.in/alecthomas/kingpin.v2</a><br>grpc: <a href="http://www.grpc.io/docs/quickstart/go.html" target="_blank" rel="noopener">http://www.grpc.io/docs/quickstart/go.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;编码规范&quot;&gt;&lt;a href=&quot;#编码规范&quot; class=&quot;headerlink&quot; title=&quot;编码规范&quot;&gt;&lt;/a&gt;编码规范&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;http://docscn.studygolang.com/doc/effective_go.html&quot; 
      
    
    </summary>
    
      <category term="go" scheme="https://23yue23.github.io/categories/go/"/>
    
    
      <category term="go-常用篇" scheme="https://23yue23.github.io/tags/go-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>git-常用篇</title>
    <link href="https://23yue23.github.io/2019/10/14/git-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/14/git-常用篇/</id>
    <published>2019-10-14T05:42:39.000Z</published>
    <updated>2019-12-17T02:03:40.171Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>git config –global user.name “你的名字” 让你全部的Git仓库绑定你的名字</p></blockquote><blockquote><p>git config –global user.email “你的邮箱” 让你全部的Git仓库绑定你的邮箱</p></blockquote><blockquote><p>git init 初始化你的仓库</p></blockquote><blockquote><p>git add . 把工作区的文件全部提交到暂存区</p></blockquote><blockquote><p>git add ./<file>/ 把工作区的<file>文件提交到暂存区</file></file></p></blockquote><blockquote><p>git commit -m “xxx” 把暂存区的所有文件提交到仓库区，暂存区空空荡荡</p></blockquote><blockquote><p>git remote add origin <a href="https://github.com/name/name_cangku.git" target="_blank" rel="noopener">https://github.com/name/name_cangku.git</a> 把本地仓库与远程仓库连接起来</p></blockquote><blockquote><p>git push -u origin master 把仓库区的主分支master提交到远程仓库里</p></blockquote><blockquote><p>git push -u origin &lt;其他分支&gt; 把其他分支提交到远程仓库</p></blockquote><blockquote><p>git status查看当前仓库的状态</p></blockquote><blockquote><p>git diff 查看文件修改的具体内容</p></blockquote><blockquote><p>git log 显示从最近到最远的提交历史</p></blockquote><blockquote><p>git clone + 仓库地址下载克隆文件</p></blockquote><blockquote><p>git reset –hard + 版本号 回溯版本，版本号在commit的时候与master跟随在一起</p></blockquote><blockquote><p>git reflog 显示命令历史</p></blockquote><blockquote><p>git checkout – <file> 撤销命令，用版本库里的文件替换掉工作区的文件。我觉得就像是Git世界的ctrl + z</file></p></blockquote><blockquote><p>git rm 删除版本库的文件</p></blockquote><blockquote><p>git branch 查看当前所有分支</p></blockquote><blockquote><p>git branch &lt;分支名字&gt; 创建分支</p></blockquote><blockquote><p>git checkout &lt;分支名字&gt; 切换到分支</p></blockquote><blockquote><p>git merge &lt;分支名字&gt; 合并分支</p></blockquote><blockquote><p>git branch -d &lt;分支名字&gt; 删除分支,有可能会删除失败，因为Git会保护没有被合并的分支</p></blockquote><blockquote><p>git branch -D + &lt;分支名字&gt; 强行删除，丢弃没被合并的分支</p></blockquote><blockquote><p>git log –graph 查看分支合并图</p></blockquote><blockquote><p>git merge –no-ff &lt;分支名字&gt; 合并分支的时候禁用Fast forward模式,因为这个模式会丢失分支历史信息</p></blockquote><blockquote><p>git stash 当有其他任务插进来时，把当前工作现场“存储”起来,以后恢复后继续工作</p></blockquote><blockquote><p>git stash list 查看你刚刚“存放”起来的工作去哪里了</p></blockquote><blockquote><p>git stash apply 恢复却不删除stash内容</p></blockquote><blockquote><p>git stash drop 删除stash内容</p></blockquote><blockquote><p>git stash pop 恢复的同时把stash内容也删了</p></blockquote><blockquote><p>git remote 查看远程库的信息，会显示origin，远程仓库默认名称为origin</p></blockquote><blockquote><p>git remote -v 显示更详细的信息</p></blockquote><blockquote><p>git pull 把最新的提交从远程仓库中抓取下来，在本地合并,和git push相反</p></blockquote><blockquote><p>git rebase 把分叉的提交历史“整理”成一条直线，看上去更直观</p></blockquote><blockquote><p>git tag 查看所有标签，可以知道历史版本的tag</p></blockquote><blockquote><p>git tag <name> 打标签，默认为HEAD。比如git tag v1.0</name></p></blockquote><blockquote><p>git tag <tagname> &lt;版本号&gt; 把版本号打上标签，版本号就是commit时，跟在旁边的一串字母数字</tagname></p></blockquote><blockquote><p>git show <tagname> 查看标签信息</tagname></p></blockquote><blockquote><p>git tag -a <tagname> -m “&lt;说明&gt;” 创建带说明的标签。-a指定标签名，-m指定说明文字</tagname></p></blockquote><blockquote><p>git tag -d <tagname> 删除标签</tagname></p></blockquote><blockquote><p>git push origin <tagname> 推送某个标签到远程</tagname></p></blockquote><blockquote><p>git push origin –tags 一次性推送全部尚未推送到远程的本地标签</p></blockquote><blockquote><p>git push origin :refs/tags/<tagname> 删除远程标签<tagname></tagname></tagname></p></blockquote><blockquote><p>git config –global color.ui true 让Git显示颜色，会让命令输出看起来更醒目</p></blockquote><blockquote><p>git add -f <file> 强制提交已忽略的的文件</file></p></blockquote><blockquote><p>git check-ignore -v <file> 检查为什么Git会忽略该文件</file></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;git config –global user.name “你的名字” 让你全部的Git仓库绑定你的名字&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;git config –global user.email “你的邮箱” 
      
    
    </summary>
    
      <category term="工具" scheme="https://23yue23.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="git-常用篇" scheme="https://23yue23.github.io/tags/git-%E5%B8%B8%E7%94%A8%E7%AF%87/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch-学习篇</title>
    <link href="https://23yue23.github.io/2019/10/11/elasticsearch-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    <id>https://23yue23.github.io/2019/10/11/elasticsearch-学习篇/</id>
    <published>2019-10-11T04:05:54.000Z</published>
    <updated>2019-12-17T02:00:34.718Z</updated>
    
    <content type="html"><![CDATA[<p>介绍：<br>一个分布式的实时文档存储，每个字段 可以被索引与搜索<br>一个分布式实时分析搜索引擎<br>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;介绍：&lt;br&gt;一个分布式的实时文档存储，每个字段 可以被索引与搜索&lt;br&gt;一个分布式实时分析搜索引擎&lt;br&gt;能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据&lt;/p&gt;

      
    
    </summary>
    
      <category term="elasticsearch" scheme="https://23yue23.github.io/categories/elasticsearch/"/>
    
    
      <category term="elasticsearch-学习篇" scheme="https://23yue23.github.io/tags/elasticsearch-%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    
  </entry>
  
</feed>
